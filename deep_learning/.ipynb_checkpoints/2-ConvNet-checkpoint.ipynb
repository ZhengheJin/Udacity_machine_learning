{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (73392, 32, 32, 1) (73392, 5)\n",
      "Validation set (9964, 32, 32, 1) (9964, 5)\n",
      "Test set (13066, 32, 32, 1) (13066, 5)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'SVHN.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_data']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_data']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_data']\n",
    "    test_labels = save['test_labels']\n",
    "    test_filenames = save['test_filenames']\n",
    "    del save  # hint to help gc free up memory\n",
    "    \n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LecunLCN(X, image_shape, threshold=1e-4, radius=7, use_divisor=True):\n",
    "    \"\"\"Local Contrast Normalization\"\"\"\n",
    "    \"\"\"[http://yann.lecun.com/exdb/publis/pdf/jarrett-iccv-09.pdf]\"\"\"\n",
    "\n",
    "    # Get Gaussian filter\n",
    "    filter_shape = (radius, radius, image_shape[3], 1)\n",
    "\n",
    "    #self.filters = theano.shared(self.gaussian_filter(filter_shape), borrow=True)\n",
    "    filters = gaussian_filter(filter_shape)\n",
    "    X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "    # Compute the Guassian weighted average by means of convolution\n",
    "    convout = tf.nn.conv2d(X, filters, [1,1,1,1], 'SAME')\n",
    "\n",
    "    # Subtractive step\n",
    "    mid = int(np.floor(filter_shape[1] / 2.))\n",
    "\n",
    "    # Make filter dimension broadcastable and subtract\n",
    "    centered_X = tf.subtract(X, convout)\n",
    "\n",
    "    # Boolean marks whether or not to perform divisive step\n",
    "    if use_divisor:\n",
    "        # Note that the local variances can be computed by using the centered_X\n",
    "        # tensor. If we convolve this with the mean filter, that should give us\n",
    "        # the variance at each point. We simply take the square root to get our\n",
    "        # denominator\n",
    "\n",
    "        # Compute variances\n",
    "        sum_sqr_XX = tf.nn.conv2d(tf.square(centered_X), filters, [1,1,1,1], 'SAME')\n",
    "\n",
    "        # Take square root to get local standard deviation\n",
    "        denom = tf.sqrt(sum_sqr_XX)\n",
    "\n",
    "        per_img_mean = tf.reduce_mean(denom)\n",
    "        divisor = tf.maximum(per_img_mean, denom)\n",
    "        # Divisise step\n",
    "        new_X = tf.truediv(centered_X, tf.maximum(divisor, threshold))\n",
    "    else:\n",
    "        new_X = centered_X\n",
    "\n",
    "    return new_X\n",
    "\n",
    "\n",
    "def gaussian_filter(kernel_shape):\n",
    "    x = np.zeros(kernel_shape, dtype = float)\n",
    "    mid = np.floor(kernel_shape[0] / 2.)\n",
    "    \n",
    "    for kernel_idx in range(0, kernel_shape[2]):\n",
    "        for i in range(0, kernel_shape[0]):\n",
    "            for j in range(0, kernel_shape[1]):\n",
    "                x[i, j, kernel_idx, 0] = gauss(i - mid, j - mid)\n",
    "    \n",
    "    return tf.convert_to_tensor(x / np.sum(x), dtype=tf.float32)\n",
    "\n",
    "def gauss(x, y, sigma=3.0):\n",
    "    Z = 2 * np.pi * sigma ** 2\n",
    "    return  1. / Z * np.exp(-(x ** 2 + y ** 2) / (2. * sigma ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels, printstat=False):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 2).T == labels) / predictions.shape[1] / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "num_labels = 11 # 10 + invalid\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "batch_size = 64\n",
    "patch_size = 5\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "depth3 = 64\n",
    "num_hidden1 = 64\n",
    "shape=[batch_size, image_size, image_size, num_channels]\n",
    "\n",
    "# Construct a 7-layer CNN.\n",
    "# C1: convolutional layer, batch_size x 28 x 28 x 16, convolution size: 5 x 5 x 1 x 16\n",
    "# S2: sub-sampling layer, batch_size x 14 x 14 x 16\n",
    "# C3: convolutional layer, batch_size x 10 x 10 x 32, convolution size: 5 x 5 x 16 x 32\n",
    "# S4: sub-sampling layer, batch_size x 5 x 5 x 32\n",
    "# C5: convolutional layer, batch_size x 1 x 1 x 64, convolution size: 5 x 5 x 32 x 64\n",
    "# Dropout\n",
    "# F6: fully-connected layer, weight size: 64 x 11\n",
    "# Output layer, weight size: 16 x 10\n",
    "\n",
    "train_size = train_labels.shape[0]\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data placeholders.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 5))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    # Variables.\n",
    "    layer1_weights = tf.get_variable(\"W1\", shape=[patch_size, patch_size, num_channels, depth1],\\\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    layer1_biases = tf.Variable(tf.constant(1.0, shape=[depth1]), name='B1')\n",
    "    \n",
    "    layer2_weights = tf.get_variable(\"W2\", shape=[patch_size, patch_size, depth1, depth2],\\\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth2]), name='B2')\n",
    "    \n",
    "    layer3_weights = tf.get_variable(\"W3\", shape=[patch_size, patch_size, depth2, num_hidden1],\\\n",
    "                                     initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden1]), name='B3')\n",
    "    \n",
    "    layer4_weights_d1 = tf.get_variable(\"W4d1\", shape=[num_hidden1, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    layer4_biases_d1 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5d1')\n",
    "\n",
    "    layer4_weights_d2 = tf.get_variable(\"W4d2\", shape=[num_hidden1, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    layer4_biases_d2 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5d2')\n",
    "    \n",
    "    layer4_weights_d3 = tf.get_variable(\"W4d3\", shape=[num_hidden1, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    layer4_biases_d3 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5d3')\n",
    "\n",
    "    layer4_weights_d4 = tf.get_variable(\"W4d4\", shape=[num_hidden1, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    layer4_biases_d4 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5d4')\n",
    "    \n",
    "    # Model.\n",
    "    def model(data, keep_prob, shape):\n",
    "        LCN = LecunLCN(data, shape)\n",
    "        \n",
    "        conv = tf.nn.conv2d(LCN, layer1_weights, [1,1,1,1], 'VALID', name='C1')\n",
    "        hidden = tf.nn.relu(conv + layer1_biases)\n",
    "        lrn = tf.nn.local_response_normalization(hidden)\n",
    "        sub = tf.nn.max_pool(lrn, [1,2,2,1], [1,2,2,1], 'SAME', name='P2')\n",
    "        \n",
    "        conv = tf.nn.conv2d(sub, layer2_weights, [1,1,1,1], padding='VALID', name='C3')\n",
    "        hidden = tf.nn.relu(conv + layer2_biases)\n",
    "        lrn = tf.nn.local_response_normalization(hidden)\n",
    "        sub = tf.nn.max_pool(lrn, [1,2,2,1], [1,2,2,1], 'SAME', name='P4')\n",
    "        \n",
    "        conv = tf.nn.conv2d(sub, layer3_weights, [1,1,1,1], padding='VALID', name='C5')        \n",
    "        hidden = tf.nn.relu(conv + layer3_biases)\n",
    "        hidden = tf.nn.dropout(hidden, keep_prob)\n",
    "        \n",
    "        shape = hidden.get_shape().as_list()\n",
    "        reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "        #print(reshape.get_shape())\n",
    "        \n",
    "        logits1 = tf.matmul(reshape, layer4_weights_d1) + layer4_biases_d1\n",
    "        logits2 = tf.matmul(reshape, layer4_weights_d2) + layer4_biases_d2\n",
    "        logits3 = tf.matmul(reshape, layer4_weights_d3) + layer4_biases_d3\n",
    "        logits4 = tf.matmul(reshape, layer4_weights_d4) + layer4_biases_d4\n",
    "        \n",
    "        return [logits1, logits2, logits3, logits4]\n",
    "    \n",
    "    # Training computation.\n",
    "    [logits1, logits2, logits3, logits4] = model(tf_train_dataset, 0.6, shape)\n",
    "    \n",
    "    post_logits = [tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits1, labels=tf_train_labels[:,1])),\n",
    "                   tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits2, labels=tf_train_labels[:,2])),\n",
    "                   tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits3, labels=tf_train_labels[:,3])),\n",
    "                   tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits4, labels=tf_train_labels[:,4]))]\n",
    "    \n",
    "    loss = (post_logits[0]) + (post_logits[1]) + (post_logits[2]) + (post_logits[3]) \n",
    "    \n",
    "    # Optimizer.\n",
    "    batch = tf.Variable(0, dtype=tf.float32)\n",
    "    \n",
    "    # Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "    learning_rate = tf.train.exponential_decay(0.01, batch * batch_size, train_size, 0.95, staircase=True)\n",
    "    \n",
    "    # Use simple momentum for the optimization.\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9).minimize(loss, global_step=batch)\n",
    "    \n",
    "    # Predictions for the training, validation and test data.\n",
    "    train_logits = model(tf_train_dataset, 1.0, shape)\n",
    "    train_prediction = tf.stack([tf.nn.softmax(train_logits[0]), tf.nn.softmax(train_logits[1]),\\\n",
    "                                tf.nn.softmax(train_logits[2]), tf.nn.softmax(train_logits[3])])\n",
    "    \n",
    "    valid_logits = model(tf_valid_dataset, 1.0, shape)\n",
    "    valid_prediction = tf.stack([tf.nn.softmax(valid_logits[0]), tf.nn.softmax(valid_logits[1]),\\\n",
    "                                tf.nn.softmax(valid_logits[2]), tf.nn.softmax(valid_logits[3])])\n",
    "    \n",
    "    test_logits = model(tf_test_dataset, 1.0, shape)\n",
    "    test_prediction = tf.stack([tf.nn.softmax(test_logits[0]), tf.nn.softmax(test_logits[1]),\\\n",
    "                               tf.nn.softmax(test_logits[2]), tf.nn.softmax(test_logits[3]),])\n",
    "\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patrick/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 16.703556\n",
      "Minibatch accuracy: 3.5%\n",
      "Validation accuracy: 8.0%\n",
      "Minibatch loss at step 1000: 5.359937\n",
      "Minibatch accuracy: 57.0%\n",
      "Validation accuracy: 56.1%\n",
      "Minibatch loss at step 2000: 3.570896\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 68.4%\n",
      "Minibatch loss at step 3000: 3.447644\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 4000: 4.114477\n",
      "Minibatch accuracy: 74.6%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 5000: 2.452575\n",
      "Minibatch accuracy: 87.9%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 6000: 3.304161\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 7000: 3.129445\n",
      "Minibatch accuracy: 80.9%\n",
      "Validation accuracy: 83.8%\n",
      "Minibatch loss at step 8000: 2.767930\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 9000: 2.959490\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 10000: 2.817260\n",
      "Minibatch accuracy: 87.1%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 11000: 2.048819\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 12000: 2.391651\n",
      "Minibatch accuracy: 87.9%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 13000: 2.269460\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 14000: 2.090896\n",
      "Minibatch accuracy: 89.5%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 15000: 2.823940\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 16000: 1.806584\n",
      "Minibatch accuracy: 93.4%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 17000: 2.641639\n",
      "Minibatch accuracy: 85.5%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 18000: 1.873697\n",
      "Minibatch accuracy: 93.4%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 19000: 2.243237\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 20000: 2.120262\n",
      "Minibatch accuracy: 91.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 21000: 1.748181\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 22000: 2.522741\n",
      "Minibatch accuracy: 90.2%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 23000: 2.264489\n",
      "Minibatch accuracy: 88.7%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 24000: 1.996951\n",
      "Minibatch accuracy: 90.2%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 25000: 2.270632\n",
      "Minibatch accuracy: 87.9%\n",
      "Validation accuracy: 89.6%\n",
      "Test accuracy: 90.1%\n",
      "Model saved in file: ConvNet\n"
     ]
    }
   ],
   "source": [
    "num_steps = 25001\n",
    "\n",
    "loss_values = []\n",
    "train_accuracies = []\n",
    "validation_accuracies = []\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()  \n",
    "    print('Initialized')\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size),:]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "        #if step % 10 == 0:\n",
    "        #    loss_values.append(l)\n",
    "            \n",
    "        if (step % 1000 == 0): \n",
    "            train_accuracy = accuracy(predictions, batch_labels[:,1:5])\n",
    "            valid_accuracy = accuracy(valid_prediction.eval(), valid_labels[:,1:5])\n",
    "            print('Minibatch loss at step %d: %f' % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % train_accuracy)    \n",
    "            print('Validation accuracy: %.1f%%' % valid_accuracy)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            validation_accuracies.append(valid_accuracy)\n",
    "            \n",
    "    \n",
    "    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels[:,1:5]))\n",
    "    \n",
    "    save_path = saver.save(session, \"ConvNet\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Enlarge the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patrick/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 13.400326\n",
      "Minibatch accuracy: 4.3%\n",
      "Validation accuracy: 30.9%\n",
      "Minibatch loss at step 5000: 1.641422\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 10000: 1.575439\n",
      "Minibatch accuracy: 90.2%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 15000: 1.750440\n",
      "Minibatch accuracy: 89.5%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 20000: 1.112730\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 25000: 1.508788\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 92.2%\n",
      "Test accuracy: 91.5%\n",
      "Model saved in file: ConvNet\n",
      "WARNING:tensorflow:From /home/patrick/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 10.452019\n",
      "Minibatch accuracy: 37.5%\n",
      "Validation accuracy: 42.9%\n",
      "Minibatch loss at step 5000: 1.109882\n",
      "Minibatch accuracy: 92.6%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 10000: 1.234557\n",
      "Minibatch accuracy: 94.1%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 15000: 1.242233\n",
      "Minibatch accuracy: 91.0%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 20000: 0.681276\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 25000: 1.132163\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 93.3%\n",
      "Test accuracy: 92.2%\n",
      "Model saved in file: ConvNet\n",
      "WARNING:tensorflow:From /home/patrick/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 16.028385\n",
      "Minibatch accuracy: 3.9%\n",
      "Validation accuracy: 41.1%\n",
      "Minibatch loss at step 5000: 1.086965\n",
      "Minibatch accuracy: 94.1%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 10000: 0.905625\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 93.1%\n",
      "Minibatch loss at step 15000: 1.024688\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 20000: 0.771325\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 25000: 0.872464\n",
      "Minibatch accuracy: 97.3%\n",
      "Validation accuracy: 94.1%\n",
      "Test accuracy: 92.6%\n",
      "Model saved in file: ConvNet\n"
     ]
    }
   ],
   "source": [
    "for num_hidden1 in [128, 256, 512]:\n",
    "    image_size = 32\n",
    "    num_labels = 11 # 10 + invalid\n",
    "    num_channels = 1 # grayscale\n",
    "\n",
    "    batch_size = 64\n",
    "    patch_size = 5\n",
    "    depth1 = 16\n",
    "    depth2 = 32\n",
    "    depth3 = 64\n",
    "    shape=[batch_size, image_size, image_size, num_channels]\n",
    "\n",
    "    # Construct a 7-layer CNN.\n",
    "    # C1: convolutional layer, batch_size x 28 x 28 x 16, convolution size: 5 x 5 x 1 x 16\n",
    "    # S2: sub-sampling layer, batch_size x 14 x 14 x 16\n",
    "    # C3: convolutional layer, batch_size x 10 x 10 x 32, convolution size: 5 x 5 x 16 x 32\n",
    "    # S4: sub-sampling layer, batch_size x 5 x 5 x 32\n",
    "    # C5: convolutional layer, batch_size x 1 x 1 x 64, convolution size: 5 x 5 x 32 x 64\n",
    "    # Dropout\n",
    "    # F6: fully-connected layer, weight size: 64 x 11\n",
    "    # Output layer, weight size: 16 x 10\n",
    "\n",
    "    train_size = train_labels.shape[0]\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "\n",
    "        # Input data placeholders.\n",
    "        tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "        tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 5))\n",
    "        tf_valid_dataset = tf.constant(valid_dataset)\n",
    "        tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "        # Variables.\n",
    "        layer1_weights = tf.get_variable(\"W1\", shape=[patch_size, patch_size, num_channels, depth1],\\\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        layer1_biases = tf.Variable(tf.constant(1.0, shape=[depth1]), name='B1')\n",
    "\n",
    "        layer2_weights = tf.get_variable(\"W2\", shape=[patch_size, patch_size, depth1, depth2],\\\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth2]), name='B2')\n",
    "\n",
    "        layer3_weights = tf.get_variable(\"W3\", shape=[patch_size, patch_size, depth2, num_hidden1],\\\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden1]), name='B3')\n",
    "\n",
    "        layer4_weights_d1 = tf.get_variable(\"W4d1\", shape=[num_hidden1, num_labels],\\\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer4_biases_d1 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5d1')\n",
    "\n",
    "        layer4_weights_d2 = tf.get_variable(\"W4d2\", shape=[num_hidden1, num_labels],\\\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer4_biases_d2 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5d2')\n",
    "\n",
    "        layer4_weights_d3 = tf.get_variable(\"W4d3\", shape=[num_hidden1, num_labels],\\\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer4_biases_d3 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5d3')\n",
    "\n",
    "        layer4_weights_d4 = tf.get_variable(\"W4d4\", shape=[num_hidden1, num_labels],\\\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer4_biases_d4 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5d4')\n",
    "\n",
    "        # Model.\n",
    "        def model(data, keep_prob, shape):\n",
    "            LCN = LecunLCN(data, shape)\n",
    "\n",
    "            conv = tf.nn.conv2d(LCN, layer1_weights, [1,1,1,1], 'VALID', name='C1')\n",
    "            hidden = tf.nn.relu(conv + layer1_biases)\n",
    "            lrn = tf.nn.local_response_normalization(hidden)\n",
    "            sub = tf.nn.max_pool(lrn, [1,2,2,1], [1,2,2,1], 'SAME', name='P2')\n",
    "\n",
    "            conv = tf.nn.conv2d(sub, layer2_weights, [1,1,1,1], padding='VALID', name='C3')\n",
    "            hidden = tf.nn.relu(conv + layer2_biases)\n",
    "            lrn = tf.nn.local_response_normalization(hidden)\n",
    "            sub = tf.nn.max_pool(lrn, [1,2,2,1], [1,2,2,1], 'SAME', name='P4')\n",
    "\n",
    "            conv = tf.nn.conv2d(sub, layer3_weights, [1,1,1,1], padding='VALID', name='C5')        \n",
    "            hidden = tf.nn.relu(conv + layer3_biases)\n",
    "            hidden = tf.nn.dropout(hidden, keep_prob)\n",
    "\n",
    "            shape = hidden.get_shape().as_list()\n",
    "            reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "            #print(reshape.get_shape())\n",
    "\n",
    "            logits1 = tf.matmul(reshape, layer4_weights_d1) + layer4_biases_d1\n",
    "            logits2 = tf.matmul(reshape, layer4_weights_d2) + layer4_biases_d2\n",
    "            logits3 = tf.matmul(reshape, layer4_weights_d3) + layer4_biases_d3\n",
    "            logits4 = tf.matmul(reshape, layer4_weights_d4) + layer4_biases_d4\n",
    "\n",
    "            return [logits1, logits2, logits3, logits4]\n",
    "\n",
    "        # Training computation.\n",
    "        [logits1, logits2, logits3, logits4] = model(tf_train_dataset, 0.6, shape)\n",
    "\n",
    "        post_logits = [tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits1, labels=tf_train_labels[:,1])),\n",
    "                       tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits2, labels=tf_train_labels[:,2])),\n",
    "                       tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits3, labels=tf_train_labels[:,3])),\n",
    "                       tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits4, labels=tf_train_labels[:,4]))]\n",
    "\n",
    "        loss = (post_logits[0]) + (post_logits[1]) + (post_logits[2]) + (post_logits[3]) \n",
    "\n",
    "        # Optimizer.\n",
    "        batch = tf.Variable(0, dtype=tf.float32)\n",
    "\n",
    "        # Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "        learning_rate = tf.train.exponential_decay(0.01, batch * batch_size, train_size, 0.95, staircase=True)\n",
    "\n",
    "        # Use simple momentum for the optimization.\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9).minimize(loss, global_step=batch)\n",
    "\n",
    "        # Predictions for the training, validation and test data.\n",
    "        train_logits = model(tf_train_dataset, 1.0, shape)\n",
    "        train_prediction = tf.stack([tf.nn.softmax(train_logits[0]), tf.nn.softmax(train_logits[1]),\\\n",
    "                                    tf.nn.softmax(train_logits[2]), tf.nn.softmax(train_logits[3])])\n",
    "\n",
    "        valid_logits = model(tf_valid_dataset, 1.0, shape)\n",
    "        valid_prediction = tf.stack([tf.nn.softmax(valid_logits[0]), tf.nn.softmax(valid_logits[1]),\\\n",
    "                                    tf.nn.softmax(valid_logits[2]), tf.nn.softmax(valid_logits[3])])\n",
    "\n",
    "        test_logits = model(tf_test_dataset, 1.0, shape)\n",
    "        test_prediction = tf.stack([tf.nn.softmax(test_logits[0]), tf.nn.softmax(test_logits[1]),\\\n",
    "                                   tf.nn.softmax(test_logits[2]), tf.nn.softmax(test_logits[3]),])\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "    num_steps = 25001\n",
    "\n",
    "    loss_values = []\n",
    "    train_accuracies = []\n",
    "    validation_accuracies = []\n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.initialize_all_variables().run()  \n",
    "        print('Initialized')\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size),:]\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "\n",
    "            #if step % 10 == 0:\n",
    "            #    loss_values.append(l)\n",
    "\n",
    "            if (step % 5000 == 0): \n",
    "                train_accuracy = accuracy(predictions, batch_labels[:,1:5])\n",
    "                valid_accuracy = accuracy(valid_prediction.eval(), valid_labels[:,1:5])\n",
    "                print('Minibatch loss at step %d: %f' % (step, l))\n",
    "                print('Minibatch accuracy: %.1f%%' % train_accuracy)    \n",
    "                print('Validation accuracy: %.1f%%' % valid_accuracy)\n",
    "                train_accuracies.append(train_accuracy)\n",
    "                validation_accuracies.append(valid_accuracy)\n",
    "\n",
    "\n",
    "        print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels[:,1:5]))\n",
    "\n",
    "        save_path = saver.save(session, \"ConvNet\")\n",
    "        print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Introducing L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patrick/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 16.734369\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 40.2%\n",
      "Minibatch loss at step 5000: 0.861466\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 10000: 0.930302\n",
      "Minibatch accuracy: 95.7%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 15000: 0.921067\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 20000: 0.714882\n",
      "Minibatch accuracy: 97.3%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 25000: 0.816741\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.8%\n",
      "Test accuracy: 92.5%\n",
      "Model saved in file: ConvNet\n",
      "WARNING:tensorflow:From /home/patrick/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 14.309683\n",
      "Minibatch accuracy: 28.1%\n",
      "Validation accuracy: 39.3%\n",
      "Minibatch loss at step 5000: 0.980434\n",
      "Minibatch accuracy: 94.1%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 10000: 0.782058\n",
      "Minibatch accuracy: 96.5%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 15000: 1.307809\n",
      "Minibatch accuracy: 91.8%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 20000: 0.827744\n",
      "Minibatch accuracy: 95.7%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 25000: 0.783472\n",
      "Minibatch accuracy: 97.3%\n",
      "Validation accuracy: 93.7%\n",
      "Test accuracy: 92.7%\n",
      "Model saved in file: ConvNet\n",
      "WARNING:tensorflow:From /home/patrick/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 12.529548\n",
      "Minibatch accuracy: 26.2%\n",
      "Validation accuracy: 40.5%\n",
      "Minibatch loss at step 5000: 1.057291\n",
      "Minibatch accuracy: 94.1%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 10000: 1.122153\n",
      "Minibatch accuracy: 95.7%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 15000: 1.391007\n",
      "Minibatch accuracy: 92.6%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 20000: 0.973361\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 25000: 1.131805\n",
      "Minibatch accuracy: 94.1%\n",
      "Validation accuracy: 93.8%\n",
      "Test accuracy: 92.6%\n",
      "Model saved in file: ConvNet\n",
      "WARNING:tensorflow:From /home/patrick/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 17.570503\n",
      "Minibatch accuracy: 3.5%\n",
      "Validation accuracy: 43.5%\n",
      "Minibatch loss at step 5000: 1.572611\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 10000: 1.560977\n",
      "Minibatch accuracy: 92.6%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 15000: 1.766869\n",
      "Minibatch accuracy: 91.0%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 20000: 1.253905\n",
      "Minibatch accuracy: 93.4%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 25000: 1.484583\n",
      "Minibatch accuracy: 91.0%\n",
      "Validation accuracy: 92.7%\n",
      "Test accuracy: 91.8%\n",
      "Model saved in file: ConvNet\n"
     ]
    }
   ],
   "source": [
    "for regularization in [1e-5, 1e-4, 1e-3, 1e-2]:\n",
    "    image_size = 32\n",
    "    num_labels = 11 # 10 + invalid\n",
    "    num_channels = 1 # greyscale\n",
    "\n",
    "    batch_size = 64\n",
    "    patch_size = 5\n",
    "    depth1 = 16\n",
    "    depth2 = 32\n",
    "    depth3 = 64\n",
    "    num_hidden1 = 512\n",
    "    shape=[batch_size, image_size, image_size, num_channels]\n",
    "\n",
    "    # Construct a 7-layer CNN.\n",
    "    # C1: convolutional layer, batch_size x 28 x 28 x 16, convolution size: 5 x 5 x 1 x 16\n",
    "    # S2: sub-sampling layer, batch_size x 14 x 14 x 16\n",
    "    # C3: convolutional layer, batch_size x 10 x 10 x 32, convolution size: 5 x 5 x 16 x 32\n",
    "    # S4: sub-sampling layer, batch_size x 5 x 5 x 32\n",
    "    # C5: convolutional layer, batch_size x 1 x 1 x 64, convolution size: 5 x 5 x 32 x 64\n",
    "    # Dropout\n",
    "    # F6: fully-connected layer, weight size: 64 x 11\n",
    "    # Output layer, weight size: 16 x 10\n",
    "\n",
    "    train_size = train_labels.shape[0]\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "\n",
    "        # Input data placeholders.\n",
    "        tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "        tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 5))\n",
    "        tf_valid_dataset = tf.constant(valid_dataset)\n",
    "        tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "        # Variables.\n",
    "        layer1_weights = tf.get_variable(\"W1\", shape=[patch_size, patch_size, num_channels, depth1],\\\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        layer1_biases = tf.Variable(tf.constant(1.0, shape=[depth1]), name='B1')\n",
    "\n",
    "        layer2_weights = tf.get_variable(\"W2\", shape=[patch_size, patch_size, depth1, depth2],\\\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth2]), name='B2')\n",
    "\n",
    "        layer3_weights = tf.get_variable(\"W3\", shape=[patch_size, patch_size, depth2, num_hidden1],\\\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden1]), name='B3')\n",
    "\n",
    "        layer4_weights_d1 = tf.get_variable(\"W4d1\", shape=[num_hidden1, num_labels],\\\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer4_biases_d1 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5d1')\n",
    "\n",
    "        layer4_weights_d2 = tf.get_variable(\"W4d2\", shape=[num_hidden1, num_labels],\\\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer4_biases_d2 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5d2')\n",
    "\n",
    "        layer4_weights_d3 = tf.get_variable(\"W4d3\", shape=[num_hidden1, num_labels],\\\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer4_biases_d3 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5d3')\n",
    "\n",
    "        layer4_weights_d4 = tf.get_variable(\"W4d4\", shape=[num_hidden1, num_labels],\\\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer4_biases_d4 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5d4')\n",
    "\n",
    "        # Model.\n",
    "        def model(data, keep_prob, shape):\n",
    "            LCN = LecunLCN(data, shape)\n",
    "\n",
    "            conv = tf.nn.conv2d(LCN, layer1_weights, [1,1,1,1], 'VALID', name='C1')\n",
    "            hidden = tf.nn.relu(conv + layer1_biases)\n",
    "            lrn = tf.nn.local_response_normalization(hidden)\n",
    "            sub = tf.nn.max_pool(lrn, [1,2,2,1], [1,2,2,1], 'SAME', name='P2')\n",
    "\n",
    "            conv = tf.nn.conv2d(sub, layer2_weights, [1,1,1,1], padding='VALID', name='C3')\n",
    "            hidden = tf.nn.relu(conv + layer2_biases)\n",
    "            lrn = tf.nn.local_response_normalization(hidden)\n",
    "            sub = tf.nn.max_pool(lrn, [1,2,2,1], [1,2,2,1], 'SAME', name='P4')\n",
    "\n",
    "            conv = tf.nn.conv2d(sub, layer3_weights, [1,1,1,1], padding='VALID', name='C5')        \n",
    "            hidden = tf.nn.relu(conv + layer3_biases)\n",
    "            hidden = tf.nn.dropout(hidden, keep_prob)\n",
    "\n",
    "            shape = hidden.get_shape().as_list()\n",
    "            reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "            #print(reshape.get_shape())\n",
    "\n",
    "            logits1 = tf.matmul(reshape, layer4_weights_d1) + layer4_biases_d1\n",
    "            logits2 = tf.matmul(reshape, layer4_weights_d2) + layer4_biases_d2\n",
    "            logits3 = tf.matmul(reshape, layer4_weights_d3) + layer4_biases_d3\n",
    "            logits4 = tf.matmul(reshape, layer4_weights_d4) + layer4_biases_d4\n",
    "\n",
    "            return [logits1, logits2, logits3, logits4]\n",
    "\n",
    "        # Training computation.\n",
    "        [logits1, logits2, logits3, logits4] = model(tf_train_dataset, 0.6, shape)\n",
    "        \n",
    "        # L2 regularization for the fully connected parameters.\n",
    "        regularizers = [(tf.nn.l2_loss(layer4_weights_d1) + tf.nn.l2_loss(layer4_biases_d1)),\n",
    "                            (tf.nn.l2_loss(layer4_weights_d2) + tf.nn.l2_loss(layer4_biases_d2)),\n",
    "                            (tf.nn.l2_loss(layer4_weights_d3) + tf.nn.l2_loss(layer4_biases_d3)),\n",
    "                            (tf.nn.l2_loss(layer4_weights_d4) + tf.nn.l2_loss(layer4_biases_d4))]\n",
    "        \n",
    "        post_logits = [tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits1, labels=tf_train_labels[:,1])),\n",
    "                       tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits2, labels=tf_train_labels[:,2])),\n",
    "                       tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits3, labels=tf_train_labels[:,3])),\n",
    "                       tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits4, labels=tf_train_labels[:,4]))]\n",
    "\n",
    "        loss = (post_logits[0] + regularization * regularizers[0]) + (post_logits[1] + regularization * regularizers[1]) + \\\n",
    "           (post_logits[2] + regularization * regularizers[2]) + (post_logits[3] + regularization * regularizers[3]) \n",
    "    \n",
    "        # Optimizer.\n",
    "        batch = tf.Variable(0, dtype=tf.float32)\n",
    "\n",
    "        # Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "        learning_rate = tf.train.exponential_decay(0.01, batch * batch_size, train_size, 0.95, staircase=True)\n",
    "\n",
    "        # Use simple momentum for the optimization.\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9).minimize(loss, global_step=batch)\n",
    "        \n",
    "        # Predictions for the training, validation and test data.\n",
    "        train_logits = model(tf_train_dataset, 1.0, shape)\n",
    "        train_prediction = tf.stack([tf.nn.softmax(train_logits[0]), tf.nn.softmax(train_logits[1]),\\\n",
    "                                    tf.nn.softmax(train_logits[2]), tf.nn.softmax(train_logits[3])])\n",
    "\n",
    "        valid_logits = model(tf_valid_dataset, 1.0, shape)\n",
    "        valid_prediction = tf.stack([tf.nn.softmax(valid_logits[0]), tf.nn.softmax(valid_logits[1]),\\\n",
    "                                    tf.nn.softmax(valid_logits[2]), tf.nn.softmax(valid_logits[3])])\n",
    "\n",
    "        test_logits = model(tf_test_dataset, 1.0, shape)\n",
    "        test_prediction = tf.stack([tf.nn.softmax(test_logits[0]), tf.nn.softmax(test_logits[1]),\\\n",
    "                                   tf.nn.softmax(test_logits[2]), tf.nn.softmax(test_logits[3]),])\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "    num_steps = 25001\n",
    "\n",
    "    loss_values = []\n",
    "    train_accuracies = []\n",
    "    validation_accuracies = []\n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.initialize_all_variables().run()  \n",
    "        print('Initialized')\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size),:]\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "\n",
    "            #if step % 10 == 0:\n",
    "            #    loss_values.append(l)\n",
    "\n",
    "            if (step % 5000 == 0): \n",
    "                train_accuracy = accuracy(predictions, batch_labels[:,1:5])\n",
    "                valid_accuracy = accuracy(valid_prediction.eval(), valid_labels[:,1:5])\n",
    "                print('Minibatch loss at step %d: %f' % (step, l))\n",
    "                print('Minibatch accuracy: %.1f%%' % train_accuracy)    \n",
    "                print('Validation accuracy: %.1f%%' % valid_accuracy)\n",
    "                train_accuracies.append(train_accuracy)\n",
    "                validation_accuracies.append(valid_accuracy)\n",
    "\n",
    "\n",
    "        print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels[:,1:5]))\n",
    "\n",
    "        save_path = saver.save(session, \"ConvNet\")\n",
    "        print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Deeper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_hidden1= 512\n",
      "num_hidden2= 32\n",
      "WARNING:tensorflow:From /home/patrick/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 18.360020\n",
      "Minibatch accuracy: 3.1%\n",
      "Validation accuracy: 16.7%\n",
      "Minibatch loss at step 1000: 4.959943\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 59.9%\n",
      "Minibatch loss at step 2000: 1.773822\n",
      "Minibatch accuracy: 87.9%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 3000: 1.447341\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 4000: 1.871655\n",
      "Minibatch accuracy: 90.2%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 5000: 0.916862\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 6000: 1.491839\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 7000: 1.022504\n",
      "Minibatch accuracy: 92.6%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 8000: 1.080270\n",
      "Minibatch accuracy: 93.4%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 9000: 1.001682\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 10000: 0.978258\n",
      "Minibatch accuracy: 95.7%\n",
      "Validation accuracy: 93.3%\n",
      "Minibatch loss at step 11000: 1.051129\n",
      "Minibatch accuracy: 94.9%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 12000: 1.158347\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 13000: 0.612990\n",
      "Minibatch accuracy: 95.7%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 14000: 1.151344\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 15000: 1.234057\n",
      "Minibatch accuracy: 94.1%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 16000: 0.703713\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 17000: 0.645453\n",
      "Minibatch accuracy: 96.5%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 18000: 0.468301\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 19000: 0.469998\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 20000: 0.355810\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 21000: 0.385853\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 22000: 0.822403\n",
      "Minibatch accuracy: 97.3%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 23000: 0.547019\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 24000: 0.993924\n",
      "Minibatch accuracy: 95.7%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 25000: 0.477815\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 94.2%\n",
      "Test accuracy: 92.7%\n",
      "Model saved in file: ConvNet\n",
      "num_hidden1= 512\n",
      "num_hidden2= 64\n",
      "WARNING:tensorflow:From /home/patrick/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 17.509470\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 39.1%\n",
      "Minibatch loss at step 1000: 5.196689\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 56.8%\n",
      "Minibatch loss at step 2000: 1.931089\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 83.8%\n",
      "Minibatch loss at step 3000: 1.597699\n",
      "Minibatch accuracy: 91.0%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 4000: 1.629794\n",
      "Minibatch accuracy: 90.2%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 5000: 0.932804\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 6000: 1.319214\n",
      "Minibatch accuracy: 91.8%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 7000: 1.096569\n",
      "Minibatch accuracy: 93.4%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 8000: 1.280793\n",
      "Minibatch accuracy: 91.0%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 9000: 1.153055\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 10000: 0.771507\n",
      "Minibatch accuracy: 94.9%\n",
      "Validation accuracy: 93.3%\n",
      "Minibatch loss at step 11000: 0.874623\n",
      "Minibatch accuracy: 95.7%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 12000: 0.858673\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 13000: 0.802401\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 14000: 0.789290\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 15000: 0.834025\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 16000: 0.431131\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 17000: 0.818213\n",
      "Minibatch accuracy: 97.3%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 18000: 0.407643\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 19000: 0.415426\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 20000: 0.451046\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 21000: 0.367694\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 94.3%\n",
      "Minibatch loss at step 22000: 0.526112\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 23000: 0.478312\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 24000: 0.830011\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 25000: 0.548204\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 94.2%\n",
      "Test accuracy: 92.5%\n",
      "Model saved in file: ConvNet\n",
      "num_hidden1= 512\n",
      "num_hidden2= 128\n",
      "WARNING:tensorflow:From /home/patrick/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 20.365400\n",
      "Minibatch accuracy: 5.1%\n",
      "Validation accuracy: 41.5%\n",
      "Minibatch loss at step 1000: 4.759405\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 61.8%\n",
      "Minibatch loss at step 2000: 1.750867\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 3000: 1.162578\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 4000: 1.783433\n",
      "Minibatch accuracy: 91.8%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 5000: 0.815771\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 6000: 1.688404\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 92.1%\n",
      "Minibatch loss at step 7000: 1.302722\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 93.1%\n",
      "Minibatch loss at step 8000: 1.090878\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 9000: 1.208001\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 10000: 0.921102\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 11000: 0.835434\n",
      "Minibatch accuracy: 96.5%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 12000: 0.896015\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 13000: 0.877019\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 14000: 0.607614\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 15000: 1.083889\n",
      "Minibatch accuracy: 95.7%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 16000: 0.682337\n",
      "Minibatch accuracy: 95.7%\n",
      "Validation accuracy: 94.4%\n",
      "Minibatch loss at step 17000: 0.639799\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 94.4%\n",
      "Minibatch loss at step 18000: 0.310876\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 94.3%\n",
      "Minibatch loss at step 19000: 0.387667\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 94.4%\n",
      "Minibatch loss at step 20000: 0.497696\n",
      "Minibatch accuracy: 98.0%\n",
      "Validation accuracy: 94.5%\n",
      "Minibatch loss at step 21000: 0.322849\n",
      "Minibatch accuracy: 98.8%\n",
      "Validation accuracy: 94.4%\n",
      "Minibatch loss at step 22000: 0.654105\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 94.5%\n",
      "Minibatch loss at step 23000: 0.859794\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 94.6%\n",
      "Minibatch loss at step 24000: 0.832268\n",
      "Minibatch accuracy: 96.5%\n",
      "Validation accuracy: 94.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 25000: 0.526126\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 94.7%\n",
      "Test accuracy: 92.9%\n",
      "Model saved in file: ConvNet\n"
     ]
    }
   ],
   "source": [
    "for num_hidden2 in [32, 64, 128]:\n",
    "    print(\"num_hidden1=\",num_hidden1)\n",
    "    print(\"num_hidden2=\",num_hidden2)\n",
    "    image_size = 32\n",
    "    num_labels = 11 # 10 + invalid\n",
    "    num_channels = 1 # grayscale\n",
    "\n",
    "    batch_size = 64\n",
    "    patch_size = 5\n",
    "    depth1 = 16\n",
    "    depth2 = 32\n",
    "    depth3 = 64\n",
    "    num_hidden1 = 512\n",
    "    shape=[batch_size, image_size, image_size, num_channels]\n",
    "\n",
    "    # Construct a 7-layer CNN.\n",
    "    # C1: convolutional layer, batch_size x 28 x 28 x 16, convolution size: 5 x 5 x 1 x 16\n",
    "    # S2: sub-sampling layer, batch_size x 14 x 14 x 16\n",
    "    # C3: convolutional layer, batch_size x 10 x 10 x 32, convolution size: 5 x 5 x 16 x 32\n",
    "    # S4: sub-sampling layer, batch_size x 5 x 5 x 32\n",
    "    # C5: convolutional layer, batch_size x 1 x 1 x 64, convolution size: 5 x 5 x 32 x 64\n",
    "    # Dropout\n",
    "    # F6: fully-connected layer, weight size: 64 x 11\n",
    "    # Output layer, weight size: 16 x 10\n",
    "\n",
    "    train_size = train_labels.shape[0]\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "\n",
    "        # Input data placeholders.\n",
    "        tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "        tf_train_labels = tf.placeholder(tf.int32, shape=(batch_size, 5))\n",
    "        tf_valid_dataset = tf.constant(valid_dataset)\n",
    "        tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "        # Variables.\n",
    "        layer1_weights = tf.get_variable(\"W1\", shape=[patch_size, patch_size, num_channels, depth1],\\\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        layer1_biases = tf.Variable(tf.constant(1.0, shape=[depth1]), name='B1')\n",
    "\n",
    "        layer2_weights = tf.get_variable(\"W2\", shape=[patch_size, patch_size, depth1, depth2],\\\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth2]), name='B2')\n",
    "\n",
    "        layer3_weights = tf.get_variable(\"W3\", shape=[patch_size, patch_size, depth2, num_hidden1],\\\n",
    "                                         initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden1]), name='B3')\n",
    "\n",
    "        layer4_weights_d1 = tf.get_variable(\"W4d1\", shape=[num_hidden1, num_hidden2],\\\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer4_biases_d1 = tf.Variable(tf.constant(1.0, shape=[num_hidden2]), name='B4d1')\n",
    "        layer5_weights_d1 = tf.get_variable(\"W5d1\", shape=[num_hidden2, num_labels],\\\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer5_biases_d1 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5d1')\n",
    "\n",
    "        layer4_weights_d2 = tf.get_variable(\"W4d2\", shape=[num_hidden1, num_hidden2],\\\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer4_biases_d2 = tf.Variable(tf.constant(1.0, shape=[num_hidden2]), name='B4d2')\n",
    "        layer5_weights_d2 = tf.get_variable(\"W5d2\", shape=[num_hidden2, num_labels],\\\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer5_biases_d2 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5d2')\n",
    "\n",
    "        layer4_weights_d3 = tf.get_variable(\"W4d3\", shape=[num_hidden1, num_hidden2],\\\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer4_biases_d3 = tf.Variable(tf.constant(1.0, shape=[num_hidden2]), name='B4d3')\n",
    "        layer5_weights_d3 = tf.get_variable(\"W5d3\", shape=[num_hidden2, num_labels],\\\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer5_biases_d3 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5d3')\n",
    "\n",
    "        layer4_weights_d4 = tf.get_variable(\"W4d4\", shape=[num_hidden1, num_hidden2],\\\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer4_biases_d4 = tf.Variable(tf.constant(1.0, shape=[num_hidden2]), name='B4d4')\n",
    "        layer5_weights_d4 = tf.get_variable(\"W5d4\", shape=[num_hidden2, num_labels],\\\n",
    "               initializer=tf.contrib.layers.xavier_initializer())\n",
    "        layer5_biases_d4 = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5d4')\n",
    "\n",
    "        # Model.\n",
    "        def model(data, keep_prob, shape):\n",
    "            LCN = LecunLCN(data, shape)\n",
    "\n",
    "            conv = tf.nn.conv2d(LCN, layer1_weights, [1,1,1,1], 'VALID', name='C1')\n",
    "            hidden = tf.nn.relu(conv + layer1_biases)\n",
    "            lrn = tf.nn.local_response_normalization(hidden)\n",
    "            sub = tf.nn.max_pool(lrn, [1,2,2,1], [1,2,2,1], 'SAME', name='P2')\n",
    "\n",
    "            conv = tf.nn.conv2d(sub, layer2_weights, [1,1,1,1], padding='VALID', name='C3')\n",
    "            hidden = tf.nn.relu(conv + layer2_biases)\n",
    "            lrn = tf.nn.local_response_normalization(hidden)\n",
    "            sub = tf.nn.max_pool(lrn, [1,2,2,1], [1,2,2,1], 'SAME', name='P4')\n",
    "\n",
    "            conv = tf.nn.conv2d(sub, layer3_weights, [1,1,1,1], padding='VALID', name='C5')        \n",
    "            hidden = tf.nn.relu(conv + layer3_biases)\n",
    "            hidden = tf.nn.dropout(hidden, keep_prob)\n",
    "\n",
    "            shape = hidden.get_shape().as_list()\n",
    "            reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "            #print(reshape.get_shape())\n",
    "            # hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "            hidden1 = tf.nn.relu(tf.matmul(reshape, layer4_weights_d1) + layer4_biases_d1)\n",
    "            hidden2 = tf.nn.relu(tf.matmul(reshape, layer4_weights_d2) + layer4_biases_d2)\n",
    "            hidden3 = tf.nn.relu(tf.matmul(reshape, layer4_weights_d3) + layer4_biases_d3)\n",
    "            hidden4 = tf.nn.relu(tf.matmul(reshape, layer4_weights_d4) + layer4_biases_d4)\n",
    "\n",
    "            logits1 = tf.matmul(hidden1, layer5_weights_d1) + layer5_biases_d1\n",
    "            logits2 = tf.matmul(hidden2, layer5_weights_d2) + layer5_biases_d2\n",
    "            logits3 = tf.matmul(hidden3, layer5_weights_d3) + layer5_biases_d3\n",
    "            logits4 = tf.matmul(hidden4, layer5_weights_d4) + layer5_biases_d4\n",
    "\n",
    "            return [logits1, logits2, logits3, logits4]\n",
    "\n",
    "        # Training computation.\n",
    "        [logits1, logits2, logits3, logits4] = model(tf_train_dataset, 0.6, shape)\n",
    "\n",
    "        # L2 regularization for the fully connected parameters.\n",
    "        regularizers = [(tf.nn.l2_loss(layer5_weights_d1) + tf.nn.l2_loss(layer5_biases_d1)),\n",
    "                        (tf.nn.l2_loss(layer5_weights_d2) + tf.nn.l2_loss(layer5_biases_d2)),\n",
    "                        (tf.nn.l2_loss(layer5_weights_d3) + tf.nn.l2_loss(layer5_biases_d3)),\n",
    "                        (tf.nn.l2_loss(layer5_weights_d4) + tf.nn.l2_loss(layer5_biases_d4))]\n",
    "\n",
    "        post_logits = [tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits1, labels=tf_train_labels[:,1])),\n",
    "                       tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits2, labels=tf_train_labels[:,2])),\n",
    "                       tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits3, labels=tf_train_labels[:,3])),\n",
    "                       tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits4, labels=tf_train_labels[:,4]))]\n",
    "\n",
    "        loss = (post_logits[0] + 1e-4 * regularizers[0]) + (post_logits[1] + 1e-4 * regularizers[1]) + \\\n",
    "               (post_logits[2] + 1e-4 * regularizers[2]) + (post_logits[3] + 1e-4 * regularizers[3]) \n",
    "\n",
    "        # Optimizer.\n",
    "        batch = tf.Variable(0, dtype=tf.float32)\n",
    "\n",
    "        # Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "        learning_rate = tf.train.exponential_decay(0.01, batch * batch_size, train_size, 0.95, staircase=True)\n",
    "\n",
    "        # Use simple momentum for the optimization.\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9).minimize(loss, global_step=batch)\n",
    "\n",
    "        # Predictions for the training, validation and test data.\n",
    "        train_logits = model(tf_train_dataset, 1.0, shape)\n",
    "        train_prediction = tf.stack([tf.nn.softmax(train_logits[0]), tf.nn.softmax(train_logits[1]),\\\n",
    "                                    tf.nn.softmax(train_logits[2]), tf.nn.softmax(train_logits[3])])\n",
    "\n",
    "        valid_logits = model(tf_valid_dataset, 1.0, shape)\n",
    "        valid_prediction = tf.stack([tf.nn.softmax(valid_logits[0]), tf.nn.softmax(valid_logits[1]),\\\n",
    "                                    tf.nn.softmax(valid_logits[2]), tf.nn.softmax(valid_logits[3])])\n",
    "\n",
    "        test_logits = model(tf_test_dataset, 1.0, shape)\n",
    "        test_prediction = tf.stack([tf.nn.softmax(test_logits[0]), tf.nn.softmax(test_logits[1]),\\\n",
    "                                   tf.nn.softmax(test_logits[2]), tf.nn.softmax(test_logits[3]),])\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "    num_steps = 25001\n",
    "\n",
    "    loss_values = []\n",
    "    train_accuracies = []\n",
    "    validation_accuracies = []\n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.initialize_all_variables().run()  \n",
    "        print('Initialized')\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size),:]\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "\n",
    "            #if step % 10 == 0:\n",
    "            #    loss_values.append(l)\n",
    "\n",
    "            if (step % 1000 == 0): \n",
    "                train_accuracy = accuracy(predictions, batch_labels[:,1:5])\n",
    "                valid_accuracy = accuracy(valid_prediction.eval(), valid_labels[:,1:5])\n",
    "                print('Minibatch loss at step %d: %f' % (step, l))\n",
    "                print('Minibatch accuracy: %.1f%%' % train_accuracy)    \n",
    "                print('Validation accuracy: %.1f%%' % valid_accuracy)\n",
    "                train_accuracies.append(train_accuracy)\n",
    "                validation_accuracies.append(valid_accuracy)\n",
    "\n",
    "\n",
    "        print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels[:,1:5]))\n",
    "\n",
    "        save_path = saver.save(session, \"ConvNet\")\n",
    "        print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAB4CAYAAABl5OIDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvXuwbVte1/f5jTHnXGs/zjn33Gf37W76YpMuEHkJqQQM\ngoBlJEWgBAIpjKYSSyoGxZhKEauQQBCNRqwgoGhAIg+NYKCKyENCnoJVCEIbaWg7NHRD0337Ps/Z\nj/WYc47xyx+/Meaca+21z9nn9L5nn3vP+NRd96y9HnON+RrjN76/xxBVpVAoFAqFQqFQKBQKhUKh\n8MbGXXUDCoVCoVAoFAqFQqFQKBQKrz1FBCoUCoVCoVAoFAqFQqFQeAQoIlChUCgUCoVCoVAoFAqF\nwiNAEYEKhUKhUCgUCoVCoVAoFB4BighUKBQKhUKhUCgUCoVCofAIUESgQqFQKBQKhUKhUCgUCoVH\ngCICFQqFQqFQKBQKhUKhUCg8AhQRqFAoFAqFwj0hIl8pIr8mIqci8j4R+eyrblOhUCgUCoVC4e5U\nV92AQqFQKBQKrx9E5A8CfwX4CuCfA2++2hYVCoVCoVAoFC6KqOpVt6FQKBQKhcLrBBH5Z8D3qOr3\nXHVbCoVCoVAoFAr3RkkHKxQKhUKhcCFExAOfATwlIr8uIh8Uke8Qkb2rbluhUCgUCoVC4e4UEahQ\nKBQKhcJFeQaogS8DPhv4VODTgK+/ykYVCoVCoVAoFC5GEYEKhUKhUChclGX699tV9cOq+hLw14Ev\nvMI2FQqFQqFQKBQuSBGBCoVCoVAoXAhVfRX4IDAtKFiKCxYKhUKhUCi8TigiUKFQKBQKhXvhe4E/\nLSJPi8hN4L8A/vEVt6lQKBQKhUKhcAHKEvGFQqFQKBTuhW8GngTeC6yAHwK+5UpbVCgUCoVCoVC4\nEGWJ+EKhUCgUCoVCoVAoFAqFR4CSDlYoFAqFQqFQKBQKhUKh8AhQRKBCoVAoFAqFQqFQKBQKhUeA\nIgIVCoVCoVAoFAqFQqFQKDwCFBGoUCgUCoVCoVAoFAqF+0BE/i8RWYnISXr866tuU6FwJ8rqYIVC\noVAoXBFf/GVfoSLCM08/yTue+1je+vbneOKJJ5jNZjhnfhqN0DRzVIWoQgiBNvS0646+7yEGNES8\nCLFrWR4dceull3np+Q8DcPLKq6xPT6iko4oB1TWqHVE7VANKAKI1SDxRHIigkl4SBYmosxdcdIiz\nRSVEARyi6fsxgjryohNCtOdhstPeEWMkRAgoigNxqBPspwWfNudEcQoVihARjYgISkQBJCKi1g5J\nX0LHtiuogEokJr+Xiu3tt/7P/0wu6TQWCoVCofA1qvrdV92IQuEilEigQqHwUDLxpuRHEJFvT+/9\n2yLyv4nIKyLyooj8sIi8+arbXCjcDyKCJPHFnttj+v4mJnaYuJGEFBk/60UQIg7BIYiamCIKAngE\nB3hRe6CohuF3xJSd4ftDG6N9dtiWWltETV5xqW1CxDvsgeARRBRVJYRgj17p+0jXRtarntWqZ7Xs\nWS0Cq0VguepYrjpW656ujXRB0OgRakQ8GgFN4k9UlIBEHR+pfS7/Gx1ewakgKngt+k+hUCgUCoVH\nkyICFQqFhxJVPcwP4E3AEvjh9PZN4O8AzwFvB46B772KdhbujIj8gIg8LyJHIvJeEfkTk/c+X0Te\nIyILEfk/ReTtV9nWqyBHzIAJLRt/JxkGXBI+snDhhu9OPz/dTv6UO/N6TM91/FtiijqK43dT9A8S\nh6gf57Lwk9sXTVQSwTmHiOLFUTtPJc4eVYX3HpeEKVVlvepYtR3LdctiueZ0ueL4dMnxyZKj4wXH\npwuOT9ccn645XbQs1i2rdcu6DXQB+i4ObYixHwQgpuJPUFxIr6UHEYiCC/YoFAqFQuES+csi8pKI\n/JyIfO5VN6ZQuBNFBNpCRL5GRH5RRNYi8j9tvfcfiMivicixiPyqiHzJFTWzUHjU+FLgBeCfAqjq\nT6rqD6vqkaougO8Aft9VNrBwLv8d8LtU9Trw7wN/UUQ+XUSeBH4E+AvA48AvAv/w6pp5dUyjf0xM\nEROAJq+pZtHGHoI7G6mjEacmDtl2wL4ScRpxkn9L7fUk+owRQNv/6hAVZNtP7c3RPinKByLEgKgJ\nQuJ0jARyOQopEqM9Tk9PuX18wtGx/fvq7WNevn3Mi7du8dLt27z46m1eunXES7eOePnWMbeOFhyd\nrDhZrDhdLFmuW4KOAppE3XguqpaWlh4uZbtJmAhA8dESgURkJiLfIyIfSDbMu0TkD+/43DeIiIrI\nF1xFOwuFNyJ3mVuc6wwR46+IyMvp8VfkbGho4eHg64DfBbwFc1L+ryLyjqttUuFOPOrjYhGBzvIh\n4C8Cf3f6ooi8BfgB4M8B14H/Cvj7IvL0A29h4Y7c7aYuYt7rkj8OfJ/uCnswfj/w7gfYnsIFUdVf\nSUIdgKbHO4A/Arw7iXkr4BuBTxGRj7+all4N513SUzt/12e2I4h2fUedWJ0dkZ2ax5koJCFF/UTL\no9rRloxnjFqSJMh4kUHoibl+UcQeCqFX2j7yytEJt44XvHz7hBdfMcHnxVde5cVXjvjIS7d44eXb\nvHzLHi++esTLt4959eiEWyen3D5dcOvkFMWhEVQF1KUoKmtTjGOkEJpfT8JPFDQ65BETgbAakL8N\nfA5wA/h64IdE5Ln8gTRh+XLgw1fQvkLhjcx5c4u7OUP+JPAlwKcAnwx8EfDVD6C9hXtEVX9eVY9V\nda2qfw/4OeALr7pdhTvySI+LpTD0Fqr6IwAi8hnAWydvvRW4pao/mf7+cRE5xSYzLzzYVhbuwvSm\n/i2sE/4hEfkkoMPEvC8Gfiq998Mi8pyqlvP4EJK8Yp8D/KfnvP/JwDdg57TwECIifxP4j4E94JeB\nnwC+BfiX+TOqeioivw58IvCeK2jmlRBlS2RRQaN5aCZVgXBDbeXdgpAAKo4ooCKkUjnpG87qB2EF\nkhETaHAVxHb8lSE9zH5zqDOUW+J8qr9jlX/Sf+SIoqBK2/d4X+MmLqYQHX0Q1ulxe9HRRlj3gVXX\n0naBvg/0MQIO5yylDKCpPSEobYh0MTALjtopT0mNKog6AhEfI040J7ulEKjJ0VJLjlM8m288Gqjq\nKSa0Zv6xiPwm8OnA+9Nr34l5s//mA21cofAG5w5zi8EZkt7/RuAlEfl4VX0P5gD7VlX9YHr/r2HC\n0Hc9wOYX7g9lOowXHjoe9XGxiEAX5xeBXxORL8ImMF8ErIH/90pbVTjDXW7qD1LEvNcb/xHws6r6\nm9tviMjHAT8JfK2q/tMH3rLChVDVPyUifxr4TOBzsb7zEHhx66NHwLUH27qrpes6mqahrmvm8zlN\n0zCbzWiaxlb+AlarNfv7tYk0Q1rYZg2huq6hD/R9z2KxYLFasupM4OlFEe/p2hWOgCMgWQXxFRpB\nnNXriTIKKLvSxLqQomzSamAOS7/KaWzz/QNCr4Rg21+uO5bLFaenS04XK5at8tLtU4J4eoS+71l3\nLSGC9zVSWe2jmFYT60Jk3S6pFgvmVcXMRxpnNZKuNQ2HB/vMZh7xkrUrxI3pYaoCafUx0vNYgqAR\nkWeAd5IiKEXky4G1qv5EyTZ5OBGRGTYR+QIsauR9wJ/P9oxYvbX/Gquh97PAf6KqH7qi5hYuxidy\nZ2fIxvvp+Sc+0BYW7oqIPAb8W8D/DfTAV2AR6l97le0q3BuP2rhYRKALoqpBRL4P+AfAHGiBL0+C\nQ+EhZuum/v8oYt7rjT+G1ZXZIEUI/Qzwzar6/Q+8VYV7QlUD8LMi8keB/ww4wVJrp9zAinwXCoXX\nCBGpgR8E/p6qvkdErgF/CfiDV9uywl24U5Tzc9g5/AOYnfNtmL36OVfS0sJFuZsz5BC4vfXeoYjI\nHdLjCw+eGkv3+3gsaPc9wJeo6nuvtFWFC/MojotFBLogqRjUX8W82L+ERZX8mIj8YVV911W2rXA+\n2zd1eq2Iea8TROSzsCJ7P7z1+luA/wP4DlUtYdGvLyos8u7dWKg7ACJyMHn9kSFqP/6hMq7oFSWl\nMJGWj2ea2zQs0+Wcgz7gEIZKOE4IOsT6EFWJaRl5hyeq4gBFQRVcSuoSS8caAtjTvyG1ARXwZjZI\nVCsQnQPenSOqsu4UjcK6s/1atj2nq47TZc/RsmPVQ6eeSE0QJeCJLu2fA09lKXJp3xGhVyWGSFSl\nCxFP4NqiQ4JHfIc4RwScBCpvBaxzYhgb3jsH6lB5dCOBRMQB34+NfV+TXv5G4PtV9f1X1KzCBbhL\nlPNnAv9IVbMH+5uB3xGRd6jq+x54YwsX5W7OkO33bwAnRQB6uFDVF4F/86rbUbg/HtVx8dG1hO6d\nTwX+H1X9RVWNqvoLwM9jYbmFh5BdN/WWmNdgXrLvFpFPvaJmFu7MHwd+RFW3o0P+BLYKwzeKyEl+\nPPjmFe6EiDwtIl8pIoci4kXkDwH/IfC/Az8K/B4R+VIRmQP/DfAvs1j7qKCal2JPq3SlYjrKuGqY\nus0w5Px6/v5GQWjGpeODRoJG+vRvwF5TVUsIEw84gioBZWoS6Fbks6qJSOIdzlVW9yc9xFVEFRRH\nGyLL1pZ+XyzXHJ8urQj0yYJbJ0tunZzSqydgQlWf1hoLqkRMoFHx4GpwNUEqejy9etYBTjtlsQq8\nfLzi1dMFR4s1J6uWZRfp1BLdAoK4yh4+/es84l1qv0NSzaFHibSq0PcAzwBfqqpdeuvzgT8jIs+L\nyPPA27AIk6+7oqYWLsB26sL22+nf3/PgWlS4D96NFX0GdjpDNt5Pzx8pR0mh8FryKI+LJRJoCxGp\nsOPiAZ8mJz3wC8DXicinquq7ROTTgM/mDVgo6o3A1k39hZObehDz0t+/ICJZzCsRXQ8ZqrpzFQxV\n/Sbgmx5wcwr3jmKpX9+FKQwfAP6sqv4YgIh8KfAdWLH2nwe+8oraeWVkd65zDlc5cCmiRyKaSkHb\nUu1ihZDTClz2ehKJpttLApAShro4MUZiCIPEE3MEEJpqA7n8av6ARROlPyVFzqgq3jtEXVoa3ttv\nxYjGSCCw7ju6LnK6tnpER4sVR8slJ8s1i/WaVa8myiAWnaQWsyPixxXKpAL16Tftk4EIUZAkFp0s\n1zgFV1VI5YlekarBi1BVFTFFAjlT0wCxottYoes3Xnb/hfhbwCcAX6Cqy8nrn4+lM2R+AVsJ9Scp\nPJTsSF34KeAfiMh3Yelg34B1L/tX2MxC4g5zix8F/vs0Fv44Z50h3wf8ORH5ifT3fwn8jQfa+ELh\njc0jOy4WEegsX491wpk/CnyTqn6jiHwT8I+S9+VF4C+p6k9fRSMLd+W8m7qIeYXCAyKFSJ9bk0JV\nfwbLoX9kycWdoyQhyE2EoBQVVFW2apfzfiiYfCfyMukh2IdDCMQQENFxJTG1/DJF0hrv9huDEHNm\no7m4skNwqOR1wcIQYRQVVn1P20VO16a7L9Ytp+uWVd+zDpEQBSeCakQFArmIs0ASglBb0QxAnE/i\nlC1br9GjsWPRK77rqdY90qzQuoHa4ZsZlfdjOtnQfsGpwxa394NA9qiQaqh9NVYD7/lJ9NhXq+oP\nbn02AK+qaomufAjZFeWsqj+TVpb6X7D0of8BSyn64BU1s7DJneYWd3KG/G0s6vlfpb+/O71WKBQ+\nSh71cVEeNUOo8MYn3dTvx27qScENu6lF5GuAP4tFCb0IfKeqfusDb2ihUHjk+bx/7wv1xo0bvP1j\nPpZ3vvOdfMxb3sq1a9domlku+0OMEecqwBFiJEZSxI09tA80VU3sW5anC2699CIvfOTDvPLiSwAc\n37qFrhfUTnGxx0sACcTYIg5EI0hE8g+m9LOchqa4lHLmEDw+iTUiQh9DWuErEDRydHTCat1zdLIC\n4Oj4lJPFktU6EIKiOIswckIURTXQxwDq8HVFVdV4N6PyMwDqeg9XVagK6/Wavl0R2iUVPfMaDmYV\ne3ue64czHru2z83H9jmc11Qp20s01S8Si2Byaan4CPzlf/jjj2hAUOH1Sopy/rtYIegv3HJyTT/3\nTuCXgbeq6qsProWFQqFQeD1QIoEKbzhU9QPscGRP3v8OzOtSKBQKV0peBl5E8N5v1PfJYoxL6VoM\nYowOEUT5u5mcBpajgcBEJI1xFHdyKph4SBE5tvS8bWMIDMpEBe9BHVGjfc+BE7W6PhH6qHR94Oh0\nRdtGjpcmAp2u16y6nlYtqkfEEbpAztIKClEFEYgIEcf169fY37PFcQ6v3WA+36cLytHRMbdffYXT\nk0DXKaIBuo5WO1QiUgnNXkVVOa43s3RAIs7bsRIF1FmKWCmJWHh9sjPKOaUXfRxWL+ZtwN8Bvq0I\nQIXXI1/8RX9Al8slbd9T1zNq561/bxpqV9uY5x1VVeER+r4noPR9JEQIUQlS4VyF1DPr930aZ1O0\nq2qwsSyNPLYogo3BUcG5iscef5LZ3pymNq+CG9dkIE+hLVl5HE/8junHmNq9+V4880kmUaqbY5Sf\npDHnz5wXyJF/Z9ey5ru+Mf3cX/tv/3xxjjwiFBGoUCgUCoUrou06E0ScIk5RJ7ZS1tRUc6OIYcZa\nIKdubdcEgkldII3p70AgEPEmtqitDeaIabtpaS4sKkjRjVW1RPKKWynVTNRWI4smMAWFEKHHsex6\n1m1g3Vo62LKLrHpF1YFzOHHJZHaM9muq1JN+8/qNG1y7dgOAm088yf7hNfou4mc1627NqluxCi2o\nI4SeOkakWtO0NcuuZR4qemkAK8ARUwqcES3CSXeZ34XCw8udUhewejJ/HysqfAx8L/AXrqCZhcJH\njUhEJOIIVE4RF/Hi8QLiYkqdVryk+ngu4lUJYs6MvKCCjTSO6ECp8FjqtYiNszbqmfgDJgdZSnQF\nriL4iugqAvZ+EPOlyMRLErVOY/bQ+jP7ozoKLdPFHOIOuUXP9WHLIEBpGvV1p6QDbrIC5vC752x2\ne3GJwqNDEYEKhUKhULgi2ra1lC5Vq90TI1VVISJDTR8QW9EqGWreeySGoUh0DAEnVqA5xrgRDZRR\nVbqutUgejWZIp7W5TISJhBhx2ah0MkQOCZ7oTBdqmgbnvEX/9D1diPRBWazWHC2WrLue08WKWyen\ngIlA4ipEKmKAdt0xm+2Z5zYEcIKTCjzs7e2xd7DP/GDO4089DsAzb34TzWzOYtWiVcWqazldLli3\nLaFbESO42rHulZPlkr0ToakcPtnA+03N3qwx0aoPiAYq8dT1tN5jofDwc7coZ+CTH1RbCoXXkuzg\n8N5v/L0d4XI24iX/nRYbIH+Pyb+T37jD7wNWC29SX87GVHfmsyLnR+Vstm+yoMNdonjOcB/VW87b\nVhF+ClBEoELhkeR//MEfUe89eIsMuH18BEQ+5m1v4ZM+6RN5yzNPA0rXtrRtS+NzlMAkDFXcRkjq\nnQab6b93+3xm+/2L1C87s808eMvFvP4umQQxRiKKiNqEPES6dZuK6cJiseC3P/BBXnjxRW4fH9Mj\nzJo9jk5P+PBHPsTh4SHXD68xm81sNaMYcdiqRX/sq76sjLyFgRjjcN1W4qw2j9MzRmP+d1cKmEUF\n+S0bcfN+20AihIi6nAIW0z0SNzyW2esoYhFCERN+vLcULisGraz7jnXXsmo7Ttcty66nD+lesrh7\nvFjB66rxOF+lVbtcqjWtOGfilveOa9f3uX7DFjW6fn2fejanns/ousB8PqeezcGdoFQokV4DFdAr\n9NHRBaUP48poqmq1j9Iqa7ZjJRKoUCgUHkZsLLAC/tkBIjI6Q/IiCs6NK1eaXZkigcgiTxKBtlKp\nSe/nSJos69jnfYqTnY7BlkYsTmzFysmQqihO3TCiqNsab9WhjCt6QvrblCPGsXp36tYgb+0wgc+z\no3elg02jhjZeL4LQI8sDFYG+9pu/W9frNbdv3+b4+Ji6rrl58yZ7e3t2A4ce52xiGboWNECIrJan\ntItTlsfHLI9vcXzrVbrlafLogeTlaTXVVlAzqje12piWonWDdzOmiaGKeULFTQzDaGqv5X86/JYC\nrYORbr9Vzyp6Na+tqiJRNzyxIeQ2ecChUYhRURWieqLbo1PB+5rZ4ZzHnnycJ556kus3r7N3sI/U\n1eD1zRMBB3hXc3z7mF/9lV/jhQ8/z/HJbUTAV4pzSt14RJRf+aV3lTu8cIY8KFrkgeK9TwVo4c4O\nx13bMS7i3djlBTnv73sZnKbhtvbCBSd6mlcimk4aBZfScBRwladdWYrLarXCe2E2m7EfAqveiuPO\nZjOeeebNvPWtb+XJJ5+0iW+ILJdLjo+OWK1WF96Xu/Fn/uRX6ZljrcngcQyxv3nh72mdlyGkWDaf\nT42B4biLbp2bnGJkqUu5j9Qclp2PpYwes+l74/PdbRjey1Eo2/VpBsYePsYI6kcjKeZQ6WDLrk8P\n0V2uz3wcNhqWfzEZnN/2t77/UvtTYawj4Bk9nmeF0AC4jRDys+cmR/ZsviciaMzncgw418EITY/J\nrTM6QO3zokqQjigC4gka6WKg63tOl2tOFytOF0u6TglZUMVWIvM46rqi8jV1XQ81HJwTkIhzkfn+\nnNnBjGvX97j+2CEANx6/xnx2wGLVcrpY4asK72tQj4q3peRV6UNP6JW2D7RtSz+zfixUMhw359O+\niIJcYJm1C/LEk08PB/q8Wgy7xPBdnx2fe/LJkHzPpXMf1RFUUDxIbTUvXIVUM5rHnx7qWqjLNS48\nEitAhsLY+T51Ueg1guhwDZoYPtoaSOpFJBJlnLKkklPDbZLnPjYBm6Yvgp+OEdHsoChxtJNyekTa\nZl45LhMJOOc27DYFXv7nP1Bsm8LA3/iu71LUrq+p0GtiQjU8h9EOcbXdC7XzNqY5h8fG/9PTU9q2\nJQa7Gp0HH8caL7lWG4zjQ952/tfttKXyzRPRSYcuPjvXJtf6ZFwe7wg36UvO1jfb7n9Es5AyHc/H\n7ee2jAfMDePudvuH46e6IaV/7X/+NZd2L07HwChJfEmp0t674bkb6twJuRsxs3Zz7Ba3aU8651B0\n+JiKpP5rt/PFaRabcn83PebnOyjtWG3XAxqvGXtveti2oow2Vrm8uONCnNo5TNeOrfg5/s6GDYHs\nTEv7aPn27/1O/ZV/9W4+8Jsf4uTVY3wUbt54DI/nQx95nuPj29Szhr3ZHK+wPDlluTiFGJjNPc++\n/Rk+4ZN+N8+94zkOrt/gIy/e4md/7hd436//FqfLDqcyOFqRnqoaxTbIxzsO5y7t+XAvgI0jklIB\nJ0dvODIbNvGg1cWNayNrDiouOXzH+lHD99J41TTNIGKq0yHV3+o3OhaLxaAPBA2EEOi1H+YlXWdz\nEEvjt4hvkpaQ9yv0kQ995LcudEYfcCSQ23g4HR8x9qMWupWrnwtxxRTqnh8uRgtRjxGN/XDeVNxg\nOjGU63IEjRshe8qm+hlTnQXInk/7XjZQbGld6zhstRFThyMRTReBiT+jsLRr9iIieOfoUUJQQqpX\nYCmc48WlThBf2cosaUleFRDnLOxfx4mDqtJrOi5OCKqmTqOcrRhx/yz6Xr33yaDLCrods0H8zp3l\npXUq0+the7Db1Sk6mO616PSfnUxzcHVyo9svnB1g/Z029hrhkEs7onlDTsfB4GFcKfBh8U5s112Z\neqO891QIguIEHnv8Js8++yaefPJJqqqipqLve9r1cigCfKntiozXOHklKT8dx+yf6aB/zvOdaJr1\n7bjmR4dXnLyd70kZnsuOz20LUtPnKtNt3xnJRtl0O8Pk9WzYdTYMpmHd54ZnX14ndn77J78/eDvV\njFs3vf41da0bTbQVvZTRE3qeACrRjAU0JFEhmqNFkyCSVwhT0vLvMtY9yP2EeKBK90NExaKB2hBo\n+47FekXXBbow3i/O2fhVOU9Tz6ibiv3DwxRtFyzcXyIQ2Nuvme3PmM8b9vatsPPeXs3e3myYnOUV\n0exY5VoOtmJa1wXW6zWrWmnndm67GlQrE0JEbD/tprmsU3jfTK+3XKfCaR5XJwxNnU4ekpgjY7rE\n8BkxWdGpmi0S3SAGKwqq6XfELAS16UGOAlPMthGUmERCBVBBXUSnzWFy36am2vcZCo5DmgaJ2VBZ\nHpSoZtNM+td8HwYUp6QaVLZhTXZNPiZXfwYLDx3OxE40zzUMuy7d+Ee6I1Qs/VbTQOJwIIEogng/\n1GpjqCsmEwGIzd/IE0M278mgPV62p1smUplQmm1NJcYs+ujoUJnOJURs0qsm8uY5QJyMmdmmy/ad\nRMX6e4h61gYZU66qSUTNdDycirGcef5aDJPbY+L09W0H4VknpLB9XnTYJoBs9CU7I8jP7NOmqLj5\njgx9nW7Un5tue/dcMMaLReHc7zIGw/ETHriNHzUvUNHbgJDGcA06jONVU1vEV7CxOwal8hW+qok4\nVinCeI5QNTXVrMHXNa6LEOyMCFbX0CL1cwBIPg/O3pPshJFULymPs368gN32eUjpg8P1RtqyR6Pi\nXRLW8mqp6Tv5Phyi2ADIdk7qi9QW5sijq9UtHO343L4o4KygFYEx0MS6JEeOJMttzAEiF+UhTAfb\nfZNlpWz6IEabeEWroyDenfmOWQr5BGa1b9M7QDJWph1nviaCKk5kw/QaWiqwqR+eNSxzh5U71azE\nm6N6DM4Tlzv18XvTbQyNPLN/JnrFVNgz4lIUwFThv7wb3yEbAhCkm+CBdS7bZ2K7Y76kFV8uGkHy\nOkV07IjIRviOU/hantXpPbE9OD1w8Wc437uvn13tc67COUdd16hXtBICyhNP3OTxJ2/yxJM3qaqK\nZvBM3bzUJrshyiYbPfaP3xKsgCGaZtvbcyZqeVdYsOhgOAFmHMew8ZoFzeRjd54wu/nenXRUl+ex\nw7bH57u+n/vIadFEGVyCIBs/5iYpT5OJM34wlgzPmVnudiMuAY+Y1zk9dhm+zjliuPg9sl0PKL+W\njVQdon50MCLAhAE1awPEkTK6qNKxjBKpK4d4W+Zd+0AfI13fDxE4ad0vE2gAL46qapg3c2bzPZpZ\nzeNPPEbQPt1HSTCgG8Sf+V7N3tzMk1lTUdeeuq9RFVarNW3bJ1HHgwbzAkeh7zvaFlarSNva97ta\niHGGOHN7xRT0AAAgAElEQVSnJMXsgfXxZydUY3+yEbk4fOZO15cd0+nkKxJw6gfTVzRYFJeYsSpR\nzcGlaaKnZktkc1PV26WQUgFVk+ffmXeRKIMDCixqYbwFzBidtniYNg7ONtIvma0guEHgyZGoUccJ\nb9QsHI/ipvVfanOzLAo9hE6LwtVjgkYWgc5HB2ObYYJof8edfet5KTMXTW3f/twum8uc1HHoO7e3\nkZqLTSjTsDSZt2S2n1/0Trmf6OvXyk+SV8rMzraqqqjreiOSAlI6NSktTAXvQ9K7xEZWSWLgcKzc\n4MB3Mr7sNGKh4OmFNKcaxhnsu5ncfylh6I+9QDznsssrdUK+ZpLz3Fn7dh17ixCzOU4EJJ4ds6bR\nZ2ffnAj/6RlMHb+ycSwvm2CjCiopvU/FhM40nw8aB0dqH0KKAnU4X1FVNn63bctqtSIEcxjNZjPq\n2ZxqHS2CFUeMVhPRvp3NNRtt8r1tDi3FiRvfF0sHzBGrqne/njcigER3vCZDxNWmAGhagmUZOAvm\nmGzXpeCOuzEKQOMKsNmSvZ+0vgcqAoWQQpdCxCNDYcau6/DejMGsotZ1TQyOrlsSQiBooG1XqAZq\n75DKoSHiRPDpAospEGzI7dSshCdBJCb1fnqQXD585g2IBDRk5dzhnFBJRdM0EE1tM89UCmO2qwep\nPBLNSDbvs+nzfd8Tog77qmo3pE5uDLzQEcbIgtoP+bCSJiwa4/C3Sx2SikUS5QKbq/XabrguggSi\nKqu2SyHwl0PtzdTcGFRyGOYwEb3zhPru3O372+/v+txEjd85Am5uYzpt3jAI1OEGL83025s32u6W\n3vtx+GiP3P0wGNnpb5+O3f2a2Ge9Mnf+3J0Mj4tu60GxER6cDJMqgHrLnYleqWoThqrKU7lRtjzj\nZLjkNm1Eu9xhMNswRNO/U0Hubt/Jf9ugOd3WdMB7sIxC+VljXiaW8nYawMZ3J9t6kNda5fyG+DOK\nQVYnZ2xjngzHpN/cpY3qhr5YCcn50FMNkR0W/WMeZ3s/j5FDGHU+LhoQZ22ofUXwbjDiskdv3XW0\nXT+kNuRrpqpq9vb2Odg7ZP/wgLr2XL9+aMKEF3wleBTVQDOr2Ntv2NubMZ9bJFBde6qqMoM9CutV\noO9AqJFJwpDGSGh7Wh9ZuUDb2upgXePS/pOMMCBa9O6D4m7najvSMH2LbDwymbBaZLSiRERljDqI\ningZJob5N2MS5CxBb5rq60ArUCEypjtYtBRJKErHScXSMdLvD7F+djA392Wyz2O/4UBSGnwyvIOA\nVx0jlIYv7j5+DgYj3dqolz4B/dt/9Vu0pR+8010X6Fc9sYu88OKHWHcdJ6ct9d4+s3nNm558jOPV\ngtNVT+yEytV02uPxaIwWpJaOa1VHnnjigGvXbjDDsz+vqWqHqyrEm1DqUGovIAF1wsmtU4hWbkDV\nUo6dF/bm+zhX0cWASiRqh/QWVZKdE957pHEoDlVnKXjagXT2DxBCTwpBtzS/4Tp1xK63iCz1dL0S\nFNrVEo39MDn1CBojy+UpUjepzphAbKmcp+2tpuB6teKdH/ecrVAYoN7bB+dNAFbrn/7IV/2pSzmb\nVe0GwfNuDNGgSeA863xN5+8OgtLOMXOSSzs6muNkjHTD7wmbYpBLfb1OLG0RN/RXFj0waeu5A/1G\nPu8DH9c+WnY73iZ9FNM+ZrfBs3luTGyJ6chaHyJJjBlnjqMdJONcLs25HJNo2+QYsXMaxjOrsMuC\n9+dMxMKWvWRz4PxZ6193ZKbfFbWNbRyDbSegDCHUr82MIy1RYb9QV3h1hGC1RvMCGE3T4L0niDkb\ncIKvK6pmBuJYrTsWyyVd6FHx1E1DXefoobwfJvrqZJXTMQp9Wr8pny+7/+xYCx5PnuVZf2S2k31v\n6phJQtMwD5j8/jlMI4RA8Un8kcn7QwewYzvT8XZju7ll6fsxyZ7jnl+MhyoSSAeDwg1q1/RAbRcE\nU7VwZVP7xrzVDRFoRwxP9oi76awsGbj2/4CKFczVaLmnbdvayVSSYT3mp1rbx3Q1gG1hVZ2kFDJJ\nxnmeeKSLMolVWXC4n0iI4UaQOKiC9rjnTRXe4OSBELZEgQ2BIKUpXvBaPC+i534Mj7sJQlfFtgiU\njW216rZEn3J7RTf6l4DSrm3EOpxdTreb25LrhG0IZlufHaJdt7z229vaJopN9Kbv+ySZbkQtxDGy\nItfUcZjXx/rN8b3z0sGm14pOdBnVMWVkaGs8e01Z3zzZDxlDwDcFn+1BfTQks/GnE1F002N7+dfg\n1OO5HQV03nk5L1VOktGa2znUfUmGRPYg2b6SjmM04Tva0vAu2bfTiHhN42z26qma86FtW1btmvXa\nHl3XWY276IYTW1UVBwcH3Lxxk4Nrh7jasXcwp9eArzR5/CKigaapmc1r6sZTVdko94QkVKzXLW3b\n03Y9dfbwikuOCKXTQNcF2jYMqZcxpohe58h1alQvd0K0y8u//fzsdcjGZzy5TkEyRzUAfhTpJ6KH\niNB4T5AUch8CSo8Gu3ZCcKg4mtkeAWW97pjXTbo5LXJYU4qYilI7R+WEvm3pu8isnhFVmVcN6nyq\ngRiHc991VqNAkhNtWudr3F9bmSckESnEbIspUvnkxVS6NLGSaE7C7AEWUs2PYXI3mOnm6Zd7M3Yv\nwk/99D9BXZq0pP5dOuHm9Ru8/blnObr9CjNXo+sV677llXnD8y+8wHqxoltHKnEEB/Omhr4lqBID\nKQoNbr1yk1/8Fz+NiFA5R+NrqlqonOB8pPLQOA+11VuDyqIZnNK3a7MrfUSCUklFACo/BxyVpjqT\nYU7dOPZu+JR+McdXdkSJQvBi6Rk4bhzs4URxUtMcNCYoRUdT1VTiWC6XrBYrrs0PWXRrWnWIs33y\nGs0ZSqART+h61MtoLztH17a86eknODk64V2/9j6OTo6JbeTa9cfMo1/XzGeXu0rfbFYz2PzThSG2\nFolQy5MCoO064Jx+VyJnUmun70/E9s0PZYcwKbrHD+NRjkoAJmOUiRGao4AmIrVuCAsxDXN3mbxv\nCVf3E+VzlbjJWDjci2Krhfk0/9og9RPOWabFxgRdHeLSamOSRbV8LDwi1eAIluE6yCJQvibMKPAi\nKUXWoodJ/4+SEgy3ikZnQjibhqeAVPXQTovW3UxF0yFyBXD+TLmU88jb233eNaV8p8++RnPE/NtO\nLFCiUjcELahEmqahmc+sDpaY+NPFiKsrXGVOnGxnxD4gztPUNbWv8OIIEs22iYJujQbZGTLUq0uv\nm+00KbsyeT3dgSYM6vTd8XkWzrb7ilzPOHPmb90U4aJs6hsbkcIXOrq7vwsXcBBOeKAikNPzjVcY\nDdaRdEo0JEHHaukMRrJYzYQxfSuSPWW2PRiSJiTi/FjfJ8roUVIx70VMPinJIdCA88mDJTnqJ38H\nVCd1jKIQQyRqSCfFpc85xKdwZwFNtYSG7sY5RD2EzTiTTVHbJpijZyDlAeYOY1BAGVxlERu4VPvU\nYV0ObkeYKuSO9tJ+5nzyYKs5DWyqmF8ydwknfj2TOw4nMobfb09MkDOv3e9vwd07ptdDJNDUEzUK\n01b/S5OQ3IXOlr5Oc56okb7v0bSk92V3uzmfP8azg+BH6yl3SVjZPIeb1anuFIJ6L9fP2fM7ekvZ\n/r2t37XzopaqMryec7Czt+/u19AgkDAV6l8/hnPh4eEyPO/DpMD+SrOGSF7dzKkbomOyEWtvWX+k\nmuwkl2sHZa92TUj3TIwRqSqbaLqaqrKOS8SKT8e+R10cFs7IqZ9+GPLd2C4m9hep/xnab2Kdzb3t\ns32aWEmaLJ/bj0yE42ndk4vWDbsof+jf/TxWqwXRdXiskPByuUZUOH75FR6/ViO+4tmnnoW6ob52\nnbc8+Qyhb5l56EOH9575vKL2QtPMzTkoHSEoP/pj/4RXXvpNDvbmVK4m+hmx7xFJDgXpLYLIOZax\np+9jKlDsiNrjnIL0xD7gqfG+wnuT230E9TUx1AgdbVwjvgGpCX2LizVET9suqPaqIQpeReg7R2BF\ncArqqUJF1wU8wsH+nH/n934K4lu6bgVOqKqGoJ6Y6m8uJNKGHpxwulzSdkpPRTOvWS5P8KIctj0n\nR7fRXrn18i1m9Yymqa0ezyWO7RuRnWMl183nkAe3M99/LVJjdolLY/+QbQqS42L3sdh9b+wqVHHv\nPAy21Ta7HCP5oVvHIkd0TL+bJ+oigjid5gYMn8n9lwVrnX8M3NZ7tmpZip6dRmBnWyWM9skkFuts\nOr7IIF1s9vVnjobtzz2cpp3CwAM2Y1wAH10aLxy186zWS0LoBsHfezf0/d576sMD9vYPmO014Byh\ni6wWa1anC1QqaidUDiondFE3Quy399GEIHNsOSwQw0l2VuQPWdp7tpW9bJVZyLnV6blKSivfch6O\nYpsfovssUZHhM4KfBIG4UYxMjp5hTs8YIbt1RMn3e1Qrh2NOIpeV4smOX4yHKhJoirCpvm/W1BlF\nIJ9CLIVI9Cb4bFfkNoa4+rGWjzOvm4ofQ2GjBePHlPBjhpSjD2vEJ0U6pa5FqYbJSECJGgnBDDSf\n6kvkgtY22U5h2SqpUJUZRcNEJhX5HBRcMRVYtyZB55GFoBgtMU6cEkI4E5X0UZHOw6bqmm+adEPs\n/OK9JDrde4OHAqZ2QrbfTf/qmZd0+GPSkSfxMM1/U0HLaCHeqtOv34V7348HJTsNqQIxWgqBbA6B\nu82jbSLb3qiLCj53Y4iY29jM2dV8xkH4Ho/cPS4dv7N9MEbbYak2eB1TWwn0Qen7lhACEkcv92Ui\nUYeisvn5YFgqg1E5pBIxCu56D/svMXs100oEk2qwohAlpD7PDQbZxmpdzt7bFqYsakhTe/KrVtJe\nnId4tginTrpEFeutJUckyK5eaDS0x2tzd00qK/7/4FKFXJVns+b0GMe4TeNSVSdhrtEqwOlmuLCV\nyjOvt8cN/aKoszTnQTwH0nU7nR9ZveRk8OjE2BZHiBC9rU4VogmbFv0TaFubsPZ9NMMtZm+1Tarm\n8zkH1w45PNzH1RZNUDmH92IRP2LdtlSCq83hkVNu+2BFUtteWbU9y3VnE9SmIq98ZeIfaZVQpQuB\nPth1E1DGlWNSIUbZbWJdJhfpA/N5HSMBptftOX3a9BxukRfaMB+RDhF5Tirms2ugHo01Gh19iuzq\nNeJwxBBw4lCvhD7gEAIO52dAB5oKfKbV3NLNNLZ12N00tgyrHuXIBjHRQAMxjI6H3Jd6P0mfGfZn\n63ilgWlrOn9pvO25t9HHjvV6RQxhENZvvXSbWy8dsX/9gL3rh/jr1wjiOF4v2Ts4RLXBa0/t5tS1\nrX63XJ7S9wGvkXo2x1fCs08/wxOfecD1aw0z71Bq22/vAKESoV0vafuOGKCNEV85iAEvQh/NLu5D\nwMkM7xx7s4qoK0SdFRClQugRCYToiDJeL6pC7FqUYPfxWuhJtTu6nk6jrUbTBjSaEHS6POEzP/cz\neOZNN+nXLRFH262o68rqzKtaKZUghNAR4opXbq948cVTTlZrlv2KCuXa3j4f8+wNmnqO+hkzhBg6\nXOOt3MIlYdfPWVtBUzTg+JmR7Wi9exKCNsbQIVFy69/ciDwltHFmdE7kj471RDa/erY9ow1y8aZu\nczcHzlWKQ1mgieKoUuE4yf9uRXHIEC0zKTovedJurzliWsBj0ucM/W7qW5xYBLw4sBF02KJN4i3y\n0qWJt6SIWtWI1zi0OdtEJNtGFELsUYmEFMGa8048Ptk9gq1had/LY29OSXL3aJMMNv4OcX0axL15\nvC+X06NjHMLh3j4ntxccrxZ2TJ3j2Te/CV9VdKFntVjShY75wZzGNzRNg6qyWKwIcY2rPM459g+v\nEfqWmzeuc3q0QueOtu2JsbOVwTTXkQsIineeSmxs8TGmox7QoOzN5kSUZdfhvUVVerG6vNp39Mnu\nrOsakVTDqO+YzWskWlSXitUG1QghdEBlkd3JDssBGA4zWJ1zaUwRhl45z/cnUVuaPhtCGM6dOQKs\nhpLE1EdNv5N/K5WpuChXujqY6PQhoDFNWOIg0+1SM3MGZ54AerXKACKWCpW/MhaHwr6RPPXDiivO\n/pdFvnXX27RWky84jyXOqpLjTakUnzqEtDxbVMuRDihdunD6mJbb1iwSZaPH7j1JP2pL22UFcVPJ\n3r5xTajKK4WliefWEbawaiWKCUBW9uHybu/hfDxgRXnSgvT7m/nOk3ndoM6mD06+u0MM2jFYp2Ax\ncrpLumzO9dC8XsnjQPYkW+9p9+bU5NBdI8b2traMifsVgza2MW0jaQLrdEgFUhuR0yR2EkaN7YcS\nPioDZ9d+79peIJjqL0CMHOztM5/VeOfNi94HNASL+rvEiJLBcIVhRSFEUjljiwLQSSRkPpByh3OZ\njd9s+JiHzZkABCZaI0N9mBx9KRoI2UNB7qcn/Zpz5BU0Yvo3n8fKBTRaioEFLnhCVJxTKnE4V7Hu\nWpsobOeQpf0XycKQbEQKgbAdPT0eKjPWVPNWUrs1DCl+29fJdrTVZeC95+Bgj+s3Dtk/mCOidN0a\nkWYSeeaSA2KM+sqPnE5WVZW9FvIqWR39OqVEdRENmPCiLiuCmBe0z0dx8LLmQ5KTRs1pYsZqTGkn\nIULfR06OT7l9+5jlcpXOndUBqqpxYnd6ekrT3KKaVRzuHRBjn6JTkhDtbLysKhN2rl1/jGa2D0Af\nHce3Tvjw8y/zkRdfIqgyP9i3otR9j/fW9srX1P4Qp0uqxg9jsV2lShd6wFN5T+29jY9XzLYBd/YD\n25O/yYRe0jOd3g4OkRrUooTMqZRSKWiwItBurMujqUglDaFbU1kRG7oQqb2gQWn2ZigVIXQmEg11\nghybk+1NcWraf27v57b33CZY9u+ueyz3dLpjcn+ZhBBMr3YeDVa/oW17jk9bPvLyK8yWM9ytjhBe\ngdhbilYNs7rBaZXERtuHuq6ZV4JPhfWd8/gofNbv+3T29j0x2LkaBF8nVuMiQp8mIepT5HuwQuiq\ngRA6ovMIDaLKwWGD95pqOqVyCr0i9HZvS0VAqZPd2nX2uncO1ZogVpDUd7AIHev1GolCiB1HqxPe\n8xsf5P0vPc9KA13X48Uhfcvx6RGuSuOMBgTbl+PlbRaLwKq1pYqXsbWIAGl427NPUVUe9TOayjNv\nKqK7nIjjjKVh7HIYMRHWx+tPVVJkhxLDuPpOVVUbaUj59d2MTk5VswesHTae4Sqch9iaIO2cQ9zo\nKM5RdiJKn1fyGvcISHVPY6QLSu08Xdcxn89Zr9dp/9JdkpTT0J83rzhfUDqP6X0bJyKZc2edOpeF\nOg/e4fF48czqGXVVD9NDSVE0tk8+CTpKcJZm2qtFLfqUBuywtHQnDtJqzujoLsrLxYsTNIaxrpYG\nQtdRS21zR5GhWp5IwFce7XrWq0Wq2VXRzG5QV55ahNXpLU6ObvPqKy/R9T2x2WN+eI2n3vQsvp5B\n7C2KXNO1ptHuqSx259Rl2YxEvxMRRSdC5nDVD9evDA4i4HIDBab0QKfQKdorsVebP+dZeYyEvqXt\nVvS9rWrbxQ7phKg9bVgTouNwubZo+hDZa2r2Zg3zpqHv19S+IsYe8RBjT3QyFO2WGBAvSaAXKmdi\ntxdHk+rmSg29wDr0BIXae6LKkPUiai5GL1DXQiU6JKComGgYvWAr69kbtjq3G+1yhOhGu9rhcM6n\n6ct0TbD0TJl2UVv12ibzl8FRrpYimRaFuJf+9KGKBJqGctkObna426uDSYyIpiQu1cmKGHkbwzeB\nMZVp0v2nf3Mevab8+izcWLV3R0C9UInD1xW+Scaqy7n6gdOjU+vs6Qb1zmp1+HF5RuuGkhDkEbFi\nlfb5eiIyjPmKOfXsbqfUoph0CEMM0ZTjeMmRQMvlmoODvfuQje+vERahYjdW16+pvO2fdxWI0LeB\nqvJku7HvI83MvGrjhUCe4+SNWkceI0Ro1z0nixPatgWgaRr29/fZ22sG70wfI5WvxtSpM2fkbKTT\nwywayTStyVnuf117Dg4OqOuaros03uEUaueHujDxDvnIuwykjTzX7fs5z+eTGODFWUplNLW7qWpw\nNriLdzQVnK66NOmDalbZNS4RQmTV9jjXsFgsLHe4mQ35x9b2Pk2YdZjk5klWzt8NwVbmqGufUj7N\nG6whWs2UmMVcZd2t6GNg//CAVdfSr1c0dcPTTz3FzcPHkBAJXY/D49IE9zInnpshqGeN1Dyx2hpP\n7rpN29BkG1sDyubfY8rWKLwYMU6XYR89/xGhjwHvarxLxleMqXYLrNYrpKpp6rlFhojY/X6OtTmN\nEh2iKuLmcTgTsr21H9PjuOv13ft+OahLqTtgTgyJKQRiTPO1985OogXSjZScK+rIKwFkBwtkWVeS\n9zlfFx5EcWJFZ83y8GRPa4TJipsexBZKyFE1MZr3P0YsEiflWPd9QGIgphoIUQWpVlSLU5qTOSoR\n74U61OwfzJBKcR6qytPMZ9RNQzWboT6tDhIj665juWpZrTu6vqfreypv/QIiRCcEFbwKXRD6qGnF\nTAhq0UFBlToPBPmAXuZ5vINX/d6YpH+d4U4ipEUWa++H+lg2SauQ6AjqUbX0dvu4UjlBxUOwBSei\nOIiCOOg1UpEnpSYIihc0dmQnXXJlbrR1c+WZsXXmskr3XrTorjGtQyaPOGznstO97ka+ZpyrUJei\nYrrI7VvHiDje++73sl4pLiqub6kaT8sKJ4ro3CauWHqTJyCux4sSeiG6is/9vN/P3vU5R8dLfvVX\n3g/ArKnxNUQc2ts42IeOSMf+/qHd697SKoJGovQc7h2CVlQIx0cVWtn7s/0ZFglU0cxqq7PhZ1Su\nBhHqBrq4Nq+zd3hfgYBX0MbhQmRvz9LNNKw5kcDNJ5/gl375XaxOLKK1FoePjqZpcFVOVVsj4vBS\n0SlE52m7Du1all2gnjU8fniNT/2Et9FHK27tPCnSPo8RD56c/nuZv392LA4pSgpiN/YTblIoODtq\nRHLtLPt7KrQ6Z6sgdjGgPgkd/ZjmfF7fs22D3W8XtW1rDK+9BmNi/p3peJyjHKert3kx8cR6oLzC\nYI6nSccGq2MoCt5lB0eOZJycd5mk1snmwgEbkd+T/Q0hgPboekm/OKFbr03wuzbD1zXBCbFbEVcL\n2sWxRdMi9G3Ner3GBWVvVg8i/tRfP12sZeQe6gFxvt33Wtgxuwh9T9/3dF1PnxaQEKlwSQCN2rNa\nrVitVqgqTT3H1TVdCKzXK9btir73rFYrYq9UlePa4SGrU2U+b1i1gagBF0zoG9L5zTACUUQjtXPM\na5glZ6FXpap6ojhq7+hioFusiFHx7gBXY8vPB5JDRfBe8FWNc3EwISKaat6BuhpVCOGco65u4z59\nLe+de8lweKAikGSP1Zlq+3ZDTjN6znqUkpcmRjQEy6OOlpMZ8sR8iMSMW1vIv58OvuSJQX7DDFjt\nNXk54/CbZogo635NIzVeaubNnP39OfWsokqTytPTD0BvKV8hu+emaRiqQMA588wJOnhCwez2KCRT\nfePIJKwDDCmwkUEkO3uyVXWIYjJBa/f5uB/W6zWzWZ3qkJxzoU1WMvloUVXavrPNiRUJG0N1HVUF\nGmG5tIHy5Zdf5Oj4Vdp2Re088/k+BwcHPP3001R1XlXNVu1wruJDv/MCv/7rv8HLr740nIvZbMaN\nG4/x1FNP8fTTT3H9xv6o4E68KLlYaqFwVeTQ0DMGWrrnbdBR0jo/Z0Ud8ZOtTfrc1EdupBZPhenJ\n7/V9IEjEuxoc+GiRj15sGfEQwvCwLGYbdPdngptV9EEhBLo20IXIyekCP9tHMU9s1VRUrjY5y41e\nsbFZbujPp0JQ3v/czlxAexe7Pm/pZZuff63C40VsUjSEsA9hvpte3KFt+Tke6Cf7tRla7MnGskUR\necGEoJyyo2FctlTqYexUETOws6CEt75PTEiKIRJ6m4T0HYTAKA4pSCqGC9BH67f7LrJer/FVRTOz\nVUHqakazX+EriwSa7c3ws4aqnhGTQd6HmNLOelxdMT/YT1GukeCtdYQk9gRFNdL1Mqy6EqOaUJWi\n0+zYXPYJzNeWDk6G+68pt51Scva3drxokyGtiB1UVYOvGmbNAVE9bRdZnS7Y25tx7eYBB9cOkAa6\n0PLqrRWNm8H16/QroWsjsg+hb6n8CpEW54S63ktFgfdYnBzR9/0dW5rvxakzJK+u45o0FqdzIlEH\n4TbXONslAE3rnL1WApH3nhggOpDYQlzTVBW+OeTw4HE+6zPeyXxmaQVOI6uwtr4teObz+VAAVglU\nKngHrx4t+dV//X6e+9hnmc338C380r94N489cYMbjx9QuxnMZ3ip0LBEfY9TWAcQjZaa4Oxe77Xn\n+Rdvob3ggqUjxLTCkWiPSmNilu8QFwnrwHoVQTxSgUjASURjnyZlM0Q8UW0/RB2rdaQ/Dbzp2Sd5\n+zvfzPWbLc//zvt4x8e8mdivqbyncp6gEVFluewQDYBQh0hIURcnJ0fs+TkvvPA7fMrnfw5a2Wq7\n4mylOBcrU5P91YhAU3KfeaEJ8lYx6OFan4gseQWvGJXj09PR0RzUIhH73I/HJCKSddyd5DEuhECX\n0mVAqCqPpDFDNvqdj87htMsB8iDTw2onrJNzboxmnsyIJE1f8/F2fihMr6S0eLc5fmp2FglpLJNx\nmyk7Y5AFpyJUcq6Mrl5BpLdIP42s22Pi6Sssb71KdDVdGzm8foODvbmN7ZXn4MbjUHnm127Q7B+w\nf+0aUlXmfB7OWR5/J22SXHbh3tguRJyPwSb3Uqbj3um6jtVqxXq9pu06+r639O9kV+SU8tVqhYhQ\nN3OqlCLW9z3rtgVX03U2B6yqiqqaMd9vmc1meL9C24AS6BVC7GikSdHxEbRPY5dwsOe51tRo76iw\n4t7BKVJ7Ttcdq763SCVd48Sj3sorECONE+Z1zWxWoWqOuoCyDhENPVErhABDujkpFSzZk07Bj3WG\nh37Q7gIAACAASURBVLiEfC0O/cbZm3/nOczOTme6xuAcTItVue0v3YErSQebBmVsYje5YoN9JHeI\nY457DGNIvmryICsgER9TIVAdvUl5NRoVNS8YW7eTOIhW9DkGiMRkMKYbURSvFdcfu0HdOJr5nHpv\nDlVNUGeRAzFYdfPKVhILCDI5CTlKxzpRC/l06eS7lLJBBUoOAUwFrNXyBmUy53EpEDGIDb5TQyj3\nz3nlk7yc/WX22zl3ezpQjRPF12aA8M6q53svtF3Y+G2NcOvWkt94728C8Nsf/C1evfURVCOH+weo\nKnU15+Pe+W/wyZ/2uwGzOZxEXnn5Fu95z3v5jd94vynM1w4A6FzP7dvHHJ+sODo55tN/7ycNN964\n05PcbRgmLFdvytwbUcybIiI4LOrGMTEkJssGD1EW93hB3enzNsjaZ+q6tnu8660WwXqBRktzqesZ\nrSht2+bxg8OqwlWp/oz37O01LBZr6qpBvBvEgSwa2hKd5o3WFNI83jNnI0c0Pc9V/LcFgWzATYUD\n52Q0TiAVrX/tjKec+rRLxAAZBpYskDD5rP2xsUfD+ztDT6e/OYm8sRDovDSvdVYeZ7Vh+kDfBdpu\nTbvuWPe2pLdUntp56sabt6i1NITVuudkuaLq+P/Ze/MnW5Lrvu+TS1XdtbvfMtubeYMhwMEAIEGY\ni0hJtKlwyGLYcshh/2KH/zz7T7AdDoUkSyHR1mYL4AKCwkIAM5gZzLy9l7tVZebxDyezqu7t7jdv\ngH4jMoI58aa7b9WtJSsr85zv+Z7voRTTsNYyqT0kIWVx7avG4bgaQ9mk7+2w/XIfXX725TOby2Rd\ntf0m23iMltSDy9e2f82HFP/B0Za975X0B2st9CBQqR6phrRFo8omC+0bawcdgWJEG5tZeTbrDkEI\nGbjrFOBJUVMDvK+xpsZV+h64qqauNDLqfI33nsViwfxozvGtE2bzWjW0TMJVHlt5vK97dmcJ/njv\nODk5IkVYHy355OOfa7oGCkJBZp+lSAj01cFikL6cvYjWRUxfUCT05bb91aZPg0warLDW4fGEnKJy\n5/aS45MFr7x+zPHtJX7iWO92fPzRGRfnHVY8rTFYK1jRdCVrdyyXC5wf3q+uTazW5wdpWxkAO7ie\nwy3ls73KKRkIsgW4dM8v732oC3STTd/DQZfLOUdVVZzMlzw9PefoZMnJ7WPu3F1gncF7cK7pvy+S\ndZModqrFYjl5uqZeHHG0nFE3U2YTYbKwuEni0eljLFOSU5Dbo9VpjHFM6i2ga3QMiZSB4hQdFoen\ngrhBjOC8wTlBzBYVBLf4SlgcN8yPhF0bSHhCsBgqSIF64vR3QNC0IkkV05hYT1bceWVBt2up3YTl\n/Jj/6X/879lunxC7wKyZKFMq5EpxubRK2rQKKhXWrK353/+3/5Nv/vqXMwnNEGKHNY2mOdgD2+qX\nf4oMAMjhO1J+K/N6WeuVCfnido4dBqBJo3UnYozqhu52Lc45ujbxgx/8JdY4QlD/oqqqnL6XD2EM\n5LWtzJuH51N/BzDCdDplOp3StcLtO0e9DTVumplwRWrlC0591wZM2F9DX1pgBJQxmESzLg4CWCU1\n1KKOdy8YDz3IA/mdtlkzLjufe5kW5XwFxMcMkiH9xST1vIym3FgTMhUkKgCXAqSgrB+T6HZbQjsh\nNprebKsaGwVf1cwWS3w96f3Bcny9qUMPYsRO+oxWfN3P1+zovm++jauGdhkEEsl2ftYVLNvqus6g\niNDFll3XKkhtRX/PBqGrFGyvJhXGKTMuZN3dWNYXByYKjoSzMKs9J4sJx7OayjSYTOyIxmK8o24h\n4JBtIElLEg9RgxaVN8y8ZzHzLOcNXepICLsYMLtIiB0SO6KpMVYrNcKhXUaf4VDml896srk+1ct6\nNH37QkEgQRey0Kkwk8XhnUZKjEgvhgToghdLtRdDlyfProuqcxD1IYcU8KgQa9juEFOyNYFMsy8y\nnyUVxOWopgjEpCVMkyR22y1JDE3TYCoL3rELO9bdljdvv8Ht27eYzSecnV7wyc8fs9lsmM1rjpYz\n3v7yr/Do0wc82AViUkSxGJ8igjOSBZs01zhlHREV9RS26w3WVTSuBq/CgqUMnjO5pGcC7xySIk3l\nSXnxXW8u2O122n+53G5oNb9ZYrxmUfnF2mQywXt7oFw+DGc1RJ9HZ//8bVxqu1SSKFHnB58+48+/\n+wO++8ffBRQJ/tV37/Pa63dZzhd88MHP+PZ/+FOePTvjjXuvAfDKq3cQgffff5/v/8e/pGkafuM3\nfp07d27p+XzFo4dP+Iu/+H6epCJVZUkHKSZ/3dt4UXUjwKR8dhUCvcey4Jr+OBBdvqqverbaHqNE\nx/Nms+Pxoyc8evSE7bbFZ6E47z3GGJZHCta98sodZrMJ292G3W6jjmMUpvMFTdZHKQ6FELHWEWPK\nkSWbubeXgYCeIv4CBk5hy5R+KToC5ThizaBh9BKMpRJJ6J2rAuRg9s0/4zCobpKC7FexCdQB2ouG\nZtXhMfBSomS9oGJmhyhYrRBDSpEudIQust1uWa/XrHdbNpsdGMNsuWA6nSKiwF673bFeb1mtd3RR\n2LRCF9VBcE61IyQXAbiqLwvT51LfvIBBPx6fhS00vtc9+sFNlFw7aEV3YlwqvrTB2L7muq+IRpNy\n0EGG9dQbi7GVavpmHSfJ0RaLYC3DiMlgpopkZofcOoWObC7XnoTYJV2PM4MrJSGhzATrPDaXvq3r\nmqaZMJlMaJoJdT3h9t1XWS7n3Lp9zHRWgxWihMGAt5aUadWhS8T8Lp+cHFFVDauzCZ9+/BHG5jTw\nTHntA0OJPvVSQaScvpYE418OkFfaOA0EyOLIw7ZDAE8/V12Y/XF6/XWKSC6zq3tZq1y/GHfstltq\na6gnM7xtiG2HN5Yvvf0q9790l9t35syPJ8yPF1hf8e3v/ISL88ijn58T2w62kUnTEGLg3V/9FRZH\nnph2tG3L2emaJ08vmM5nOl+3ykDJV5X1yAYWmt56Hm9Jo/Uigs16JWIyU9GQWWuX71nnl3Lfn/Uk\nfrk2pAcNDmTTNDSTisWyYrtziBHaTqi86pVI0rRNMYkUyFFhwKrNl4yhw3Jy8jrO11RVRbtpefXV\nu2zCikefPOXZw5+A9YixuAAGfba2bhATNF0rFxHZdR3WVjhxWLFagj7PBcYpmJqiij03daL2Eecn\ntDshRscuM6udc1koV9/xNuz0fTKGFD3Lk2O+/t47LOaOFBInJye0O6FyCxqj9ysu4FyNdNn2tjV+\novamAbpuR2Mb5icnxGSZ1VNC6JDYEk1UOzi9uKP74s9wX5/q6n2u/nxgYV7etg/Oj4H34Xdj94+T\nUuL87GI0ByVNexmtI4VgboRRCu745FmAVnIaZbI46+mage1zieX7Au26tfGQ7ftZ/fEyWmx3ECIp\nRkxVZXsjr+dmAGp01XHDtY5AnmT0PXDGDOCPNTmtuTD59+fjInbeFw7K9+mKUEsGjoyBXdsSSXRB\naJMh4sCAd4I3CQmRXRfosMyObzGZzjm5cxsxcLHd9RpUfX/CoM/Zt0QyJeB/fX9fBQBdt5oYY3Tu\n+AULo7xo2+YiDl0bGct0KQAkmSHeqe6OUTukbVu2ra43IQScN3SdBgnbtmW2WNJMKqbTBlt5ogRC\nitSV6hAWe9garQRWe5hOHbePJ9w5mVOZROh2rLcBfIWtK5pdgGqOu9jy6OmF2hPG4BxMK8+tecWt\n44bFTHX1OkmsO4s579h1iW0XNGhlPGK8MjFFg3BGJKdYH6z7xvTA8wBKaxvGwHh9zcQUVLJC91fi\njLVazIo8dj9PkOsL1wTSBzSiL2U03ljRNK+sobMHMZhhP1CEu7B6rCjEY0RZQCbnfpbSwKryp0uC\npIAYh83CYYjNL7y++N5pSbrpdIarPcknTOuxLuDrCRHh7OKCh0+e8PDxKSklBYys14nbabTUZEdL\nX2mduDT+WK5dncN+qxmhfjk9I40nphLJzv90iUv60HPUarxwJTP+zqBu/zftb9pVrUQ8ixOKNTmV\nY2TwXMO+KBTlwzamRb9o00iBGkwffvgx3//+D3n65FQj2t5rhaH5nDfefANQuuWkqXj48CFPnjzC\nGMNrb9zj9ddfx7ll71gDfaWg0goq/3maiAqFlt/L/Q/3qyBQXddZ2T8MqP8oxfSm2jia3ke2RtfW\nizubcv22p0v3aWB9Hvw1iR0ypOkyMvpSmY+Ngm6lulcIgTazeh49fkLbBtbbDRebtWq6dC2QeKNy\nLLoZKTVsNhs2qy2nZ+c8PV0xnS3ZtjvWTSQmvc/FYqYR1ms0qQoLq+8POwIsC+HA9DvnDhzS3RID\naJKyiLYZXoF+QlX6+HMfyy/UBgHSMaAwOEdaZnpwlfYBvsQYmNqLSssgKmpMwpp0CQQaAMERaGbz\nGMmGi0VLvEZrteJQFp/uMmsvdJlpg1fwxqTeydH1VVOuY9DiCXVdZ/FtMNbjKgtSkWJLipFu19G1\n6qyuNzvOz9dsth0kS2UAiRjpMCkOYKQkjczmZ1py81PSoJJEEK9OmUMjjl90e7nBA+0HLbtdI1mf\nSUT1E776q2/y7nv3efP+CYtlg6srdlHYrhLf+95PaY9qCI6wvcC7wGLR8M6XX+f23SkXF8949uyM\nGDvWG8/qwmFypThbxCmNOiuFiXEYYR5H3cfXC9dHsL/wYEsyPasX6zLzMHJ8fMSWNcZGLi5W7FaB\nqlFdnNo3qvVhnVaOydfctp0GAiVwenbBG28co7q2QjWp+Na3vsUPPvg+H3z4Cc5YhECImestBusc\nqQtEG4jGgES8OCqTiESiEWJex4KFKhmsBIp2lxWtxphiRGRD6BJIhU+5KhyRLhmqDC6JMySbUB2B\njl1rWRxP+ZX7b3B6vuXBgwfsiFQ5patLKkLadhusOEzykBy2UaA4xMi6E05PH/D7v//7WFerRl8S\nYoC6LlqOcQ/M/mWbTTbfx2et7yPNOrHEFLPzePWY2x+LBwyOK/bVyryqA9jtdoQRCKTyE8NxrmJ4\npgyMqlOn5bUBcBbvO5opdDFRimBcvtZ9SY2SnptwPWtGfafx8qH9dh0ApOvpwbb+5b1ZHrzaTJFC\nCR33zVVn2u/Dq4Gt0iIChl5AeOyPDgRFOfheytVNs9yIMViX09TrKbbe4CdLjNFqWE3TUHnLNoBg\nMdZrkNBXxJT6FPmiDTW2Vfb6Id9OYaS/6LL1OTKCXlqLMdJ1qpN7OKZiDH2gplS0ck5B6pSishud\nG+l1RkJSTdDJpGa2mFHXvgf+nPfYykFs+/M7A5U3TBvH8mjKrdtzTOzYbiJiPWZSUU0apsyYHE+w\nz9Y8XZ1DZqxX3jJfWG7fqrh70rBY1EAiROFsa+jYcd4KttM0dGWF7ftOBdgraV/jNgRUr3qo4/e3\nrxvXF0Apvpdw+bifp32xTKA9FgG9iPOQPwfjdI3PcpqUBjhCwg92L45oOUyKgM3HN9qxIoaYcjli\nSr7hgmZaq5Fo1hha6nqSF7GWthO6UKqRVWArrPVKOTSa3iXlLstNZhHEqDA1FS4DQDbDQ7I3iV1C\n9bOO0vNQ+fLv0HC6UUPqkiFXFpCUHcwRTXbPWzr8lrnm80sn7NMCRJIq8UvoJ8yPPv6UP/2T7/HT\nH78PwFe+8g5/+3f/Dq/euwUClZ/wz/7JH/HwwRPefe+rAJycHFPVhscPHvPgwUO+/vWv89577zGf\nV/1ZuzZyfn5BVVXEICoULLLHShq3v25pYKWVMeONzZWY7AhcMJf23R+T1z+7z6KYFiNliNqBdRXE\nDjHQho7Ves3ZxbkyDKIyCo6Pj5nNlwCcnl5wivCzn33MJ598TIwaddEFxTKfz/G+6gGY8rMAXb2g\n/DXMi/1o3/720qy1/R4lalxVKj87Pl8Bgm7yXXwRlsu+kZbT/sZVIwwM8PL1QJVWrbhiQ2YvlNKV\nCrp1rNdrnjx5xnq9ZtcFQkpsgzqGs8WC6bShmdR4b1mv11ycr4hRmM1mJBFcVSvLcbvhjjkZ0qVk\nOC+UcXR53kxxeK62rCeH+NZ4jRlt649z8PnLbKoHxKWxmPL6lrBZHHv/e4fOQ4aMLo9TowLw1mhY\noDw3TC4pToCcNmRzOpimgJXj5gu0ldKyRTBJhfmV4i15fS2FbE1fGWMoJ99R1ztw8ODBI+pJxXJ1\nwfJ4wWQ+xTir+4WO3bZlu9N7X6+3nJ1f0G4jlZ8Quo5nT56SUlDjSKKyfWV/DS0GZnkPRQSiQXKa\n38tslx2Iz2o5aPWix79yb336s8UcbEWISsev65pXX7nN7/3uN3nvvTe598YxzkEgcb7Z8ejjM569\ncgs6g2y2bOrEdCq89sqC3/vdb3D77pyf/ex9fvTjn3F6eo7zeZ0wHqTj0JHVPxzJqFUlfbWOmPej\n17CBy3ZbYaQJusQYMwCv/Zz3wj31+ZqWmi6Ar4C1iLPUtWE5nbKbLojrxNe+/iV8YzVFfdux3bW4\nZsKuXdM0mh42m8z0WmPgR3+5pnGeys/oYsKamm/95m9BY/mz7/4FYqPakS7igjqbxgjGW8TWRKI6\nrCLYZEipQ6zDea0wKzbhrMWKMsGVWRJx1uEyG9U4iCYSsiSnjfquljiAsRGs2lbWJLw3LOYnNM2U\nJY7J1PF//1//guW8orYTxCrDPXYaDHVNTYyCbyZsulYj9zFgJPKlN+/xynLavxfOWGUgIhnEuMF1\n0Ulvp/ZjyaAOvBR2p9HzGlA3KPsFKaiscNb2lJT6NBUj0O02ur6gqSLGjO0HdVolJMQaat/gsKQu\nMPE1F+sVznq881S1Y3o059OHDwhtlzUrLZvNis1mx/nFBffu3QNsrlwGp8/Osw3qqerALEkGerW6\nYklvvyq2pXbK4Cv1RTmMG3TSDBpM7/trFIq2+pygvIpDysvLas54rA1Yq9kdEhPGk6vaSb8W2lz9\nqxQMOQStxinW5b8xkEW2VWV0vNIJMWpVscZZnOQ5S4b+s5MZoQtEN4cJLOsTFrMZk0YBn7qasO2e\nsE1tZsZ1bDabIVCXr016Bz/ASFA/mWKjljnJagDnOTNg6Rtj/XPfqjEL6GWw1AFS7HSdzkDvPtg2\n2MelBLymcekabbyhcj5r79Z5zdGsH+89Ta32o0oV5tRdb9ludnhy3+Z9fV1TT2qaWUNqo2oWJkM9\ntdSzmto5mHq21mA+EBANlvnaMJ3XLI6Fo1swm6md24VIXBmarVBfCGYbIXhUiyqpTk+u4C1myI0x\nmfmqBTl0hlI7TN/hlHJhkCuD7Yeg0Hiffd2oz/M8v1hh6GsclpQSxonS9g78ruvAoIL+ld9NT9Ur\ngwzKi10AphQCxjlCGgCWJKjIpSjg7Jxj1sxoJg2BwLbtCE6o6wl1FmOzxmMzqltVFc5VWt64CGP2\nb15xUKIygMr14jTaJGCd1cXGXM6D72mNo4h1ud+r+rBnG5SUF+HGjd0+xSbnnGvLQohiMEZ1JW6y\nFYmArhsmztLOz1Y8ePCQn33wEQBvvnmPyWTSFwiYzRY4V3F2dsHPf/4pAI8ePSbGlo8++oi2bVks\njhQAGuFSlfdsNy1Pnjzl6dNnvDG9ey0A9NexXQIc8ySsJTHL4jTe31HKrh4i+p8FRHz2dZi9RXE6\nnXL79m3u3bvH0dEJIrC62GRR8qbXpUoRVuuLvjR1Sh2PHj5hsViwXM6ZTCak5PYWnqvencPPxwBY\nMjo/HLodh4aGzmEaGa6q6lI/jfOBb6wZFbfradGSq0yJOjBWVBwxMQbl8nOXMQA0tKIF0z+P8Vxc\n5q+DWwghaAWGqkFnN9Uj0ZQkmx3vzA7IVdJKhKcY1yWFyYrDuAqRipi64b5kn1mmhIOr38fxmBQR\ncgmyfmFNI0ZR/9wHLCn303WR6ZuHe/tgiM3Gj0ENpgMcVQ11vUhvPJ10fXBgH29XHQVlng5j0IrS\no4sqn+R3z+RxkJBRVBKtIJj72BwY/ZIGdluKEOMQXLHGKuBki3mh6TIpJbquw3aWjz76iKrxLBYz\nTla3OLp1hK8rYoxs25bz1ZrtRteVzWbL6mJD10WmjZaGvzh7BpIyeKWGZh5IahAaj8k+j0SU3JDM\nsC7eqNt5eT7Y//z6M+0Fxq45xvXt6rW2DUF10RAkJipvuHNnya997R3eeH2BMx2h2xJDYm5r7t29\nzSfHTzh/vGLTtNxaTjm5teTtL93lG1+/z/zI0Xbn/Pzjh326qzL+2nytLjvb2aEfi2TrDlcEDH4x\n5sdLZwbpwCdLAxFTwPkJXdVS1Q1dNLz1lXfwx3OtcGcdk4XFXKyVrZoaZYcDk6xxF2Pk1bs7TaPP\nJX+2bcebb/0Kj85OqasJ3lWAJWV5BGWzANZhXcLgcVFyWljCewUarOiabRF1fGJFKQGeZIeziaZS\n5ryJBuMSxIg1I/xOdI00zqkgvCSsbaibBfP5HOsrfATvK/7B3//7WHZUrsL4PB9FoyWXJw04S1XX\nyurtOiQ5um7HB3/5Q6w1eo6YmT/5nzW+Z6ncRBu7EHv6kexNp/n3Aptn0WVR9sBnZfxahD7bYHS0\nUtGpL4KTNzuvTEqb35+maZgvFyy3K0IInNw+pm48pCMePXmKqyyz5Qxv1MdoY2Kz2SgDMw3BXmNV\nh/Q69tK4jdfEwzmnZwuPDpMYCgt8Vm/osW+u8inQpyZaaynC+/u23DXfGz1k209Bg93TW0Jju+mK\n4IrIwKYGehtQv6vBvyTKCBLvwTd44/DNlKoulRkN3lpqa0jtToP+MalPZzT4L2ObQga7s5zsyunz\nef1mxuvcdW0/XfJlsYbW6zXb7ZbYBZzzufJwx6SpAYdNHcYY5vM5t+7c1rUlXWiqqvc0vmI6a5jN\nZlxcXHB29oxbt25xdHSXV16JfPr4MR9+/HOgaAzl6sLeYbLAfxcDYvTd3rQ7QthxvttwenHG3C9Y\nTBVgWt4+4uNnZ1hvWK1WLCYNzWLC3TeOuffWXWoXmM8qnDN0wWGXNSsrPFxt8JuIt44uQWp1pult\nVKPP2matMNj3DcaBTOv0nyR7SUMIhtlmnO2j5pve4Ngne9H2hYJAEXVK+vSnEp0dvwNSokcD+KMq\n3wdlgAFIvahc0ROSgmozfF9QTSBJCRFFEhUMNrkamBDz51XlNEo9ndKGHZVztHki9t7TdZqXizX4\nutKStk2t0cuuo4uBGIoxJHuGfJ+KUZp1SCol4w/KIY60WfTLiWSUqiyoBkAv3pn7rQBBV6GIN9Vi\ncQfGtwGUSgjGeIbsgufNQvtAwpV75Im+KAJ457QCxejcR8slx4tlDwwVTZmjo2meQA0nyyPatu3P\ns91uefzsEQ8eP0JCZFLVOeKYzxtgu2lZr7eEqBGtGGWvkNJhVbCrKoVpGeaXg7DfRBuPN2MMuKwL\n5EZ9MXoPDyeYQ02gIRXneuC2HFPbkNxijCVIIBmYzKe88dYbWd/KIsny9OlTHjx4gPc1r7yu2k5H\nt07oUsfJnVsc3Tpmu12zOjvn4uJCS0pmBsJYSH4Yd8P9GWOIyJ7BIKMBMXZonpdCVgyW2tm9tKzx\n+3fTToy1dj+qNf6ZI177nz///JeP8dmtqiokp74VR7/b7mjbQNvm/reGqqppphMWi4VqnlmDNSrK\nqYCCnreuaiTkSGwcCW9fca37fXyZun55n8ttz+DP7AWdd67qgJu3lophNNY0Ktda0hm9q7T0utlf\nG8dtzAaVnI5T0hdd5XEkTFSac0wRiUHBphzRtlZU18N4nDGIGwIXugQLKeSqXFnMuxgq3ntdRwFX\nV1pKNWvR1ZWmfnVdx+npjngqiEQm8wnz+ZTNrmXbBpbHR0SEzWbDk6enrFZrQDUCQhvZbDY8i48x\nApvNhovTZ4rwSMAScQLGGibVhBQ7ZS+RQYpRNG6wD27SaSkpAsOz0/nks0HDq4y25zk58PxRuFqt\nOD6aZkAj4pxwNHfcWtTUFs5PT1mvtFzxrVuvcP/VV/iP5sdMvONoXlGZGW/dv8t7773J7WOHcVC7\nrFtla7xrFNxIHfaK4NVVoqpcsT5e2x8vsI950R0/Z/t//933iGnbv2e+ccSoacq0W372/iN+7Wvf\nIISWGB3RGtW0AIKojRZ3LZOq5my9zmPPcX6x5s7dY5LTd6yTxNGrr/LWxTtMqiNqt1WmuO0wVcAF\njzcOKsFLRYqG2nlEAqZRJ8EZZa4YpyzN5C0mGUz0eNthnaVxjmh2OAeuq2ijp2kCnWxJdcqZWDWS\nLLhEFMEEg5UpwXtMTsWOweBdja8NKVqiREwwGG811dMYUogcL0/Y7LZsdoF2GzCmw0jHdLHAeI+x\nHisO5zNwbSqCSdQ3qFspL5xatv9uDvbQdQPr8nGH9/bqsT3M44aq9jjvcJVnOm2YzTS9ves65rMJ\nTaM+RkiRqnKcHGkAs/INbRvYXKx1LrzYkFLAeDNoZJZrdvbKeeOQ1fwijqIKS18d/Lp6vrrZ4C8l\nQGkGXUeM6wGhYW1XtM0YTTnWNEgNjiVjsCMwx5msJ1RKxR/afHunz0QDa8B6ook4iv8qGFEL3xLx\nkkkMRvstiNdgfEiKFHWB9fk5bb3CVpZqOsNZj3JY98+rKbbD74Xj8Xmylz/bzny5WkD9WTI5wrlK\nyRO5mqfaipoiVlWOqlI1ubZte1tIJSBm1FUODm23bNcqMi0knDM0vspaoa3a8PmZJWMRSQSBNgjn\nm5ZHZ2d0pmG7O2e1uWDbbklxiscwqT2maaimM5LT1NjohVQlgk+0NiA24G2i8o4WIRiH1BBsoiUS\nMs7QF5LJfVBGr+zpCwxtT/9HLAbX+9PlID1eMgJt9wBu0fS5XwTN++I1gUaGavlbOyb1vxeQR/b2\nH+hP1lpI2XHLEsWFYkWeFMSAJOlFopJkvooRTHZKEEtEclQz0jQN00nNdNZQTTxp02GM0iutJecf\nTjg6OqLtUi4/PqWqHBfn5+x2qnLexYAJBWnaF4Tq+8FcVuopzB/JqSplAhKjcTZ/8GKXBaswNFGx\nQwAAIABJREFUDTTyrqVWh6pEXJrcfpnWdR3O1ZdYMUqydJ/7XM/bv0xkpcqLRtU6pVvnaNdrr93l\nS+/cYzJR9sVb9+8xnTb9+v7s8TPW6y2xjVReGSSLoxM27Vp1W0iE0JYgcr4XePLwMWfPTnnrS2/w\nyiuvaYrKNQv9daXi/yoDQJeavSwqeN100u/XGxIHoma/0HjTSd1a07N9ptMpdaVq+w8fPsZXqlt0\n797rACyXSzCR2byhries1xf84D9+jxhjLypn8vs/IPDX3MsLNDUyxvNW1pBhMKpUe+Xqfvi8CP2L\nXE/+5YAIUlIm9lOaVJesME0KyFGYJOrAHA7ZsUHSH9/sGyTOOYSBGaIVY/Iilucug1Zr81VF1dRM\nJg2+siq2mATJ2iXWVjRNQ5uGd15EoyrGmizoL/09HQJbY6O8f0ZDyECvt4TXGPqhv8+hSzF7zkRP\n6L36YfwSTSvKjAxeZ/PaNt5Hr11TCgdWXmml4td+as6QcmPJxihgkEz1z8EVjYOrSGtMGgo3fs/R\nHg8BZRUNKZZJAqDpCHhlyDrvabJjZystcKBjQ7WDtts1IWq1kBCFLgrrTUsyCtI/OztlfbEBdP5P\nXWC32fYVL3e7DYag635KIFqlxSV0jR8D9gIkM1TZFKX4v4zZeSx2r//vwybPbZ8FVH6ednLriNl8\nwm7bEeJO2UC25c5xTbcO/ODbP+Avf/QjupD4jd/4dX79t36Ho8mCZXPO9G7DYtnw3tff4qtffYvG\nqajpbrdhdb5hddHR7RLT+Zy73vDk08d7jtTeoOkfwgBeDvcoCg6NS233lXHG/XWN5oocgLc31J49\n/jhfi84RrnbgEqmD82ePWZ9f4J1ll5RVF1PUd8kCSatjSUxE6zSVxOp718aEGKdBSK96SlXlePOt\nt5nNb5PsM5xTIVIRi3GqLWQ9hGhwVNhkMXaK0BLSGd/87W9w9/U5q/MVH7//Mz5+FLBugpcN733t\ndabzGduLc97/+CcIFaw9ZjvNAHGFtRFMhzGOFKbY5DAuEgXaDmaTBbVvNA3DQ20dSFQRedEHIBno\nVCF24fT8ghATu01HDEErzVnHv/6336byNWJUT2y322Er1flbLpcIHf/of76ZZ2j2xpRe36UmQ/Bk\nP6PAXDYS+mYvce96Rs41Efgy5r1XdlnT1NSThuVixsmtBcZGVquVOsFG8JXj1skxR8tFvhZlhlXe\ncufWLS2wcLEihlarEttBF7Rn1RY/4jPssM8z50hSQFkds4MAdR9Yu1mW7LAm7ttSVzF3yucFDOqP\nMdrPmFISPqfWXHHfwzn3tS5V7c71KVRlqnNG10DiDum2dMkSrMPMFplVG2i8Z2OEdr0ihZZut8RX\nDbGq+gBZf549uwb2guUvCKQ/77lfG3B/Sb5KCWw557DG4Sur6WEp9vIIhRle2KVqTyRqpwWSrDHs\ndjtCJ2y3W0LbITExqT2LxZzJpGa1WWd7RCgi4SrO7NiFwNPzNclFHq89XdrQhh3JBEybqLCAx4ol\n2ooOgzhNA5aqInrH1kArKlLunGB8RXIVwXcEa+lE6ASsdQNwmO3WxLWk9dJLe3+VZxRHRJYXbcU2\n/yvLBOoNWTLCaZL+Qx0nRWx1D9XruaoDdNITIt7YvvtEVJU/ox4kSRhriEnlkyNCSCqIaa3PmhGi\ngn4ZkWycYL3F+QQEYtzRhQ0hRpyJ1JXFuZr5oqENc+rphNmyoaos28daCq/dack7L1U/6ZhcwqMg\nyxptzYDX6FkdMgaMMZdNIJuNXqwCPVKM3KurGoyjwTfRHj16wNtv3y8x1vz/IjKrPy5VOXxOe5HB\nan0W9w0t9aRBgBADlfPcu3+LP/yHf4/lXCtGFT0YADr44Kcf8vOPPuX45IRvfetbABwfH7O8NePd\nr73Lg4f/jp/+7H3+4rtvcvv4BICff/Qp3/n33ybEVoHBmR+cZsbGxfi2JTuxg3DwjduoL8HoLS2F\niMnVfBCbqwXRT9Ql4lKcfMjodBqEBEtUasz4GT/fy+9zGd1KTe26jqqq+kpfs3mDs7pATFeOptHS\nkMe3VRNoNpsh3OHiouLWrTs8efKIn3+05JNPPuG1117pr7tpGkJsaduWus6VS3p1fb0+n1f1fukV\nXaRi0bEoVzxia5ToRML1aZIlVU1ENYyKKN44Beqm2pjJpefUMTf+XGQYqhbXG0ViRg6XfukSoFLO\nAXqMAQwaGdkGYuwgmcxaMVRVQ1NPcxTcgvUakas808WSo6Mjjo+PmXrBESEGQrcjiaWaWqZ1w3qj\n1STE6nnLMyzAYzJjxsHhz/3fTaHUjq+ffX0mI6JgfZ8+peCIZKN335G4+ZSww9Lwh6w5ZXVZMPsp\nhfvBlHL5SR3TcagTrb6hnye0VIEGV0xhApVbJQNEKZJDd1gDIQlGIrFrCW1H125p221mRRjw2m91\nXeEq36dF2irHwnbKIOrCju12Sxe0DOxmu2OzC0zPVoDVdLDzc3Y7LVmdQksKkRRaXedIhLbDe6XW\n9/zYJHovjlxaOPdl0r/J5YatzUbvDQZHrneoPt9YueRIXlU6WPL4zWUfxqKuYoUQWqw1VLUlboX1\nasuDTx/z7f/vfbbnp/zpt3/Io4efcnQ8Q8QQu0hod3SbNcvlgq9+5S2++uW3WUzUxjg/O2W1WiES\naSaOqrHsOq34119mBnb2mM+Q9Q3IYLBk6E1G88fIwimg0IHVs+dumgE0fRnt7bdfxfbOh5CkJaSA\nROHZ0jKZNVAJsjOIH5xMff4J67yC3d72NqfJqZApg8/GoOLok4aUElW9UA12J0CFiNP5zVVEIAh4\nD9J2GuCbJP6bf/gHPHryjP/n33+XP/zD3+XNt2b8s3/yJ6xP1/zef/kVjl894Tvf/ilffvsNvn48\n4U///EeEpFVmI0U6IIO0eY6T5BCEYALiPdbUiuPlSoHODWuEpKRVvTL7QnVlEqaKJEkk6fIaqs8p\nxISzOp/GKKxWK7z3bC5WPHr0SBne/4maRQN8YeRwD4DQ5Xf6Ksnpw3n4qiYSiakjJa10tVeJkkSM\n9DbQZDJhu93S7rpsb1kNmmRmaEqJGFpNs/mcAvdX2mXXvE7XMU6H+NOwXt3gdNofU48/EsUd9fPz\n0uutMdhUVMguP8P+b2v2phvtiwHq2+unEchVPLPKCsEkiB10G2IntAaSq6i816sWZdDutmtirIi7\njq7pML7R9MMrrj8VWZMkmVk/Yqm9xEqlN91iVIaYc8pmtk7txRgLU9lp8Elyldh2Cwh+JE3R7Vpi\nt8P5pMGg3QZJgbqumc/nzGYzTs8vNMiVmZeFnWhsRZeEi63Qnu5w2x34qEG2pqaKDreD1iYuwobT\ndUuwnmAc0VYEX9PamvNkQQwXW6FOUNUVxjV0NrIzno6KaGzWBFYASEzRDYPi6/ejtYzbXMyqhCuH\n0NEwrseVuBUXiVkPOX+2913JE/qL2x1fOBPoqtY7zCZpFGS8jevAoKEZO4h+ptLRAjE/iJhEIxCS\nlFWTwDj9GbMxGFF6WkqBGDuSCey6Ld2uJey6QaE8dOx2G7puRz2tleZZVXTdTqOaIZCCuo7OVUpN\ndGocZ2uI8tpbq1ERGRn/e+lyGVGU0WcKJF1G+UWU/aO27sghuOGJuVRc2W9DWs8wGG9+cvJZ50DP\nEYhJ5T6WRxOq7FybrP+xPtvxwV9+yI9/9BOWsxPeffdd7t+/B0DVQKLirbfe5s6dH/Hxxx/zr/7F\nv+RocQzAsydPWW3WWNEo9AcfPODNt1/FG0hSIut5keid6heLvvxVaYfXWQShD9MQvfe5wN5QgnsA\nBuTS4t+P4ytEkC/3zXgayw6p8YjoQpFSAg8htmy2FxibqGqLs8Ux6rAuMV9MOTqektIJk4mmG81m\nsyzoqFGImA4EkV/wOVnZz78dH6Mwf5ytSM4wmUyYTqf99jSqADHu44mfvdC5P6tdle506a3b+2w/\nPfFQc0Z3d1wuVX3YigOnjo+rPBJTz9IxRvqUwMIWsVWFMU7LLTcNTV1T20iKY0aJ7Y27ZEogABUg\n9YYw8hPc3tgaQJ3DdDC47KCnpKL+vf7jnlGsD1sxwYIKHoJjNzy3iVad0/FxNTDeM6IM7C3wRVtD\nRn+Pr7T0R1IhQiOpB340xysV+opqgcEADtmxGKHP7Fw1klXDI5FSRJ1fh/EOKhWr9d5jq5yK5kzP\nGOq6HW3X4nOAZrdtCRFCsqw3qgEVJLFarUidssFS7DCijAskqf5P6jBSaX8o5xxborRJVJOo2Fmi\nToFJ0mt1WCuMhRZ/2eZMThM/eG1EhDRiZx0Ct4dz6qFz1js9I/BZstuKOFRa0GSHXIW9L1bPmC8X\n+HrC5mxH4yvOz4X/9X/5x4TNBZ7EG/fucP+d+3zlva/x9OwZjx58SlM7vvbu2/z2b36DxdLw7PQR\np081Ve/VO6/yyutnPLm4IDDnz77/fS7OVjS2yoxt8rKv4wLI7DKypmzqXxszkDAO+gkwqWfc9r5t\nme4NmGIL/QJR0hdpr796V1kbmdWcpMN5Hfu3Ficspo+0ypY1hKTcEO8tzlqcyTaKKRqVEaIyIANC\nVTW5UpfVVC9xLI8XbFsVS4824cRjncXYQDLKB6xqweJopjVRDFJveOfLr1DNOv70zw1/9M//mD/8\nr7/Fb/+tb/DD737E3Vfv8p3v/pBPP2559umf89/+d7/PTz/+iE+3BtsYouSqXOKJ0WvygQimUvs1\nSsIQ8aIVwDQdU4gp9DayyfpamhIoWF/R9dX58hh3ktNOHb/67pdoKhWOnjTzHDwRqsqT7KAvdfPt\nwBm6IkJZgkFW9tmgpY1lLC4fSwVgB16h2QsGlpYkEFNHjHUGzbvRuiO5BPYGay2v3rnLpPLs1pFu\nt80l5ad463EFyE+R2HbEbseYTVeYM5/VShrv57FZpU81OWQC7QNDN9XEGoIEutSxrCcKzGY9MmtK\nMC/rrVivwWgDkitROtvQMVyz/lD9sqLRGiT0LPjDDBXjLJV34HQ/h+vvPWGwJtIFBUO7sCF2G84f\nP9X5oTlmuTxmcbRkMZtTT5fMpgtCbHn88AHHAifLE5JEhKRBCnM5cKxMc+ntOBlHKvvfD59fmT+v\nAvAO2c2pP8+wz83Nq8UPsC4DmCb1Mg3eq9CzMYYUE6Fr2Wy3GO+obEVVO6xDGa1bBYG6tlVt3yR4\nb5hNG2ZTLcYSujQEpVO2G12DiKWVjl2bU7Y7wdSOxk44DQbfCls65KLl6dmKNkGyFcFWBNOwlppn\nW0MXBKFjMrHU00hTWy6ip6Omsy0xWnypiDqyrQX2KrvC1TbeYf+LXC5mMganrUAw+2z9Mn19nif4\nBTOBkg5Ck9TINmYQo7WoaFwuheacQ/JEKVLQLXVKpalVQFPA4zUlTDokY/lqi2VdjiS90psYhySI\nJGJUxyNqLgeJiK8MkUiXOkynolZd1zGZTIgxcnFxwbNnp1xcrHP6lepgaAWOSR/tNybgci51ZTy+\nctnBFawjO45aKtDWHuMc2zbgKk/TNEwmk77KkHOuz/MNkrBYvHM4a0lJaZHdroWUehZAcaqcVedl\nzF74ZVvYdWi8/6rnOx5+v8xEMmaI0K++KQnOFcfC6SSXDHXVDKdLIAE+fP9jvvPtP+PZ6QVf/7Vv\n8Fu/95tU2T8vVM7799/mtVff4E8++BPOn5xz/w0Fid5791eZzCa8//GHnK5W/Jt//e/5z93f4a37\nd+jznmXv0v5aNsmsufHfe6XMJY9VYwi5XPN1RsMlRsoeG+W6sbBvKFlReq0BFZUUJcDudjvW52e0\n2zX+aNGnRXpjmGaxdgfEbqdpIrlihzJwSlW3EkUbexafn9FxJVNDrmbhAXvCbmW+u6k2HHsk2n14\nnbpnXwFkSE01OQ2qgKputGglnvf+JlNSlbRsuZZ9h4kzOW22oqk8y9lcHdS20yiJWHY7ZUyquHzM\nLEIVDi5Ml2Q04pHoeqFk7z273Wa4twxMikjexynzI4/PUhr9Kn0IY0oqcQbj8357AVURco6Hfkd0\nz5f1vpfxuccIkiEipELWVwME/THyn33a6qhyjbElBSyDPynmUZF07bA6fxvITBkwosAegKRIqaxS\nO09lLZU11N7ivCVFg3iD9YYoQZ9tTukDFdjtYkvX6T/vPVZQxzEIu11Hu4vZIHfENvTpa3mRViZC\ngmiUx6SsJskAScrPLIPTSbR0OWDFYsSi/+VeTJ8lnPmLtRdJ+XweW/K6ZszgrBr0nsToO2OBZIbi\nEcZ6VpsdvhOcrWnqObuN5Qc/+ICjecO9129x9/V7vPv1r7O8PefHf/ZTzi8e8/b9L/MrX3qNiY+c\nP31GaNfcfvU15scNVbPh04dPePDoCRfrFovR9Oo06sQDRkLxGZNNGVAtxi19WsVl3aTxMUyO7o7G\nfVHefUltOs1MzmIzRfCVhSRMmorK1UjI2lnO5jFmsWJy+kfKgFgDkjAmEqSjiy3OGWrjtKx7FLXj\nfKKZeCpbAYlktWaW9UmZjlEdfAXSjAYFZcqDh4Fby7s0wNGywpqGbVvT1eCnDRU1Pl0wnXuiBN5+\n+z5PH36C1LViU52yxWyyqnfkHIaINaL2ZKyx1uNchRdDlxIpnz8FpVg455URlN/NNijTxaAaHiXg\nEAXu3LrLYlbTSUJamEwrfO3w3uKdsgxvquncOMz7/ft1AAAVW84Y6beVdDCTj5NiwrrBT0kIxAx6\nl+ICMozRUvI7Jck6aQnnrGqKOq14qanqiaqqqOs6+xdd728sZhOWixld23Jxdk7XdSyXyoZFIpWz\npBhURylpisxs3vQ6KiWL4vqgm7kUzDpMB+r7bJxXO3JO054ddXD4G27XsXiKXbe//aqU0gOAIy8C\nhTCgKiJDoGjcb2NGxh5QZFCf0ua5Fw2CeO+BkNfbqOxT57G+xtcVJkKwo5SzVNLzr+68Mh5/kfZX\nISDdg0B5vMUYe91I0Opf1ghdSmy3W1arlYpCL481iCu2D6YaiezWG1yClAKVmTCpPdPpNFdxVt1X\nZyyShIRmcIjVYlBd6iDCLias9xg7Y5Uqqs7iQ6Jbbzk739IlTyDRRsdOGladp1sZ1q3Qth2TmWe+\nTcxmidXWskk1iQpMRcwR42w1kcxB+mi/DBZ77rP8gZz5tOdjZDDLZFuOwTb8RczT/2RMoENK++HF\nX5XX5pwD7zF1nYW5wBIgWUiJXewKyZ0IypgximCnHCUTY0hiNTpnHGIG9QVjNVfbZS0D79WAaqYT\njFi2qw2PHj7hybPT/tqWyzmTpsYZS2UVnKmcw2Sy9sAgTPnpjybfsnZkg9TIYMiXCWpPZGrEFrL5\nZ5kgyoISo9JDA0GraolREb6/aX/TRq2fUGRI8Wrblu1Waf51taTxhZkxAB9jp6WAjimxDx6NzjH+\nebjt8P0uZYeN08iYnk8FYdfrdS/abkv2oRWNFlhL23acnZ3mlK9cPSylno5+yBD5vAukiFJUr1qQ\nrbU4o6lgWkFwcCLKAniY7nMTbVgUBgOm/OzFsE0BPQ/PbS7/3+iCa0o58D19mRIl1YlKGVK2B1BI\ngq8s3joaZ7HmFpiGs4sN5+sNT1Yrtl3LerWlO5qDqNBoCFt224jgsFlAWMUxO4yD6XyKqyzbVqOk\nSkDJQQEpIpjqZNqspWaM6T1Qcwl0U6dNAwQZ+Bnd63C/CnWbTOMtKa9/rXS+/qZ94e3FAB1z5e/j\nzy7bRy86b1jqakEMHomOqppRN0tCcsymhunRlNfefJV7b7/Ga2/fYxPho08/5vhkxpd/5TXuvXZC\n44RtaFnUnuWkJgAyazheNCyamiolJrammtSsVufDvAAUYBjAXJF2OW56j4OJfKg1dlX/FAAXXo7P\naYwhSYvqm9g9Z9kSiXmdk5xCpHO/8udsKUEuygwZHMsSBMjAYzJofQuHterQGGMwktMYLIhUmdmd\nlKxnySDMhBSEf/x/fIdZ3bFcLvl7f/ibEGv++Dvf4cnZKeerxLf+s69yfPQhR8dTYow0zGjslNbo\nem6dU6Fb8Zk9bXDR4cTQooz8YovGqIwfY2wf9boqJRUyw8QUECLXjIulH3TmjU5wxuAr1eK0doK7\nRvvp5bV9kOCXWpXFgpHnvKcDeFBS6Iq91DvI4vt12xZWIUOa8HU21BfVrmLYvuxmbZk/rg46XhVQ\n22NZmqvniMP5V0F1BXw0LXC83VEqcI7Z7eV5xlzZqG7mqixzq0JS4Pz8nJQ6ndPqmsoYbtnX6bot\nq+0G442y6EQJEXIY+M5NhF5OZNh++K6UjYM+7Is9o6u1aG6y6XDPldJS0YtUxmFVqWRKDJGu6zRF\nvOuIZT40htAFdrsdEiPOlOO5DNImvDVMakftHa21qkPmnGoORQjOkUjskmUnXmVoKo+3NZ2fY8Sz\n7ioIHavTLauzHTFaYvR0qWITKs67ComG85Ww2ibmHcx2iaMgxJ2lTQ3BdhhrlZid2YEl7qFMHdlD\naBJySeP36g68/pnsPeNfAiz8T5oOZkEjdi71qUxkI38/WhaHstXeY8WD1cikTZbYBaVIh1z1I5nM\nOtp3RBMqEF3i3NFILqmsjJqQstS0ZIFOU+ErmE4WONuwXZ1x+uSc86cX+GnFfN6SgmAaBYC8VeFa\nZU/4rBQvGsXNlFGXB4blshN32NLeMzaZFrjPwynHKA5ojFpa1NmEd5q2dJOlzS9ON8QOinzMy2n7\nE13XDRHlJBph6deFHiHL2zv48P2P+N73/oKfffQhd1+9y9/6nd/iy197hxLcS5kFMpsumDZzJpMZ\nd2/f4bd/57cA+Lt/9/dwDj746Of883/1R/z4Rz/h9ddf58237hCTMi4q57/QRfim26ERt9mok316\nesrTp09BIrPZDG8MdePzu3gwjiRm9tf1DJfr+ujyImXxXqOPJNESz5kNsV1v6HYtt2/f5nh51Efg\nUuhUh6fyrNoNXdsynU6Zz+ccHR1l+rDpU7J04XEj9syL6zb1AFj5YLSgSVTRuM1Gy9inRF+JUA1h\nIcbQj9l5U7/gWZ/fSt+X69vbZgC0fOyVT2DvwzEA4kZ/lyibzpjj+SiNGDYW1VmJErBJiF0g7LZs\nt2t2u5a2zWkGUcvWgy7myagOhTFK5TbWgdFoq+TomLWA1fGlon8MbKYejFQWUxKhiFPqnukgbb7w\nl7KD0+elJHXMSHkcy7D/OD1ZMqh/w3QgvZQCErr+WSaTQPadZDFo+tP4+310aN9BK4EF0J8OQ5Ss\n/SOZ3TN+jpKUbWoqTZe65nq7bkeILTGnTnfdji5XDLIpqmEbhRizJpDX6nFd2xFTh6RASpYYU15v\nI5GOFJVp4Gylxl6/dhuMRLyvEJNUX8QYnQdSFrbOekCFCTRWYjSS7QzAiM02By+VUfLLtMP0Rf2w\nzEFQooNlPA+OpA4QZyc4N8WamspPEbFgDa++cZv79+/wtd/4Mu989S2qmeXh00c8PTvnlVeOOTma\n4UzCG8u8qWmaClVsMLSbMzbnZ2wuztmcb9BauIUJc7UD368ZYhinq+xt/5zP4Itac2NBXpxHjMda\nCGwQOnZxoymOweCqQag+xggp0MagZd6dIYnoc3Be01imCyAhRtNavMBu15FMwrikrDVnhjErLutm\naj8mgUigjU/4h//V32fTnfNP/+mf8fjBOa/cXrJjwr/5d/+W149O8Cz58JOf8s2/9S6b0x3zqkJi\nSxfBJrWVLQGXwZpIIhFxNpGMZdpMMCERyngL6mSpbRwz60UreIaQcunrUrRD51FnDJt2w7SpcsAp\nKAsjCbHT+brrOlx1s5Wl9gSBrxSGHm+nT6M4MCcp6VXGqA6dWMdVK6rp14nxu1COqOuIiCGmSBJD\n14V+LHtfYVxFVTVst62K5EbBOqe6UTldLyZIYogau9OxkG2hq0C5SzZWv17uB/XsNcGt57WbLgd/\nXdN1fz+d9kVsyuct0YXxOm4pP/jCtrz+u3G0PoMVA8Zivac2C7w4rCQ2Fytlw4mQjAVfUU1n4B0u\nKqveihD7ilGZtVqu5+Aa9vydPfmNvb1emFl6+b6uBnV/6dZrmWi1rhJsjqWMuzGkqBVA267LAL8B\np0zX7W7HZtviEZpmgvWNiuYntQmsUSDIO600GxJYn+fM3PcJQ5scrUAwFjdtcPUEqY9I1tKGirAT\nzs8jq9OO6WSiqeupok0T1nFCGxPPtg2rbcfOeHapQqzHREPHBGwgWsGY2IOWJv9PWbA2q/iRtyng\nf5XXlAzY1Cfq5Wcf+20afL2sDdkPEWM+R9DoCwaB+hz9Ur1qfBNcnlT2KY2SKWEDQs5oAox5ouxZ\nQGKISUhiCKJOQRQFALSon6aaCORQeaINgSDqJEgIhFBS01TFfbttWZ2vadsOV1d9bmPX6sTtM0U+\nWYMzRgEf9Ni215mg12ZQ4zVeKaQso5/qEA10737biCJWJkhvLNFoWoVzRtUD3M0xgc6erdltVajw\ncJwNk095Lp89EPcW3L0twzU7r1ucLSkkCpylOEToy4EefPIpP/7xT1mtVrzx1ht849e/zq/9xq9S\nTej72VmDBOi2Hdtty9HyhF/75q/zm7/727p9qhdz/0tv8Pqrr/K9P/8hP/3x+/zB3/sdnPX53soV\ny3MXpr+qbRyZMsZk8CLx9OlTFouZVjiJkflkktk29CBaadboO3XV/T8vcnVdf9ns/JHRfu89bbvV\nigAh9AbLWGMHVLfp6dOnPHv2DGMM8/mcpmn6d+J5LKXP0zRqoYBkAZZijBini5nPlZG8Q50HgRiV\nihpjrrx0g22fmbUfqTNoedTSSt+9yH0XJsxVc/LlloGTpKm+XRK6rmW13XB+fs5qk9hsA7u2I0jC\nJEuKOpdH0RQx4ypsVWctIBVNjUSwCmI5ZzDOsScKdMU1j8fVAFoWEOtyG4N6V4KYY2rCS8z7LM9m\nzBY7dJB1kU/ZgL2cv78Xqc1BpwHAG/YtgpY5pJDHj34CpR9LRTbpv5/E9hpzKaouSDmduojIAAAg\nAElEQVSeFdXt6iQgscMlwftE16mws3MKuEp+X0Qkl4EVxFQ4V8YEkCzGgySHczrXxiBYm8eHxJ55\nolHSXFVuTIk2OQiUhvtWnQCjoJE1Og5vUBPoZbQ+/cuY3tYpTVM4hjVXZDAxo07K4C1dF2l3G2o/\n5c37t/nmt77Mb//tr3F8MuNs/ZRPn37Czz78kC+/fp9nT57wc2OpPBBabt9ZMDmaIiny+PFDHnzy\nCY8ePOb0yTM2qy0havpftnTLlWGuSMHULQPAakdGz2XtwnxP4yCY7G97WS32AOIBqC6GFE0G+A3i\nBg2yFLVqkrGCc6J6V13A+waDiiNLFodW4e4EIeX5OFfbcoIQ1KGkxlohioIxxpqsz5ULEFQt/8M/\n+gf8hz/+D3z6yTO6jRDNmt/9z7/JH/3L7/AHf/Bf8PjDU37yFx9xsjC84w0beYZP4JLFiRDJgKIY\nrFX+fIqpZ3WWkiu91mEOzKaYMZ4c+IlEYgiaJidyab2NMTKpanYXaypfUVlHK4kQd1g7wRi0ItoN\nr43Xpll8jqolh5mHhkOgqiSXDulU11UCtNYreKbCVz1TqjBTnTN4V1H5moihSxGxDlfVuKhapqoe\no86kgnbq9O7d3ue0a56fnp6B5lJJzZQ0lMGXG/a7+XZpPcxt/Hf5/bKmzVVBsTye0fcK8jM1ZR3M\nc+hhnw6Rv/74AjgskaBVr6YLnEA1n+OJPHvygF3b0saWbVSvczJZ4H2F3axIEkE6nHUakDk4YZ/p\nMfTGVT3EQGng8j1fMRauZWVes/8v22IUKluxOt/2ws9JYpY6GXzokiLpvOPOK3eZz+es12sVkK8r\npEtoupXl/fc/ZH1xwb3793BVzcnRjMV0ynYTqPxEU82cgrIxCW0SYvKYqsZPa5rlkvmtYyazBiOJ\n9XbL+ZMN29OAlQmPH66YLeYcTe9QzW4T7AzxhuZkCW2LIRGd56L11ECzuE2Shu3FihC3ykQwVgMB\n2f5MgEmJkFTPsvgxxniwMqznFHsp4lGNyFY0xQ0LRgxilXUaQuhT5Rxu712R5zCIDtsXCgIZhuhk\nDvQOPw9fBPIUO/owxoh0HRI6bOpAAiZ2hK4jxDZHl/NCXeioSSODKavxi7E6YRvApL6EPBhc5fFV\nhfWGNghtCKSiLRFUiK1rw5DniCGEwG6ni5iIYI1W4zJGfyclpQlmoMmIRsMNMed62SsnrcOmfta4\nHGWekJH+RYoxQkx9ek5KapDd5Mu9utjlKIanPLGXTQ8tkQBryRWBEqkrUSggwU9++FMAfvD9H7Na\nrXnz/n3e+cr/z96b/EiSZGl+vyciqmpmvkRERu6ZVZVV2dWzYIbgAmJAYjDgiSBBgiABnsjhdS48\nEiDPBAjwxAv/grnyQp7IA0EM5kBg1l5nep+ursrqrMotVnc3M1UVkcfDE1FVM3ePjMj0yOohWrKi\n3N1MzVRVVJb3vve9733Ehz94F9+Y4TJt1MVGvri4YPt8y2q14b333uPk3L6vMtKcg9OTMy6eXvDL\nX37O8+c9Zw86APyRg/avY1NVXKmWE6NVtbu6uuLZs2c04mlaTxfCdCzYAhbr/arDFSLrQRTma/rj\nNoBIEwawYhX1PJ48ZvptTx4zGpUgVT8BGtcQh8jl7pIvfvkFX375JaFp2Ww2dF1XNFaKQ0HVBKo6\nOuW85fwvM4JVdRKwHOI4rQNt29I2nrOzM+7fvz8t5k5AgmBbRWFf3OVYcQYUGP3U7sBRheTnmgPA\nFM28NlePjGIzTItu25EApCvfd2ycOOcMVIiRMY48v7rk0bPnfP7oGbt9ZMiWh52dQAdDVoZkMJND\naVcdYdcTc2ZMkYvLS6vy1644PT9jdXJqegze4bLdo2nClLW5XI+V4yxrZNGAg3xtY3FU/TSmcE0F\nQgzYWIBlR+CP4O7cD62OFmBRpDJmLb3EjrH7rae253MoAl3S3JTyut4arZ2AIylgdvHhpxRkFOeq\nZ16uRZSktnB2XccwKqvV3vTrhsQoVhUjiysGXcLVEvGpGPO1gqVko4arzU/vAs75UsnToRLAuWl9\n1+ChVPt0gLp9KTk/35+lMQrZ1yoceaLYL/u3Om52e3+x06SPQc0Z8HUWFCoBphnsLHPcjQQ/4iSB\nZs7POv76X33If/1f/R2+/72HNCHx5PlPuXjyHJ9Hzk7O+cM/+Bm/9Y//kO2zC9CRv/k3f8x/8p/+\nh5y/DX/yk5/xm7/7+/zWb/8xP/npIx49MbFk1zhi3JNd1Vc6dgYL4FjUdhWm+XSTaOmUCl8ei8sL\nx+7IEXtdzQIjFIPb/rYS0FbxyuZeLAdEYEmJzlPKqvNSQFud7DtVnQIHU2Uo39E1LabJZmBl0iqS\n3Zb7TlNVNNuzE6ELZFr+9t/523RhhDby9HFPHs/YPh/phwve+96Kf/+v/S3+7n/3P/A//vd/j+7L\np1xuEzCa/aINMY+oK8iOBiTnkrrQIMGY8uK9rZl1POqsmaOYntjSEa/7jAVtgbJ2aXGGNSYTwk2g\nMlpU/xvo832X7dumctc052zIbdEnNRaEZutj7636qWmm2LNumqKvpLZbJq1jyvbq5RpxzAx40fW+\n9L38itfIZfrVi1q16W56TvmbPrbF3m+/2sJwEHSbKj9boNSLlFLyWkC6NIG56u15LyubBgfjLbGt\nWpTk69vr9b++TZMsU/D4eA+2YhFqzLby7LxvWHcbNJtvnQVWqxXSeUJoSFHY7wbiaPMglKrd61Vr\ngEm0VLIMVBaSgWwelYYsLa7Z4P0apEOkrEmpJacGohCcIG6DyoqoLV5bRvVEEtmbzleQhuwDSZWR\nPcklEgMqiewSLlEIKYrHWLoqmZSraPxCM5Vq5wlgQS6rm1tTRiv4bB3p8YsAVpFEWBBE6tr8su27\nTwe7bcHCTZvcRGWqWjnMDpiOAxoHiD1oxOXRqnHlWMAeO9ZYQI7ETKGs4qjV2NWF4aQuszpZsz5b\n0510DMNgNPUS9exWDSena+6fn7Hdt5yfn3J2dsJm3SE5cznuSWNVLk9WGQwxR7AKdJYoqxluRktX\np5MyPBxO+qX/YWkdBelb9Fv9N44jaRgtTSVHckql5HHiLheJfhjnKgFV6LH2I/Ni/NLtps2qjGRz\nGGYQKCXF+UCtSoV48i7xy198ye/85u8B8OTpc959930++uhHfPiDt/EN9GMidG4uQ6qAemK/Z+h3\n5Kx0m24C21NUGi8FZA90neXhP3/+nLMHb9XLnu7zmzKBvil18y5adRtcjYJkM86GPrLf9vTr/oB9\nk7PRYPPimmuEfellv1pO8uJ6yueGYSDIrMUQY6bve1JKU2nxZYW6YdhzcXHF5eUVKWYevnmPN954\ng/Pzc9rWvmMcZao0VM9Vfy4fm0XcZ/ZDBaadzu/JxKozGvtu17MdIkmFmJSTkxPefvAGwXuCOEKw\n8pgJCALpTp93zSdfbiiLa108p8oKETmKZk6imMuokrCcxMvvnv+eN6YJmHazo1PzvlPUssmpRT1g\nYrOIONSBbwIueNKQSHEk762aRE1xbZpmUU63XqFM688StKnjZjkb1R3eszvIsa8H2ViWsl6XI5mi\nfzVyKDWCe3fNOSun3nWdCXumTJZs9bjqebWk+VbjKWeWNPnK8lq+VytyAZBGRKLl1mPBDyfGiBXq\nnqhTWpoCuDmiVHw/VJ1pijhXALEqrupwRcQ3+Pp+6dqUiClZJZBiRLebNS0NPrS40IHzrE5b2m6N\n94EvPv+Kfa3mEbVEzwz4cNKS6UEV5x0kq1DnBfI4MCisVy2bs1Pr3yagYpX8BKsckkUnptFdtNcV\nCLhtb6kpSLW5spYJymbdcnqysuNSz3vvnPBXf/whP/zwbTZtZuwH3jw9443zB3zyyRfIoHz68894\n+ugSl5U37m1Yb85Zb07JGcZBGXro95n9PrO96unHvV2bhxeng8Hx/mDXf3QvL9GUOW3jdTWJWtgA\ntg9YVblsS6JrGGIu6ZgOFXPKg3fgrAItKvgsRE24LKRxJI1jSecZSrGCFhG1wOXQ0AhFzwxLZ5B2\ncYtpCpRaoQ9Pzp7/43//B8TY8qc/+Q1+7dfeJawuefTpc2Lq+Kf//A/58K17vHt2yvDzBPI2P/r4\nP+CP/+j/xIdIyIqXhn1UltreGiDGkegVlyJtVwCs4PHSMoxXBQQqgvFZLPVC1ap5qqWKet+AE4Z+\nJDhPGrZFSD4wpNE0TlxLljylpuY7FIaWqs0k2QIFR5oytr6lA4CjBqIrK63EBEzgd0oxXnjrB2mQ\n2fYyXe4bh+LUbbvChx1eK/OnKcFas3HaxtLB2lVHHJW99ngcvrV0u5SUcUiTVIYWEFvVlT19AVjc\nUPZzmb79ItvsOstn0arQPtkGi8yO6OsAZ+ueXwG0ypatbNKDS6s/q39XDHRn5TZngBKZ7PwJWJ++\nxR28XtsMLFlKoIh9TwabPCWlUbxDGsc4jMQYAW9VKp1DfEBKQYNhGGhLkJIje9kAi8W5FUuHr8Vx\nFpXgltd8YLtN130c4LOxfNOeIguT7y73spkVWBlbAcEqyKaozGnCnqbpcD7gxJ51CC1dp4TQ4WlM\nRDo0Bho5Y943jfnlJydrkEzf72nalTEXy30ppaCHeMS1pOwYk+CipdfmJKBNSaPOhE7xvkV0heaW\nnDzqWrOlpDVoRx1KQB04D+ISSENmnNYGXTDJbTw6Kku2gjtLU/QQzJXCyCwBK8SALNJSrGEOwB9s\nqO6VIPXvuDpYNdoPF93l3yzE9ZafcxR2S0rEYUDHHiHhNRoLhzyJMeWCklupQJtUNQqvYg+Qwsxh\nYgoo3SbQrZ3RU4kMw55xyOz7jsa/w/n5Ke+88xb7ceD0bMX9+2esVy3b7dZYQuOIJou+CcVwEDH2\nj9hZKPmodZOp1dCWOXw3TcGlVsRhf1qucY5W8YycrCznxAS6Xq7y2zQtVTBu9qOup6Z8Xfs6sEAQ\nutbYNzGVFAQN9twyfPbLr/iNf/Y7/N6//BM73nnWJ/f59Bdf8PTqKaP2XO4v+OB77/PxDz6czimu\nRqtGA7aIlCwjQjBPc7+Fx189oWvXrFZWorIOy+Vlf9NF81cFAAEEJ7RtQwgtQxx5+OAh290Vbz58\nyP379ydQxjVhqkoiYgBtGgtgmZmqYIQQGKKlf9xUbvKYsnv8PkDwjhDWU/WAz778jM8++4ws8PZ7\n73J6776lOJU5+/Sp6Rd99dVXJBV+9KNf46Mf/QC8sBv29Gmxod9Ssn5iyxQntzJJnFilqyBNcahB\nVCc5lsurK3b7gV0/MIzK1X7HL37xGX/0B3/Iu2++xelmxfvvvsdqtcJ7z+b0BLIS2oZ33n5wJ8/w\npnSwJcC1PO74tevterrJ3I7G94EhsjCkpY6TQncH1DkrGexCYSd5M1q9pXq5PB+fUiISSSjd6Ypm\n1bHqNgUEKld5i5FawXE96od8vEHe0g7v1yIyL3fst2+uVEiz7y4Vy5SifVSeXZ6TD2qrZp9iqdGq\n9jk/GQ6LJydM6fk1IcxsCylp1OW76rrubs8q1ywklZJSUpyStEgvK0DSMl3TDKfC0nEOFzzdyQmn\nZw84OTmh6dY07RrnG8DxxsOHXF3sAXj25Dnby+eM435ikHhqWWCjR9u1a7lHEyfORzZEKgyyVLS0\nbsla+kbttjFhwPnt8+9Fe7NprlSPpaZ7yfyvBpYQcwZNdZjgIt6NnG7W9P2OD9455z/42/8OJ15o\nstCGVSkR3tKOnke/+JJhl4kRiJE3Hj7kxz/+MQ/u36cJga++fMInP/sln/3iCf1eCWFFaAbTuFG4\nbe2YAMjyGJKY1gGAn+7b0vLNPCpzdwIeb9alern17Bu2LKYXJa44KzJVhcoF+MFZlVnVmgY2FyKI\njqliXWIgp0hOAwFmW0xnu9CKgRRxaXE4aZHcYpX9tBizxhyyRSBBaEkps++FPgmffPoY10DILZ1v\nSTHxy19esfvlwAcfe7JTsq5ROpzf4oOyT5EwVRsLaOoZfY+2CT8ILq/w6khRCc6b3Veq28aYCoPP\notV1/XZqoHEizdW0NCHBM/Y9oQYOxNLNUjaZhBz9Irjy7ZvHkYqtQtnLJzvjYJkvDhklMCGUaqKz\nD+LLGuOd0AQF2TPm3u6/0MXElSICUses7Y8p2ZBuuzU+BHwT0CHjfWAcEk8ePWEcbR5dXQXaNtC6\nwOeffYGITtWGrUqbZ7/fs98NJWCwZrfbsVq3FnAZPc6XdS14UoIQKjCVD+3VYuhWxsRUcGHRP8WF\nxmWZ7m3qNvEFtFuCCcfgxLdvx/P71lSmiutInuYWlRFcAxrTGrXQ2KvXXd+7Vd9sCbQUQFBNRLru\ndbXFmMlDAjVmVxNCARITKWVyHG3NFkHFWZq1HPalXf18TjcF6eqFz3vC4TV+ff8f+9ZTe02+SNRM\nrRNY11KTYkwTYcCLM5BPDNQhme3TuAZtjSkcpKENlkK22+7o+4FxHDk523Dv3j3u3b+k61qu9r0F\nCkq00MAXNdDaOcR5Gj9nE2gCjUqOpiWc8WzWKyR4nAby3tYzjWnqIjchPw3OOyNyMICaVpEixu4r\nVlV9qhVwTGop6RlbMw/sdwpLTARdSF8cPKqKlZS0XSNFFIBWAtyyb97WfqXC0EuqrDXHjca3WoTF\nqXWgpkyKpQSfFO2CUs5Xc0kTqKCPlghSJYgr4HJxSEpaldhEFE9ZSKGPI/v9lnFM7HYtu92O4Dxn\np6ds0sjmdM3JegUpMVztSMNILrofxqwoUaRFlB6WC1lFQQsDyoXSDQvEXuefEzt/es9EGbPBojN4\nRkWUX8+ktjKU9dqONlYpA/sVvu9WAGWG9icjmuVimOCP//Bn/OP/95/wu7/zB3zxxWMATk/O2e4z\nP/nk53SbhkzPOx+8yUc//CEH5d0FTk7XfO/77/PJn/+cX3z2KX/1b/xwPn2G3//9P+JnP/sEcHzw\nwQe88cZ9lo/v2Dn+Joyglzn+LkG86bxphOxMs6YAmJv1Ce+/9wHvvf8umiKhMUdkv9/SLZTAp/Qb\nmY2D47SFa+d7idcq62gJCtTXavU756AfbI24urri+fNLnj27ICWlW/c8f/4c13hC40resVUPc7yc\n07BkzSw3ZhOuN3o2WMly8faPcaSmmZGEP/3TP+Vsc8Ll86tSMtRKt8aiA/Gf/xf/8ddex8u16yys\ng3upf+YFUGS1hlkO48p8UbAy6+Wv2hfz986blUUgC5COTIbMVE2jshbFUtXssNkAm763GKJZLHPa\nNj1lJesJXPTeW1le8cXYA9E8sXPseoqY9PEwq3oGi2ar7iGIZUGbYkg5QbMrotKHcy+Luz1S+i2a\n9Yedy9eoGUz3oxXMOnjE9vwrOHscUVoaiSqL+UlJG8Ryz0UsqXP5PFyhMC8W9+lnRkzPp6Zbl4AL\nmslYSWQz9Mrc8YDUcymuCZyen/HOex/w7nvvc++NB5ye3WOzOTempwrPn13y6MunAPz8Z5/y6Sef\n8uTRCDnQNGuCC+TU41WNcq6DRYCLQzCJaIM9zwIKZXXEMq7vlpX3cu1VgIsDsONgzM3OCNiYrN/q\nEXKKXDx/wrB/xknnOekCOg58+pNPCSQunj1n1w84afnpzz/jkz/5OX3vyGOkCcK9+2e8+fAe3iu/\n93t/yJ/9q5/xxS8ecfF8z7AXxsFSQ4PXA6DtZdu1KPQrf8Pra9o0jFjJc7Dy4BbxL0EPnBUmoUa4\nq706iz2TE2kc8CJoGm2vVdsjcp7TFMU7fF1/MKXy4AXf2r6XsiNLM53Bq6X3JxyXO/BuxXqtONmB\ntGxF8E4J2VjTgxP+7LN/wf7Tf8rPf/t3GLZbhiKeGlVpned+8ESUp/Q4cbic0GjaQQ4r7950K3ZP\nLgneWO8WPEtWYWzBRgQDwHL5NznjDnKYiwyoKk4sJXccEyn3uHS3wtDWqi18xwv2MkVKl/vHcs56\nllIMYzK5hnEcDSgo1xfjWISxDQQKIdD3/RSEq2C69w193zOMPeM4TiBbjMP1azm43wUwIPnw2vlm\nNutsB8w/j1nVd9GqjXDTmvmidfTAthBzqmvwaLkvvHjdKf100F9HAa9yv1Pd0JxJJMY4kjK4CcQr\nNm0eCpvEbKa81JS6k857PYysb9OyGjtZXAG7vSc0vjAHjRXonKNrVtDKVDFsGKwqGM6z6jpWzQpN\nlhWw317w5EnDxeVDzu+fsV6vWa2MoZPSSBfaogtcbXiDYpwH74V109KFBh8CMfd436HdhjEqTQGk\npDAu85BIUUkhk7wnOfAhgPOIesiCaDBiQhY0iQUSACXZmk0Fo75euPuAgYYFS4xNZXt7EZIp1ewO\n5++Uepv1uh38gvadg0BVBbxpO9YnG8Q7q/aBGWopQ45loyjaNqmIL+eUGPtIHmJR4/dFL9HyMJMm\nXHFeslLE7GrReDXBpZKHmHO2ykJtoOvWhOD46Ps/wDl4+vQ5u92+UA8Hnj59yp/8yZ/SNe0U2b98\n9pzHX35B7C1tbLvd4rPjwfm9wjzQiXJqFC5Ly6qI6GzPW75ozBnJudjdGSfG1mjE8onHfsA7q7AQ\nfCDlRPArduMFl5c7Hj15ytXFjnXbMIx7vEuoCOdna9br7rt+zH/Z/oK3pMqYEhp7+v1A1625d+8e\n7777Lu+++w7D0JNyT9c0rFatTcziPuZsEV6dgDB/RGX8Zs2icabjUgXPwBZuq+qVSIlCtYW+N9Dn\n8eOnlsbW90CiWTecnp5yenrKer2eNuGXvb5lqoXDNjItaZxVE6iKsgEWmVMDehon7HdXtF0AEcYY\nyRq52m3ZbrfTZ+6iVcHdG99zbjZ2XAW3Cpggs54OHBpDU0BwYXyZPbXsvznyAEIhzlk54wrsi0Uk\nOwnkMdE1ARda1qerkqrXsmo8QeD83qmJf+eEDgNh1XJ2dsrD+w84Oz+hcd7YlO4IgFnm7C9AyOVd\nycFr8725CZyfI27WJ758bTyqLFaOkrt3Wo2xLot/Buqz6PclL0fM1QfGVzpP2SrxyBQxdZNAphn0\n9uz8FMOSml431uuq7FpX4H4zZEu82b5risDWCCuoE3J2NKHl5PSUt956yA9+8D0++N6HdJs1bbdm\n1Z3QtitCcPzwo/f47LOvAGgCjPue/XZH6qFtE8GP7HfRtIpSsqCI7bgI3qJ+dcw6Az/VzSmL0QRf\nXvlZfdu2BFZfei2Cg/l643FiRrYKts7EEV03nDbnPHvylN/+Z7/Fv9hfQkw8e/KcfT/StRueb3s+\n/eQztFkZ+2AdIO8Y+mf88tNP+If/4B/y+3/8cz755BEXj3tGWlIBkb3YXqBHlb90ilQfXmOtJFaP\nm2jude+YbuYF9/qaNUr+r//7/zH9xzIDwoKJt+tH+n7k17//60gXcY1HnGlEWDVrJY8DOu7RcWBI\nI84FnHq6xtP4DtVI8g5RZRwjrl2xG0ZwVp7d4fB4BhdJOSE52D9JuADkgEsZ7wQnEZeD6VmQaIpW\nxFiA3sf9Fc6d8r/+z/8LP/vz5wy6I4qBWfZ5m98p7Sz1wnVI7tm7PWOfCO0G7wI5JoZxz36XyXic\neJKMJI2otzRQl5UsFRS04JD3YqnYmvHOI65BQ4v3imipjhUjOUfcHaZmgk77xDfWg7mhGXsLJKul\nstU0sQrUw7SvHO6fBu4F59A8MMTMMOwZ9tspdVpCYUmIoiVNZigFJ5yztTclS9fPMaPBW1GZVMpp\nOy2MEzv+eD80U+2QbVoDAodB6uUd56n/ppT4a32yBJ7udmc0IM0X+8Nf69fpuAmPKql2hQGmda8T\nY2ZkOZT2noCrpfC1HvNta6tKgkWfVM1eaJyYPp0DR2LY7+n3W5JC2zS0zYpQcgyHfoeMu6nStTn0\nRWKhnOU6Y+16Stf8RxlfB0bR8vgXB14P7Bv13DWTC6xgRLUJxTucFoA9J+KYyG4GRpq2pW1X7MeB\nYWdC0qFkgRijVtnutlxdXLDZeC4uruj7nvVZQ9MEUhqJ48CqXVOMFFALkHlvzL3gPGvfsPYN4jwa\nhNw52hMlNQ2dMxA2RWEYI2M/Miok78khoI3HnxibiWQp9TljacQRckz4krLprcNRlw2r0FqRsbRc\n7BLNuGKToTUvyP5LhUyyZLQbVlL+lWBlBaAl6w2FFl7cfkVMoOON3IzxWttLa06tYV5AGbyFDWTd\nW8T5qCXYC6tHs9GxjK87dbyJQc9Rbo/Rfi3PtEQrKZTemNBx1tuJMfLk0VNzXNowIfApJVK0QR6C\nLw/SUDgVE6pUspnIdW4vo3sTG8iiSFIilpMq/vRgE0FC6SVLHXBqAoaajW6esdL2CZn6BY4j+XfR\njOYqwkJhf/kkdToO7ia6M47m7ITQIGri1J/82Z/zL3/n9/nJzz7h4uKC8/NzAFabU2JOPH36lGbv\nef/Dd/jxj3/MGw8eLFc8UHjw4D5//W/+FbKMfPHFL/lH/+ifAPDmm2/y9PFzfvJHv0BxfPTR9/nB\nD76HD0zlyavxuuzbu4o4HTsIsYidmbDx3bSacpVzYr/f45tMvx/Zbvfstj1KxE3aHp4qcpkX5amP\n7/2bRZXmdt2Rp+SCBxOjHQZ2uyt2WwNiLi8vp3Sw/W7g4uo5kZ5798+AIignljvsdJmfvLj+r2Ew\nHV/bkglkOcmeJIJP0dYcL/zo1z7mrYemS1QrIvV9z3a7ZT8Mt57jVVulvZqA4OxYJUoFpAVTryah\nzq9ddy5l+r9DY7Dmkc9RpvlNp1UAVPDBJLA3m1PWqx2iT8gKXkzzous877/1kLffeICrsIET7t8/\nxyOc3zulT5HQNmzOzzg52bDuWoLz5LjHE6aIXpbpFqwcqBhtemm0Qo2NHV8/U27/bD9VUAO7LvGl\n3w5ZFyKvynX8+rY0yg/2B+eoKrniYKnznGUBttR1SJXjvfXACZCiq1QNjunc2VI5xDQK7DNLVheI\n92gyE6Ya5QBCrWrmcbXQgthoq4BnllkYdb1Z88bDh3z08Uf86Mc/4MHDh+x2O0n3+2sAACAASURB\nVLa7LX0/cHpyzr37Z3zw4XuEst71lz2PP3vO48+fsEuJ1idyKs9oivbZgHAS8K6sG0WY2nuPBEtB\nzE4sPbEaVr+i9nKg+QJ4PbIfrh1ZnhnYfimitGtLqXz8+Cm/+Rv/glVMSMpcPLtiu+vxzZoxZq62\nIyM93brBO+Gzz37B7/7u7xKC8E/+8W/w+aMdjy9GhqElOUdWbxprL9AD+ro2pSse9YOxRO4qMv7q\n7Ycf/5CcitMC+FyCDjnz5OmOrx59ATIawKkyGfdQ9kpx9Ckhmhh3V7Z3rU5ofAvqqjXImCzdZxgT\nF0+fWJqc8yXV3ipBJc14GYxdLQb5ikBEiRJxhXGXTFWVTh1xlKJnGIlknucrPt+9wbNxoM+BIUXI\nwqYR+v3IlfMIQodnt4+kPoO0BjIEIWsijsow9MSYyNnsZaGxAGt5TkkNUM5gIFHRTfISeHZ5wT//\nR/8MR2CMuZR/LsAZgc2qIzj4u3f4HO8K/FkCD3Wdted88/EHOp4Lm0g0l3XJl3XRAsRWZTGZ5ku2\nAjaOwuzLuQRX1IBttWqM3lmAWFAsP305B2cwpgZ+7D4siFbvaXl/t9+7n7MRvmat/La2383t9rXl\nuu1Z0iX1+nHHQBeUHjoGrvQQQMnyIg+mhhwO91vzCWMJSgjB+8LgGJEUIZvvubz2a78vmdrfYhxf\ns3WP3z9w3F4Pg0gXrMA6d+ZS8RGrjGWs4no5/XY3VQTGma8dXcMYR4Zh4NnlFacnHbvdjmEYuNe2\nnJ2fcLpecdGZFu8sL5NLgSZPIybjv/GeVsTmn2aSmk8dXEsXPBJhSNFYirsdMSujCNIGYuNYt40B\nWtEqAPsx42JGxgQxWVisAFBUP16X+MNhoHnqp5yr0sX8WKQE7CgaQDcCsWb7VXDoVYNb360mEC8D\nUF1PCaufqwOpOgLHNGkDbcQgnzL4pp+CiUdPi6J9l3fO9D8Q4mhiuMNuP5XMVlViSgRxU8nb4Gzh\n1pQJYhuxUNHkejX1l5IuwfHCa+hgNcqlINcH9K7q2DkThjtIC1rkPtgAqvevBSUE2zL0Tqsbt11D\n01K0Ja4vrI46wO9uQ2i7MkzLQLi8vOTx48fEnHjv/fd5790P+OEPfwhgYEEc2Y97dv2WD77/Hv/m\nv/E36Dq/uCYh5USzCvz6X/srJDL/6id/wi8+/RSAn/7Zn/Hoiyek2PLu+x/y8ccf8+t/5SNCgFhK\nmTp3XaPpZduSVXEbM2Q5BkK4+2lax/Y4WnnGL3/xBeuTx4QQ2O12nJyt2awbxnVHaKyEac4OrRVS\n7OrKupYnyuW3vaZlnzaNZ73u8L5htdpMlTL63ubhfm/zVFVLFE3Y7/e0+6YAs4G2ba3/Ur4GAplx\ntvhdXh7Ym2naHtRorLhM4x0//vGPef/9d9lsNqAzfX633bMfXo298aI2jaMC8qhaNHbh9h+1G6J1\nRxTxJftn+Zr1jZue90Q9rswftcoYFGe/6zqaprHyqV4IbUu36rh3ds7JelUq7dh3d12LnJ+yOlkR\nc4LgaVcdq1VH13gCQtX1tnuUaZ07uG7nJs2Ypdwj1RBcGrRlDZ72EnUHPWbpbcYMqncMBrrfNXbg\nJDALdi8jyd70uOzG68Fw05qhJnwv5V5cMT4mkFPtblxNHXNzVcoqLuik6gN5REwLI01rVU07sope\nTgLBhSlgUVMuVeY5vASBms7y/e/dP+O999/m+9//Hm+//RauCTx9+pSnT5+TU4Pmhnv3HtCEjvXq\nBICzszNOTs5w4snJEUn0/TDdQ019FjziMiFYKugE2DYdoelwTcB7h+ZogaJji+tfg7ZcnyqThmr8\nYWkmJ+u10epdw3Y30G97rp7sebjeENTT74SrHaSrHRFBmjU5DiSF/RD59LPP+c3fNr28P/3Jpwy6\nYqQF70iaSJoY0oDkWiJeF9f2Im2QF+911fmpf18vkVwsjhvSWu6qvfXgFOcsqlwBci+WmnP/fqRp\nFaUnuA5w5Zg0rSnJwZgTLkdO760JvqUfjaEQEXyMk03mnAOXOOuED90Kh2nvPLm4ZM9Y+sGRk4Gc\nLo0gI+OQSFIY5hFWfo56pyyQHUGUE98R+z2SPSkO0JsYahcyK4GucVw8v+BsvaJKKWRJJBFCt8a3\nniyZq6srREpavgrIODncTh3Oe9P+EFcYP4WVlxJjipyvz/ne9z5is27R1DNkZdePOOeJY2a/H7i6\nurqzZ1iZqK/6mZcBOqQAdP54H10ccxPbz4RuHat1a1pJUxqdI3vASanSqrRNM82hOXghUzAmZyU0\nDudzSbW9eV6Zw30ctHMHgHL1q25L13fHhSQW/VCPuZ42fjetcQ3JJyhpPJX5HEdFJNJ1nZUgbzwx\nQeMcKSu4QAiZIZv4bhs6tDKJyJaCVAIBTvINTrMj1SCTZPP1VIAWr8bWci6V6rV7HMrKC9vLC9jt\nuXr6lJOTNU3jGS6eIuMV49jT9zuiwmp9StttcFkJOOIUBKpj103jd+rRicV1095/c78fHFn2ihuf\nkeSDasfXbMRv0abxwWx3qVrVtDFGvKvjz2wrTUqO2Rg4KeLbccoIsMIxEcHsbu+bSSriZLWmWzU0\nzioZVvkU1aK74yBk6LKQrvZkAs6NkDM+ZSu2iqMTs+NVR1xMMI6kfgCBHFuk8TTnkeA9TTPSYExQ\nnzI+GhjknVmNczXXItdStLmm1LAlCCR1fuo16Rdq3y3XqMmGnd+v+28iH+ANX9d+pZpAy1YxDVXT\n7qlI7cHitAAWJiYNhXNy5LgdLmr2d0ppiqCqWATdSlWaiPPls+eM48h+N9Dv9xZRy0rKmRgHVG3x\nTs5BThOTyPtQShIv70gOfsrx3xPCZ4uTOpnKBk7g0BSBN1XxY+e0gggTYynbRp3NqicU9tNdLs6+\ncThvueI3jTOLYxxWXvi2rbIX6qa13qz48Acf8uY7b9P6lq5d8XYR282FgJQzPLt4TtsFVquatVu/\nr44BpWkcH3/8Q07OVlxcXADw1ReP6JoV987e5vvf/4GVjz+1qjIpFVaS++asnFcFeG5iyHzbVsdN\nSlbu/NGjR/jnF3hx7PZXvPXOQ95+6yHO3yOOmRBaVNMENtqFVb2iqoT/7a6pls8Fi96v1ycF3PF0\nXcfp6akt6qV0dIzv4VzgwYMHjGPCBWFIPWdnp2w2G9q2ncChl4Gnbo7KHL5Wr6/qFXlv9Hh1Qitm\n6OFcAUGseodz0OBpu5b18LrEE482hFufxU1vHAIm1q4bsstzqYKqCWbmXABwNUO2bVvW6zVnJ6fE\nEcQHQruiW684Pzth1TX0w4gvvNWu62i8pyvpsOoMTGqahuC8GW1fM7gOGZbzPdV9ZVpvRaiMmPpo\nE4qft5PyPUcVxUo/vA59rgn0Yaa8H9+XtZsNdZEqBH2okXSdcVvOle1YYzUVY6UY2LPhUo6ZNEtm\n8ehazvjwXyJjTKJUItBjZQ06xXvL2z+/f8bb773N2++8wWrVcnFxxZMnz3j06BnjIOQk3Du/z8Wz\nLVdXOwDGIaFRSaOxdEXttaY14dmcMxWzq2tq0zTT2lqZQL4p1TyS/5o5clet9r8evVYduxe329Z9\nVZ1Yw7J8TQzRlBZOz09RFYaYaX2g18BPP39mTOpU0u69EFZr9hrg5JRtHBkYic+Fx3/wOarKl88D\nOTjWpyeMRLZxTxZHbsCrIxanxE/XMVlvN+5XFVhJxZZzzAbszff7etO/jtvDe/cn06UGGh2ONGae\nygWnm85SCnPGZ1DtCwDq8c4zquAdrJs1PgiqyVjjmidNCuchJ6Hf7VmtVvz9/+3vW0pUYyzzpm2R\n0OBRfGiZqj9qBkJhtXuUhkhNWTMBVnLCSSrrmSPlhC+C4QDExKMvvqRtIY7Ko6+eIaI8e/KIL774\nil2Ez794zi8+f8r6zXu1EBqaUgl0lHFZdCjJxpgIIRA14kJLHBMxl3QvMsN2x/11S1gFsjg6Vc7O\n1jgX2O8H2vbBnYN6LwPqLNtNc+ymY5bBouzmgIBbnq/OzcWe9NbDB5ycrqf0r6xC2xR/YhH8qunm\nBwy5AnqGEAp72xxfwXN2dgZY8IciPJ5LdgETA7YG6Nx0Pbfd93FbArHzdy1erw78C7/lm7VjlqCI\nzJWJgUoYsCSvOlBNly6XfB3R2ofznuhEiyZeddRnW8Eqwhoz9kWV0urzFjX173EYiNsteTDGz+rk\nhBBanBP67RX7/dYCODgLjElJ43FyY9r5d9FmG1de2zI7DANkMT+t6xj7PZdXey4vtwRvYM449qxW\nG9qmYb/bs9/vjV0usyj/tt+iUWmKTX+53bHdbrnc7k2vNzjefvNNnj3dMewi+9jThA4Rx5iiCTHv\ne7Yx0TUt236Yqs2JAimjOTNeXlpwvB/Iww4XI61mY0kbQIHutqQcGfMITQMxQd8jeSQAoZA+HJ48\nZVBkxFkmhfNmI7nK/ik2pRMT1jd75nqBrBogWRIHQgjmk1g1rG8kN/GdgkDCzS7I5JzfsCAdlEwH\nsqsL3GFLLCJkYlFJl4sQpZYA6hjRkl8rWMTEyvEmYk48/uqJLcqlxJ9mi5M6EUvJUROhjuWKGxVy\nMIc6uFA2h8OUiSkVIVVHZNZgEOcMTHHerhFfHAGjFVPKP9ZI67KPtLAvcqENp5KHmCggmsx9d5cL\nTB97Lncj97rm1mPmKMHy1UMh1ls+WX7WD+aDn0pCxHN+/4Sz8xN0YdssT+NNjoXQnhSmRk2XqN8+\nO3MpKydnGz4++ZhUWD7Dj/dst3tOTu8Rgi+LNaScLd+U60bCbdGUF7WbDZXr/XTXEZa/bP//aDNI\ns6R5F8NTb2MALqHQ+uscddRaratGCRfnmZttiCJzdZGaGiBiTnfXdbzx4D5xNEcmtB2+bThdNTiU\n1pdymZoIDqQJNIWCnQQUV7QQSv59mV+m269HXFFbYz1StDwW9yc18lk2AZlZmbW/ZIrr1nv0UzdN\npXUnkeTrFPBv22pO/7HjsASqlg/TSaCyZedjvmbtyRR9HwN2JnFaESbU/Gi8HFOWa/PBHFkp6aLO\nORMw1GwVLfQoEKOmPRLaxsDBsxM+/P4HhNCy3w/kDGmA/dXAZbPj4tmWp4+ecfXcQKD+cjBR1MGO\nleBxriWlHtDiGFgUzDtfxCddEffFysdXgXhXggpq1//dN4vqv/yxrkRSFwEgoaSb++l38NMI6Pue\ny+0VwXfkqAyauco969DSD6Oluws0rsX5wH6/KwK9I5uVMTkudnubT2HDmDI+K6NCP5o2jYHfgZzM\nac1TUO4l721RYVDz3YvKftPWBG/OfTYoa7kGeu+LbIAZ8ymP+NBOtsTSADebr7Br4mjMPBFQ07EU\nb+d49vyS3/ytf04aE2gZp8HjnM2zuVquIK4ta7PNJTBtn7DqUDWH9eTkpAABytnZGUFsfnatmfqd\nD2j3Nld5BO84f+ddYk6sHnzMw++PXG6vePPZnvNPfopvE88//3PS2KOa8GGhySK+rCOW4uKCM4H2\nhZix/W76ZW+/eR+/bq3STrIyx8aIKVXw7tBIFRFjNihzufDSpt8XQvlQ97BDNrAeOWkVYFZVC7BO\n32mKn6jSLD4vziobOQQ5OaFZNRPI41yYtRVlvrZjG9L+tlHovS+AR91/7OeDB/cmWz9n83G89ySN\nc/DkoHuXwYLbnUZVnar4HQNHxwHp19EOHV53wMKt89EYwXneL52QxFLoUvGDkuqUZlPi4zfulhPH\nwIn5esfAoOSSv1Hey4m8j8T9josvP2e82iGajUn3zpqu69CYePrkS7bbPb5tCN2Ks/WG0K0sPTnl\n1wYAvQyzbXF3r+0apm/Os7yKppkJ50uf1jYWnd2ma2lb+0cWxmx+ufdN0ccVxnEs6c9SgomBgYjP\n4NX2eiNFlEqOWYmXlyCC982UXqUFBJrIFaNVIA8azU51ZQqJ4vstTkdEEhoHJEU07XEaCQV4vCZ4\n42rQY+7zpDr9beDjDHrOGOv1wVrfcyIHe45JJJRKgK/wOP9iMIHK7FvekE5OTHkwHG6w5gZkcDpF\nbCahVDXddS+FQJwznmQaA2WDEm9orCsoIOrYX+3NoSponMODmDPivRmVoaQBOXKheFr6g0wz+fBn\nTfWaF85q5DtTh6/6P8fH6YziV9bTtUWJSlW0603FEUuq+ILu6rdIW7qpxTxYKXC5GQR6Oc7FKzTJ\nkw6Nba7ZFoDaTw4rV1nKyvpg6XnjuKfxAbxNbtRPhnSMI6FtsGo1ZogY+cCm7nq9Zr3Z1BtCiwZS\nEDdteBW9XxoM36pVa7MIwh74sq9gW7/06bSy43Kp+BYYxpEvHz22VL8c6dqW8/NT2lU3XZCVe7SL\nCZXzqEpOapWygApkZbEUm9uiKbN+izk7Voo9T3N5s9nQdR0ZnaoG+MIQAVh1ax48eMh2u7WqGznx\n9OIJq3XL2dkZbdvO7J3y3S/bN5PtdLTQtm07/WyahqSZXDVGFoi/a7wBGtkitZWo4dvXwyQ5uPb6\n2gt3g0Oj7jgK7xab9zEjaHmcsaEaog6kFPF4vHesVisePHCkmPFNSyjPr2s8MY0GImgFzRepuU6R\nDKPORlkFGuyE050e3I3tEQe3dWBcCZVinRcOqJtA+Vn55zDd6zrTSrjryVgr3zVNUxw42wuz5Cnz\nS3NxVPATiD3vJ8XAKP1klPlEHEbyWB3tTMwRSUMxYKySCZIXIqoZ4wYlxEXUB0PUAScNIXhwniFn\n2jawXnesNyvk8rlV+0Bw3tM4h4qYoDwGwrjCjvNNw/n9syllK+fMg/MHPHsyoGPg/OScsd/x6Muv\n2F5sAfjss8949OUXjLFnt7siDo5V16J5JCcTQfe+QURpnKdpTYfh5MTSydadOc/DMOCdpXAjStzH\nO3uGegTaL+ekmyBLPfoJL9qaZ64MB4NZAC0lhzUHVJJVX/EraopS348kD861Rg53wk4Vmnai7Qyq\n7Pc70zdAcbSMmhj7jJOGQRVtPPjMtjivq6Yzxzqb4G+t+FcsOJYMumNKuhnRxhydKP51DN/ATqgO\n8LzuzM/uxiqyd9AU0Jjm9dCzAGJq1KkWLsCuu1yK945cxXqdp+taUhoZGsFHwVNtRwNRu7OGEAP/\n3r/7bxMVFE9Wpd/vcRIsZaIfqHtj0oy4iPiWYbdFMbtWnK2hAWhkMFi7CWj/BOc8oWtJg4espNAi\nrce5Pd51tK0nJ2PTba8Gzs869v0lb5x17HNExeFXnpaAm4Sc3OScuMJ0jTGSNBEaK5nu1DEMA2NK\noJlBlRW+MCfynI6jCj7ctdX4Uu3r7OLbUqRgZo28bGuaxgTqF+cOoS221hIY1gUgesiE8WUtnoEg\nN79/w70s2a9zqv6h/fEixtSvPPiYF+zAEhw/APSk+H++7P9Op/td9t3Us8UmyiVY5RCKtJed4wZG\nzqEPtmhqKYH9GInjyO5qi/YjTsGvWtpuTWgaogzgAxIa1AekMa065z3x4Lm/vna4nn63zcDgRM6R\nlIz5FocRjWnSlJ00cLPtojHGkhFX7c5MTlZuPqMGkjctMVoq6eXlltB0rFYrqyZbPjexvTBNLstc\n8PQXz8Edsq61ZjjoLBuRsxE/qoi+d5hYf7+HNJLiSA4GGGo/4lJhYIp9D0yiCXaO5Vi86VksbfAy\njtNiZVza48e2+LEUx6vM3V+JJlBNLdYDkMv0GY4F3epxGSxNQOSWBThPIJAYMgDZDFPxNhw6aUqU\nIiAlenlgsGW1jdoZuCA657uSFV8AJB9kUUrZ2jKCYNdd0gcm8WRfIhPFYSyo9gz4HIqSLdX+6/fb\nwz4CylRRTUaBZC7ZerhY3t1CExrQa1Vpihp6jbrLMoIxX+tNA3P5HGvhzIqO1gXZl77JapXdKhpc\nv9/7Wd9BCnAY2rJRqjLRov2cHjA7vQYi5bxAaUUL68joebbLCCnNUSFYuIPF+7xlL365Ntu5TLre\nx++9pv2iAq45WwnGi4sLnj5d8eCNC/r+TXO0gjAbHtUAP77QV2vzYjYbM/W5hNBOkfyYE865qSpY\nTQcTEXNE18bOShpZn67wpdJGjUaqqkVlv8UmWD9bryGlOQ3Fe6ty5Us6WIxxen8cR9abrkS7TYNp\ns26/8XUsm2nJyPT8YDbxMgnJDnEVHDmKUk835liK8rkKyJfXbBMr87ICJgvgAGSi7kpobPo76FYr\nmtXaqjiKmDclGSQVQVAp/wuYclmhcidbl/FMAH1WXczZotOx6IfZZp4FO2tUULOlfc5PfkEdp1xs\n6bG8+LZQy7XXLywdnMTfeYl4h8dLkQNdpEXY/dYHK3OaNLeDz6oGiDsO55Oo7V9pDjsbMSrXuZdM\nL0iUVACyas+ULzBAXmq1mlLOWgwMtu9KkJ2laDmZDCEabC8rAG7btiXIIqy7NQ/ueeJ7nmEfeeON\nN7h3/9QMunKpJ6cdJ6ctm5OGNG4swONGMgGhQYDGJ4KHxmfaYNVC6lLtvF3vwdqcX69B/KrpKK/4\n7YCUyHQ2RobMa5SWrk9+uScWENSoe5YGX0DRVD5nJk3VPQFFUVl8d41K3qr587IA9/Ee8henqSpJ\nRlQ9YACPU4NGrUCFs3XQO3Dm1Hi1CmAeJTtXgHBvItDiUPUlWJcMlBOHBCFF09N55/13UByRiEeI\namB6LvPQSlsrXh1CLs8tUIvNuwJM2ZibV8Y56uym96HaLOZQZ5KxycfIan3Kvu/Z7neMb55zuR14\n2raI9uSopLQr+0NxzMT22KSJuvAH5xlTnsa/qDLmzNo3VsuliMCOMeMnUE0PnJ27aHddFez4dwvc\nTq/O5+X6iFaB0Das1NF0zQQm1nRVm1+HjvqUT6BpupfGNagUTSBpp71CC/vA9tnJl5xA2Cl99Ogc\n1lyxW2/psGm7OEyF/i4AosN0sNuBDPON5p9JbZ+aJKzk0AeafSkLdi3JUjfpWk7PnFLFaWlNeE92\npuXlmwBZadYbupONraMCzfqUiMe3Dd1qhQ8msJ/09Qrg31mA+ls054ovHLOtNSkxjqbz48sG71ww\nwkU2M6Px3tK2RSFFxmFPyqZJ6b2H3CI4xjFx8fyKzckV9x40nKzXbLoVW7dDxAT2Zfls1QT74zhO\n66Qe9Y+UoLGNES2ZQ4BEcrKySxpBoyMODvEL3yWnAj4xjS9krkgnZb/N6IENecz0zVI8qzwXp7rJ\nHbypVeb6q+yqvwIm0M2LRy6Ll1IHb17c7c0OjA3w+TtqFBQUJ6ZOE7QWZ3e41gwhL8FSsJYUa9WJ\nSl6/pzpyDkGCWoSxaCCYU5mvLYzHEfXDCbhk+WADtTI/AOS6JsT8XTd/7wwEWam5yaGf6iberQaJ\n9xQK+NKt0urTFQNFEClGR001ORiWcgD+VEqqO75vdQX0K0wgEUQdPjTlc+XzabHxeUAFkcZezNbX\nXtxkd4ozsGoclSZgrKllUNgVLQzNBs45Mwa9uqPj7F7mu+Jwhk4eG4fDfpExuH2+PXqm16dv1Sp6\n5+O3rr33TVtGCU2gEQj9QNM0DEOcQI4hjjx+8oS3nj/k8vKKB/dP8K5BG0cuukjkVJgKggumdbE0\nRJ1WHP4ItS4Py+XCyCh9061W0/zPKVkUsVytiFE/je1gy1bwLc5501lwNq/X6/U05lSVFMu5uNlw\nmaZeeS/nqoVzdJzIBOrU77YqgZG262gEtvueEAJvPnybtm3M+FCl3xtd1fSJXvVJ3d60CAgu+3eK\nasFiDGdq9Fan9KbjdUsO9GA8TP1ovIr5PMcgiPVXoLISbXErQLwzNZm6qdZI+nyVljJLgZxcSbsy\nseYX3PuN/VFvrWzA1Xh0dX5RhKPdNWDcIdMJVbXoAbgbkjMP2Q530eqYdiWlGIpOkR4vHIf7Sc7l\n2RVNO03Zis5oYaRlmcAOzQUoz/ad9b8p1VazGT1lEIjLkNNUIh5NBYLK+BBo2kDbebqVJwRHEIiq\nVrXLGbCVjtJ5zUkxcd+TzYb16oTz83O8Roa9ENvIycma09MNq1WLK4vtvWcbzu9tOD8/IUXTX8hx\nKCkPYuwfL7RB6UJg1QZWXUNTui44q5gkWOUO1Bi05NfDJrnWvqneyY1gy/Ugz3R4ATuvAYPFfKg6\nfgYqYEBQmdez0+zmfXU5R46A45cB/5cR9rnNa8ridsopjhmH9feFZtDdTr3rTTKaDlnblKiwc7Nj\nVedFQmm1VG/KxnBKKPsxokOabDKr7FnS+0tqC+IZyfSa8GJJqQ6hwZhrS80IzRXMDwaKCzgUqXoy\n0oBAjLa+isLVmKZrzNmA+6Rwcfl4tjmS7U2WamnCq189fsx+vwdpEM3kFOegmBp7UNXWcxcM5Mo5\n0ogwjokKrHvvWa1ahovEoEKbDRSLKTEMI01jxwWx6rp31Up26Cuzdb6u2TOxEs3L4TFnAZTzl7eW\ndxRTsoCMLIb8wk7JE8ulMlO1BJHneWRwGeCElHUOIufyCeVgb6r7up2jfvrl1yJLswpYss6Lq8K+\njlYDGmi5DzVOtUhvKVvmSln6eKkyJXJ9fTzYM5nZGQ4mgFukaqxJGTslWC/z510BwKvDnsXRnKxx\nQVg/fMMAoTFy/vABqWmN7di0PPzgQ2KM9H1P27a4rmPImVhAg7tuU7LgIpXvEFC7vR0Dyd/6Wkpq\nas6JqHHS/aysZcumCVYVsazxq1UHHtpVY0WBiuC3ePDOgkirLpCist/39H2PKJyenHHv3j0ePXpq\nxA9nae9WeK/qDCcMtylMVBXQZOmZZW+MarIvWtLHK8htBegKCzvb2DD9L6GOqmV5kUO48LDdxCyr\n/X/jsfX9xWtLkG8Gp6+nj39d+05BoCFFEko/jqz8CiiDLvhp8lqagAMVUo4WaXeOrmm4MgvH6LTO\nBL4Uh1fBBzeBCSIG6DjvUbGHq5Jtg/LOorwuLKK8tePKn2r5g5WBIsVYlMIoqCkry6jAGCs6UB5T\nguqKAZhmppTEvTnPuwpuZhOdsdSmBYshpVTykIuDlV2pjpOOADDbdFMy1aZmmAAAIABJREFU4ams\nEdes8E0o6Tx/2f6yXW91DK9WK1RlStsw0CVOdMvNam15rc4WYqj05NlRGYab0yteuAkttCFe1Gok\narl4Zo3T6XOe15Djz32bjfb4ul9kABnFO9gaNq/bry0ac0xVPo7wze95rjOBDj8zRTaX33H0bOZ7\nvQ5S1/Mc+o1LQHtO+7r+PObvFcxw/6bQtTkA83PJCwTW7lEK8+j2Vg3C5TVMTvKvLqj2l+0vcLtt\nfXhdrRqGNegl5XypADpWAMOijpaCIwYYF5tDihN/27q8KD56MORfhWExfecN3XCbkXrApj4ycg/Z\n0q+pqaNNStTCTmyWC1p1hIUYE6ENk9Gf4mDYWFLGCLvLC3KGzkNX2B9aWR1aot8+8dWTgX/rb/1n\nuO4eTjMeoQsNeBP8bHQNIrRti6RYUmYdWT2CCaBHzYiHk/NTpDGnxPSeEtF7mnbFvfsrhMhmc8rZ\nxhNcZL3quL/ZEHKmbVecblrGYc/l1RUx9bz3vTfxaqXcnbTTM6kgk1KBaJNryISy9lovWZqTAVAx\nmhBrRUESiowZL4HcRLzeLSD7TXRWbgwSvaTtcFOKxnLgV6a5eJnBnPrdTsp8rMzVBRueNM8UN8tG\nGNAmi93N2hSEofZ/ZQvVa3k1B7Gy4eWWSoo32x5307xYVeScExv8VIzD0qIt2BNcABTxrgCmDSIJ\n7y2Qm0u1uoPr1Tl5V7yb06GP5Ejq4zmwWQowlSgggUAOgdX9cwA2mw2+aRhiAXicRxWcb1itA+qE\nYRxLRoilfpPytXH2bfp1ZpHpdF91fN5W2GJeW+/2OZrNXrJUUmHTiJiMivM0PtCEBhFnpAuy9WHr\n6dYtfhWISaHP5CwEH9h0K1ZNYMypsO4N3Dw5OeHeGw/gpz83hk9hv5kOlAE7UgPWuVYtM7bPFPyS\nwoAuKkWRbO9N/Wk6WaKKV9CsBkKKTrKRdTxNbKBFy7IsoqDc5p9MWVHH7pIKWZxJaJRnamsJcwBI\nZl77y7TvVhj6yGlZvMN0t3ne+B2Hk/LAIYEiwHTohB2Y9wbdGflYdSqPOwlEFoV2xfJEp5RnrfRZ\nJvBFDsLfC0OPREpfT7ubIllTFM1NC34uTo+4OSL3cptPPgp15LLg3S37Z9livOLpsy945617Jbpl\nTahsgroBKXij/4EBBhYtK+ytRTrstAApS8sCfGV6FV0KN4NmkxtbPnPga47z5jq1zATUNU2ADC6C\nDgqjst/25Ark5TQ9r5whp1KFbVFi/NHjx9M5cgayTtE0u/9sYmMlmlcBvZTSxEhSEs+eXhwc00c7\nJtUIvupUBv2//Z/+3jd5ZDe2urHVOaNOCF1LU6qebfemj/X555/Ttgb2+CCsWlP5B+gaP1Xfcs7o\nmceG+9I5mp2CmopztOlSkewFW0UW1PKjOZFzLvMv3eogyFQrcnGepZNxK6ChEzByk5bQ8eJd/zam\nYDW8crlHM2QUeSnA61XaTX1shk5l3pS/Z4vmhs8f/n3Y/A3XvGTIzAbMcRpnpb9KiZTM6//NkSbV\nktcvUpiDxzyc4/W1AF1aPivXr3+iyZfPW4rLIv1tPnLRB6Vka1mkdFpo7ObyC8Q0v0nzrjmIjKFS\nxsrhcRYZlmIMHxqJFuid16yafljHrsvGFK3FDerCmdWKJ1TXxFHTlRUX7H2weWRP0Rv4G2DdNnRt\nw6r1tI1nSBHVSOtbsnNWNY7i/Ggmx8g4jgzDgFMIEiDBxdNLvvr8C7aXO84uTtH8kHfeeZOus3X/\n3v015w82rE4a9GmkH/fkYUfXuimFzTlHcNAGoWsC6ybQFfHc1kkRbDTmREVo75IlcPycXsV5/CYt\n6+HFm43ip98ne0Pm+ZjVdA6tcERN4RbTzHuJy3jVFJuv69/6/uxglb/r+2Ki31IZQd8cy3+llryl\nkQvO+scp0na0q2YOgLgGya6kqSYkWPph0wQ2m1OitNj82uO7NYxXeFcjz8MkmrzplK7fMwxfmMpl\nVpKDpB7JjhhNN+bCZaSxdGyNCaIiBFxYkTTjNUMQhhRtH8KY7uIaopiod41gJxfJUlKTXYPPkRwT\n4hp8diTdM+aR//K/+Y/4W7/+JuotbUzLXhzEkcl4MeafYiBRVoVgrCWy4orORs6ZJ8+e8d77HxY7\naERKyW9JCc3uzi1WOdjUrrNfD1ph47+Mw63e7scv9zCRYoMeAcCy/JzDeSGEhkSei7lgLIOs10HT\nyoKrL0g1dg1tRKRURVwAFgbQlVLyzDt1Yp5vqlY2O8Pk4C41AKfbqlpYZFjYV+Lk6Bq5ZlfcWcuK\nZsg5EpxVxqupg1JSC61nHFpkG17EdprHRbVLaspm8ckkT5nCNS3HPmdPwosvYIH5IanpIAQL1AtE\n70kik5ZfTcgwoXKztbPYTptxZdwcg4d325c3+d3X/FV1HJfbuItWfe2cM1Vr13tP8AYEee8JbUOO\nBgCpKpvNCglC0wayCCkNxNF06iRI0QeFvh/xQYmDiUM3bcdmszG/r/zTovkkUKqW5smyzFpSoRVw\nRbrFVQaVmj1VmETVhg6+pNFPWpK2h46qk/pInRw2d67bAqkwOI8BudvWnwm+Fcx2zfP8g+WzXDKu\nX/4ZfbeaQEcLc8Y6JMwHXDtOshlr9Z9HyWqUclfWR0t9N9Dm2GGZFynFexN5dg6888XYd0iyjT7F\niGoyujSV/M7kDKKVLZRKLiGIWqWc2VE8fJBTha6yoOuEyuYy8ZYPbHbmUGdo5MKgmx3lw82mUnTL\nGcvvuaRUZO5SrPnp00d88dkvOVuvJ4HeSudr3Iq2NXHKlEaUniFa+ox3jZX47a3Mbx6Vk/W6aLbY\n4hPjSB9Hxn3PkKI9YO+42m7rndn9pmzob1Y0ahFuLk9miAx9tKhAmbg5Z7JGozgDq1VHzsqw75EI\nYx8ZrgZyLIvgBAKVjAHVKQpRx9N+v5+iEXZiA3Eq6FW1aFQVKYufqkyLYX12w343GUpJ7XMxzef5\n/9o7ux1JsmQrL7O93eMns7LOVNWhZ3SGtwJxg5CQ4I5buEQ6EkKCB0DijkcAccEljwFCMIejMxrR\nU901VdWVGT/u24wL29vdIzKyuro7u6unc31SVUZGRPpfhPvevsxsWYEDxR69Zr6xjA7knJFq94vD\nYYCNI17/8SuoKg6HA1arDjfPrnBz8wwA8Gx7hc12VT//+6mn3wWpE6mYHF94DcvvfUujFjjGesMb\nLhb6LcbL5wPhdzms94QoiQjUFF3SMLuN82I2bW9/u/z+PAYPieptIlFfRWuJXl9s7wKwvGGVZd7i\n+YruPzX9lHtPTpKLO1TnbZyO38XlpansU6ZS1vvb+hBt4POz50IUbxPph/fj0msPRZN/SGbZJZrZ\n+VJUB9CckqZ1TtcP4OS71MaW8DaLYEa7prT3NKNpmcSiGCfauNYM3iXJNFF2tznI4lXU9PBI6ZKg\ny8B6nbHdrPD+Q0IaJNodK7A0nIaNGIbw0xqOBePhGNfTYhiPBa9ff43f/e+/xft3d/jVi+dIKnj2\n7ApXV2HOf3Nzg+fPn9cMRcAQ7Vl75Ok4JMjUgrtLii4rNl3MLNY5IU9jbh1DMY87j8El8fuhCB9w\nv6TylE8I5PjSQHbeBrjCXGsGUC3inAJPIQBBIpLpaENRu7HEXC5qZ78v17M8z8624dvaHU9R0jrv\n0bPxYnmN9YXHV1QdP+ZM5jL/8J//y59IagqeX7/E//ndf/8pV/m9+SefewO+AzEenJYdQ3y6eTu5\n3IvXfpdNUG5BTIQnzzjG2J4Efcon1QCxrvk778WqS4BgnKLKgKhiMGA4lumcijlTmpah1cNu2rST\newdb3ExUD5z6tuW21GemYzDdFXgbS0p4CXpksZRaUjzWbk3e/FBrAKdUURFlkV1ri+sF5iDd92lP\n/UmcBF2sihU1yOGALiorBO0+UaZxod6fTyVe9y6c56u78HoTAubcqiqvVfFd+7hXm+fpPpWbiTf5\nzk+EdBGZrsOXxosfMlec7lkf2p9HnId+fDuA8FgdEKWxVqtWNAyec9x7Qz3KxVCQ+jgnxnHEeCzY\n7Q4YDxbWHf0mOnorsL+7A9DXkrAjur5M9/QmVeiROTu8lYWNsOovW02gAejkd1oDf4sgirhBRZFV\nkVOeNInYv8g4Kjbfi8ccKl5XORW4p2tGm53fCyTXv3PUMrN6Py9Wz4O4FjQdyMRqaLPM89/vGGj+\naTOBfIBigMoA8bDCaw1rxYDkIcLABeIluiGgQKtuKlUJivvNSOWyekCSpDCemuesKGbwNE88QpWc\n29pG9kCYRlv5tpvXmu7l1TehxIevrT3k2XvPHzaF0D0m11HRHRcxh0fJmSvUY0BK4kg1Qus2wm0E\nJEFFwuBTa1TTCqyMELR/YR7YzAIfm7/7279BGQ746o+vJ2O7VZ+x3VzjxfO/xM2zv0BKCYdxwNu3\nb3BXBZxSHB/e3eLDux0Od3HSrmv7P/PIwBmGA3aHO+xu99gfDxg99hnVA8is3kgMI+xQUAYLzxcz\n2FgjHqNjHK1Ga2bjLsN8Q76+itKn3YdbHO9GHG8PONwdp7aFXeqn9bn7ZCo8CW6Yuz1M5t01atJC\nAMsbsPOIqC4GtRfPn08K/CQcmczRW4TS/dhtJJtpXiPn6LDTDHi7EmJpKQUfPnzAbrfDet3j+bNr\n7F5G6+bhxQs8xw2uN9uaLRQ8mAE0veH8ezkPrSdp1Gfva15d8/KsCkH1p3u9mC9W9a2iVFvHw3XQ\nqjp1sznfptO03eialHOO9srF5vbmoSaeRih/IM2jYmn82TKioolOFVI0DKJrjUjb8sXEo2W+YBKZ\nT49ZurfvyxzAxmRKVyeIktOUidMGra52vzrJxqqfefMNm8TTZfRRZr8QWexD+7HMMruXWSD1TVX0\ncJOzb8npfrQ/bO1DRaJzRTPOfew70eYztyx3tKgfOBHMWhDA/fS55uPSjts4hujdsguB6s/lDreI\ndIb4E2MvJEwNIQZNXQRZzqPmIpg6csoIlYSuV2xWGetVwrpP2B8VNjrG4YgiCWNp5aEdVMPQ36pp\n+ngssN5ho+PD+zu8/n/v8PqP7/Hu7QFX22f47W//Pm6u47q/3SZsN1fo1itol5GzwnIVdWBzm/ok\n6LuMPndY5Q6r6jPSZUWn0ZUONQoHIDIWHolLgs+liX07DT+FOKvbtXG5rTEZFFcICqDRhhtSID4g\neYFAoO0nCtwSoPUaUQUegcc5cRIRPt2GFgRr3732npZxfW6k2jqy1ANwb5/aWJhqXtnyctpEeZ0i\n8/X7LVYbbNSOdj/N/Qv5c2YZFF1e7S/cIH0sGPRgdL4GfS69/lDGxXxe1DLrpbEzomxIROYLhFh4\nR7VAsTf5ASfCwaWM5PPnllfzafT0aHxg01LnrYzSqks3qWfXgm85Tj+YqaFHDaq1ACBawKiWxEkH\nq933Ur0GJWiIRLWMDl7bhqvEPNHrQajX06ns5+wza3Pl0uYjItO8pozhqeV1bjCJYinWLZIAryVD\niy9ZHMNTn6XTIGeahLWHg04PBwsi26suexnwe+g4/0jSd+4U37zf4XDYo88dUlZcXW+x7nqkPmEc\nj/jm9j0Ou33NqomAc9cn3N3e4e27d7jd7bHKW3zxxRX6LmG/u8Vud4u7D9/g6maDv/fFK5TR0ecO\nr371Ai9fvsT++Bq7/QFSM3GSajWkNqBWL6QUljHTIZjml/OcMV6dM2zHMcz7p2CHx8w11WNouijR\nAup34GwOoDp9JmMVmEVaB9xqGF8iU6ldm0q7N8Tpd7T9bPYxyxLvT/6MvttH+sPoZI+j3yHZHTI6\nZKyQPSG51JTx6KAgLlUYKEg4An6AYIDIABGP7jSwWosHtIukndh3FrimkImk1R61C2qq9XuRTmki\ncSTGKtJUsXieYEdHm5Ye2DqsuPmURH964C8pr8sblzoZn5R+g0uuNeEOdYOKAT5CLUFNIGWAikPV\n6/tGRI36EW57CAYAe6ikKdIpGENAe8TyhX/z1//+J42UkR+X6Wa8lHD9bpe9lLDehEjnBuyOO4zj\nceqGBYQQtl6vcb25QkqKYTxd7keFoE9kqY6fZwLN53RE2h4z4jFlrix+X97ULfetvZZSmm5Am8jS\nBvRZ2PgxTh+79zhqmxdZMHaahdMmnKfHp4rTDx2yC2V8sa4QedqQOaXPjjbpTu04nd8AX8piujSR\nnV6vXRYvT1r08t/UZXo9BnPm6OmOzlkM7do834aLtBT7cjLOPAbNHLGVVi4H9+Wgf467z9HIOl6F\n6DOL1susQw+1rO631zDEXB4WQYkRLcy8PPciQzb8RmwckBKQJQSWdddh1ffo8iG8VCzKdtsXyUqB\nHYHD4YD9fo/d7oA//ekdEtZzVpA7hmPBh3c7fPPNHaxoCBdAFXhjQ/o+o+sTzBKSFKSiyMmQO0Wf\nFV2XsFp3WK965DRfy0QdWiK1fOrX8ZgdwloDBNcpqNG+7Klr5c5x8xdnZQ1O1PeKn5Y/RkSv3bzN\nkf0ml7pFbyhxAXxAlZ2RdMBKdlB0yK00BILIBopPfIqcL6LWQMwZGssAQZsLLQWeFvG+mNE0Bb7a\ncuen22OtItBJImH9sqksynOk7b9CxHGsN11tiT/O9ZT8OdMyIYMWVGpi0HLsmn8XyYC38qoqkPhc\nytwyIrWFWUXgpd50oWad+2wLa9VAWGwOHp+IRgtzdUGUwEcpcKxcPe4vJvP+aZ8MkFSv2bEOR82C\nEUFuBrttF63Uc0jncrAIkcdjbx4oUtc7b7PUcx7tddRjsxRJFkG5xxaCFHEJbV2SJiOqj3A6P6sW\nFcvXgam061Jg9WMCvdfjaBBkCdeYlPpaAVC/RxqtMlvHxRgLp/DWYjtt8fh8DnQqTHzfxgLn87tv\nvVZ+3wYGH6X553qUk9ZtKAhbjKGMGMqI4hYnrgpyn6LcFinKzyUjqc4dVBHB6aE2pvEW3KqPp6Da\ndH/QPJyqTiCLcWtRKhoi2Wz8/eAeyWkQUX2e18ZZXRMB2imjy89Q6zzgfF7XNIom1rVrFqb3TWJo\nM5SX+96WZ5Vin8RPKgL9h3/3rzhiE/IzYJrMYB7I42YrjNvW6xVubq6x3W5Dqd5H5sk4zmV1u7tw\n5h/dphTihyYCHxeClpfUsxvzZWbQ9PucQn2aFXHhAjhdfOe05cvrbplIfm+dy+1uAsAl7y5FGEPn\nXIcRq+KL1sfysHfR90EkTRH5lnrcprWTCWfrFtAiBF4TgiDR5tikGuZpTS26LKKcci4cNfut00l2\ntOaWk2Usf7YSwntiTBNozidHqjj3E2pT+9HsZDC+JC61p6xmjLXj5YtBXVAn8O4xMZBWJqeA1GDF\nI4tAzW8utjFh7uRyuv3z83NGontEMFUEBkNpvnI2C0NAZAKFH1C7+VDArebTytQxUZDqxLt9merf\nK+rko0ZILNbZp4ycErJGBDaLQnKGOHAo8zaW0XA8jNjdHXB3u8dut8P4bETfZ7z4i2f4q9+8QpYe\nLoKXL38VUbc6sR7GI47HY6RhtwieGFQdHRxdAvpOqh+Qou8EXZemFvFNhIzHKa4JVh7VE+jNV19z\nbkPIz4B//I/+Ac/FXxDnU5I5+3lJZF17nQO0kvL784BPveg/NMbPCQW+CIhGcqkha8yjio1YZm59\nOj/MVuHnxn/7L/+V5+LPnM/QIp4Q8rkJxdsgbkgwrPqELkeXvZQSrq96vPjVDbbbLcSBtzYCtcyw\nDAcAwHDYoRwH2DB36VIsBq+zMezS+NvauIZ5W7igRJRmjn7N2QinIk7cNJ8Osffr0luEHlNK8GWa\n8PCRY3ZJWDAHZITCkESQF8FtWZQdRUTnccfDf/3X/5YD7C+AruvQ93nK5ImMoAS107KY1arDOBqG\nY5jMQx2pehFIcUAdh/GA/XEXEbZhmNahkmFlH2JQE8Pq6RCto2uUrET2iOdIck4pSrI8tTb2iqGW\nmZnFeXVzcwNIRtdv8fW7d3h/d0A5HnG1uQYADOawLsEM+P3v/wAvwBevvsAmbZHzCr/+9Sv8+ovf\n4LAX3B32uL7Z4NWrF/jqzWsAwJdffok//OEPePPmDfZ3H1CGI1DietR1js0qY9UnbLYZV1cbbDZr\ndF1C17UJemRzdSnBVeGDo1xI0yaEEPLzwLUFOwyeFanroglISchdirmXG0RGaO4hqtHOWwusNhiR\nE59BRDRjkQUsi9JTkRThRW3ZuGFqnCRyKLVmaJkVFIlirrEGSSQBLoriAIoj1YqMk/1ZPBbRyTw6\nMsUWpfBA9VKswcQHh6mPV3i0QNF5Vn5bzylp8jf9JYhP5NOhCETIE+Rf/LN/+uh3QKv1+rEX+bPj\nRf35219/8a3vzdvF8VhvfpwNIr8Amm9P80pZssx0qxLpwug7upnYlOYcXkKt88tiKVN5Y/27adEp\nUrRrJtFsx6Vwl2jPisimUQlT0E4TvIqvmoBOBX3u0Hcd1n2Pu90Qu1QzeczDh8ZhsDFM5//n//hf\nkCJ49eovkboNrq/X2D5b47pECeq7D3/Cu7d/AgC8+fprfP311/jw4T2G4YCcBN1mBQy3yOK1HMzQ\nZUHuwhw6En5i21MVfMTnLCsR3Ms0I4QQ8vMgyp19aqbSvHnmce3UK601D/oumHzC37Qu02edx6Ld\nt9UgZjPSn7flY3gzlAHQOjZ+dP0/oFTrXAB6iLk79vdeFfkzhCIQIYQQ8pmYS5Va6ZZOXnfLeZt4\nK2W7P5lrHZui7K8A4iHuTNE91JourS4StV5egGhFELPhKBCTeVLbfCtqO2MRgaQOqhkutd1r7pF7\nx2q1wna9we3ugHRIKLXbogOAGpImHMaC3e0dfve7v4ENBV/85q/w7NkzXF09R8qr6OwIx/F4xNs3\n7wAAX375R3z1+kvcfvMBw/GI3Cf0OUGQ0eURqw7Rpn6lWPUJ/Sp8g86PbzMkn48VRSBCCPk5Yoiu\nvOWsO9j9952WXNmimn/pQ3bO1HxlkRH70e0R1EYfsVStC28+glPHMEzD7un6HvpdrFobLLLel+2G\nHMCF9kMPMWfXn3lgLbfp3Nvyk5dOfmlQBCKEEEI+EwlSO07MfgDhPTSncWszzfVWZni/++OJSSfC\na0g1hnhBAYrAJJohw1P4ALWuiSKAJLQmt9Ubepopu0uUjHkz9a1dDKFAcnRdh26V0R079OsOq8OI\nw9hMj2u73KhYw/52h/d4j//rv8e7b3a4unqG9WaLVbfFWBz7wxG3t7c4HqLs9Pb2Fu/evcM4HFDG\nASMUORc8WyVsVoLtJmGzztiuVlivoivYquugUzhW0HbRAViqnkcUgQgh5GfJf/xP/5kXaEJ+ZCgC\nEUIIIZ+JE7PsRUzuXmtRAKX+D8zp7+3fUgSKTmYLDy3JQPNRgAKSYF4QnW9i6d462ogAWjOJpowg\noBltmkUHMIvcoMgqUq3dAntcb6+wPxr8UNddSo22OjoBxuOAfdpjfP0Gd3dHrFdv0a3WWOUtAMFu\nf8Tbt2+nbS/jEcNwhJcRGQb4ADXH1XaLbW+42mRsNxts1j3WXWQB5U4X/mBVUDOvJu0C5Ev+YYQQ\nQgghTwOKQIQQQshnonXqA5p3TWT+LB0PdCEI2WQkOQtCwLJrSm1CLhmmVeiQ6HBmIlAP5yERAWSs\nHeOi60lKfSxLBKI+mUVqzRQCwupHVaY1q0q0aO8zhrHH1bVjKAbN8f7DccS+DNHWvBPYoeC432FI\nA47FsO8OyHkNlVuMo2F/OGAcR3S5ClBlhI0DuuTIWZGT43qV8WzbYbsCrrYd1usOq3VG1yVk1akt\nbey6Tlk/Fk3fpq5ohBBCCCFPEYpAhBBCyGfiUte5h177GO4Oc8doFkKRzp5AomFqKdDaVl6gLhDN\ncC+17b0iZ4VBJ4OEZq7s0MlPR1WBpFB3qCpEFWnRjh4AxnGcRJjbJMDeUMZoKz8MQ/UsAsRKtGsX\nB6zArKDLCrdo/V53DJYMq17RZ8E6Z9xsM67XGdt1wnaV0dUysKwKUQcwm2c3M2yohAIk1YaT5WCE\nEEIIeaJQBCKEEEI+E02sSDX7Rx1Tps6yvOty61a993gWjiRKulBtKzVKwLRm/bjMFtHTtqQEda+t\ndDG3jW3rkdbCXmEaS3YJj53OM4ZxRL9SrI+KUmJ6YVYw7g1FHFkURzi6dQfTDmNxuA+ADbByBMyR\nU4KrYZVCBRINv6T1KqOTEask2PSOdS9YJWCdBTkJcgKyRhcXMZnbnGg7JtE2OMSgKA8jhBBCCHmK\nUAQihBBCPhOr1Wr6B8yCzzAckXMM0aUUwHXy/XGP1rlm8VNaG/SpvYii1PcAQIGj2IicIuNH3Gom\njMA9Op2YxHpEBGLRnaV5AoWrc5Sq7fd7ZO0gSZGTokTzd3RJcH21xnHYYbvpYx0AYCMwrrDfH3Ec\nC643PQoMLoZ+1UHTKirNvIv9BLDOCVoLzjoF1AVdKlj3gpvtGtt1wsvn18go6Fcdui5VccrrKsvU\n/cXLGFlHtZxNRKfjSgghhBDyFNFvfwshhBBCCCGEEEII+XOH4TBCCCHkM9HKvFrT99bKfOkHZFCI\nCswdDoWJwuXUGDpcj31aZvyrr9WMHjODyIhoE+8QN6hEppBb9fhxh1X/HylzBy2vqTXiChtrnzKr\nfd99hFsB3NFlRLnVKqYXbj3UDQmOPAjWLvhmt4NXHyG1AkGGoEOK9l0Y7YguxTb3CiQ1rLJj0yk2\nnWGVBVKOkKSQMgISu6/a9tMnPyR4dLr3ZpLt/p28lgghhBBCfmlQBCKEEEI+E0vfn4+JEy6oAtBc\n6gTUFvG2FH/kpGwMqF3G3GEYIW5wHwExqBuKGUQAhcFLQmnbpHOicCulggpgUUrmQ4Gpw8XgXuAo\nMHf0CuRO0UkHAOgEWCXFpuuwPxwxFMd+f4dSBpgbVBWaDUkBSYqUEg67gk5C4Nr0GetOseoTtlmx\nWSn6LkF9hBSFIaE4wssIsxl2KbHv6gqTWLa7VxNsQgghhJCnC0UnlTdTAAAD5klEQVQgQggh5DPh\n4VN88nvrDd+Mnb3+s+X7Fn8sAog7xARiHo/r70Dr8lVgZQB8ROQWGUYvYUJtBocBVoUjFaD6A8UC\narctiWwaq9k0JuHtAxQYCiBAckOS6DQGAGmd0SXBKilWOeFYDMNhg9EUxYDiBoNB5AiFQl0hnaGv\n7cGuesGmT9isM7Y5o08JSQEvFhlA5kAxmBmy5OkY2ZRhVeL46XzwWqczQgghhJCnCEUgQggh5DOx\nzP5xic5gLrWjV33eALQ2Xi6TRnTCMvvnPBNIqrhThhGQAvEBBgPcajeyMJe2sZaXtdby07ZFi3hp\n3bUsMoAMBaYltrC2Zjf4nDkEIItAsyIhIYlibUD34iXGAhyGguM44DAOKG5wOIABm01Gl2J6sl1l\nXK0yNn2HVUpIraNZGVHqdpkIMI4wKWFgLYLR51I2ETkpsRORKg0RQgghhDw9KAIRQgghnwnJCa5z\nZsokvOgiQ6hmrjwkAAEXRCATuIeo47VrVikFKkP494jB3cILqC7VbFwIJbOQI5Lg7khwIEXWUUGB\nY4RhANThtb99CC5zFpG4IIlCFej6BPcU3ciKYNMDgxWMPsLgNYvHIeJI9e97dfRJ0YkgiwJe4MVq\nFzXAqtgTmVK1i1nSqdNYlNm1LCqb9stlFokIIYQQQp4SFIEIIYSQz0RrV948gUxQ27f7SfkXMAtA\nJrj/2tIU2sIXaGkUjWJVGCmAjCH+uMO81LdFSZViblMvi3I0kSj6SiIoNsJsRJEQgUQEnh3qOolE\nbVsdCapAn3pITlDpYIPBcwYkAamWaomjCCAankGoPkdqA7Jo+E+XEK18HJFSCgNqsymrx8UhSaHu\nKFZFIMeUUuVa97kKQoQQQgghTxFpE0dCCCGEEEIIIYQQ8suFbTIIIYQQQgghhBBCngAUgQghhBBC\nCCGEEEKeABSBCCGEEEIIIYQQQp4AFIEIIYQQQgghhBBCngAUgQghhBBCCCGEEEKeABSBCCGEEEII\nIYQQQp4AFIEIIYQQQgghhBBCngAUgQghhBBCCCGEEEKeABSBCCGEEEIIIYQQQp4AFIEIIYQQQggh\nhBBCngAUgQghhBBCCCGEEEKeABSBCCGEEEIIIYQQQp4AFIEIIYQQQgghhBBCngAUgQghhBBCCCGE\nEEKeABSBCCGEEEIIIYQQQp4AFIEIIYQQQgghhBBCngAUgQghhBBCCCGEEEKeABSBCCGEEEIIIYQQ\nQp4AFIEIIYQQQgghhBBCngAUgQghhBBCCCGEEEKeABSBCCGEEEIIIYQQQp4AFIEIIYQQQgghhBBC\nngAUgQghhBBCCCGEEEKeAP8fShc0rtFnAboAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f31a47dac88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20.0, 20.0)\n",
    "f, ax = plt.subplots(nrows=1, ncols=10)\n",
    "\n",
    "im_samples = []\n",
    "for i, item in enumerate(np.sort(np.random.randint(0, test_labels.shape[0], size=10))):\n",
    "    filename = test_filenames[item]\n",
    "    fullname = os.path.join('test', filename)\n",
    "    im = Image.open(fullname)\n",
    "    house_num = ''\n",
    "    for k in np.arange(test_labels[item,0]):\n",
    "        house_num += str(test_labels[item,k+1])\n",
    "        \n",
    "    im_samples.extend([item])\n",
    "    ax[i].axis('off')\n",
    "    ax[i].set_title(house_num, loc='center')\n",
    "    ax[i].imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
