{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import Image\n",
    "from scipy import ndimage\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified train.tar.gz\n",
      "Found and verified test.tar.gz\n",
      "Found and verified extra.tar.gz\n"
     ]
    }
   ],
   "source": [
    "url = 'http://ufldl.stanford.edu/housenumbers/'\n",
    "\n",
    "def maybe_download(filename, force=False):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "    if force or not os.path.exists(filename):\n",
    "        filename, _ = urlretrieve(url + filename, filename)\n",
    "    statinfo = os.stat(filename)\n",
    "    print('Found and verified', filename)\n",
    "    return filename\n",
    "\n",
    "train_filename = maybe_download('train.tar.gz')\n",
    "test_filename = maybe_download('test.tar.gz')\n",
    "extra_filename = maybe_download('extra.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train is already presented - Skipping extraction of train.tar.gz.\n",
      "test is already presented - Skipping extraction of test.tar.gz.\n",
      "extra is already presented - Skipping extraction of extra.tar.gz.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(133)\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "    root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "    \n",
    "    if os.path.isdir(root) and not force:\n",
    "        # You may override by setting force=True.\n",
    "        print('%s is already presented - Skipping extraction of %s.' % (root, filename))\n",
    "    else:\n",
    "        print('Extracting %s file data. This may take a while. Please wait.' % root)\n",
    "        tar = tarfile.open(filename)\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "        print('File %s is successfully extracted into %s directory.' % (filename, root))        \n",
    "    \n",
    "    return root\n",
    "\n",
    "train_folder = maybe_extract(train_filename)\n",
    "test_folder = maybe_extract(test_filename)\n",
    "extra_folder = maybe_extract(extra_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# The DigitStructFile is just a wrapper around the G data.  It basically references \n",
    "#     file_:            The input h5 matlab file\n",
    "#     digitStructName   The h5 ref to all the file names\n",
    "#     digitStructBbox   The h5 ref to all struc data\n",
    "class DigitStructsWrapper:\n",
    "    def __init__(self, file_, start_ = 0, end_ = 0):\n",
    "        self.file_ = h5py.File(file_, 'r')\n",
    "        self.names = self.file_['digitStruct']['name'][start_:end_] if end_ > 0 else self.file_['digitStruct']['name']\n",
    "        self.bboxes = self.file_['digitStruct']['bbox'][start_:end_] if end_ > 0 else self.file_['digitStruct']['bbox']\n",
    "        self.collectionSize = len(self.names)\n",
    "        print(\"\\n%s file structure contain %d entries\" % (file_, self.collectionSize))\n",
    "        \n",
    "        \n",
    "    def bboxHelper(self, keys_):\n",
    "        \"\"\"\n",
    "        Method handles the coding difference when there is exactly one bbox or an array of bbox. \n",
    "        \"\"\"\n",
    "        if (len(keys_) > 1):\n",
    "            val = [self.file_[keys_.value[j].item()].value[0][0] for j in range(len(keys_))]\n",
    "        else:\n",
    "            val = [keys_.value[0][0]]\n",
    "        return val\n",
    "\n",
    "    \n",
    "    # getBbox returns a dict of data for the n(th) bbox. \n",
    "    def getBbox(self, n):\n",
    "        bbox = {}\n",
    "        bb = self.bboxes[n].item()\n",
    "        bbox['height'] = self.bboxHelper(self.file_[bb][\"height\"])\n",
    "        bbox['left'] = self.bboxHelper(self.file_[bb][\"left\"])\n",
    "        bbox['top'] = self.bboxHelper(self.file_[bb][\"top\"])\n",
    "        bbox['width'] = self.bboxHelper(self.file_[bb][\"width\"])\n",
    "        bbox['label'] = self.bboxHelper(self.file_[bb][\"label\"])\n",
    "        return bbox\n",
    "\n",
    "    \n",
    "    def getName(self, n):\n",
    "        \"\"\"\n",
    "        Method returns the filename for the n(th) digitStruct. Since each letter is stored in a structure \n",
    "        as array of ANSII char numbers we should convert it back by calling chr function.\n",
    "        \"\"\"\n",
    "        return ''.join([chr(c[0]) for c in self.file_[self.names[n][0]].value])\n",
    "\n",
    "    \n",
    "    def getNumberStructure(self,n):\n",
    "        s = self.getBbox(n)\n",
    "        s['name']=self.getName(n)\n",
    "        return s\n",
    "\n",
    "    def getAllNumbersStructure(self):\n",
    "        \"\"\"\n",
    "        Method returns an array, which contains information about every image.\n",
    "        This info contains: positions, labels \n",
    "        \"\"\"\n",
    "        return [self.getNumberStructure(i) for i in range(self.collectionSize)]\n",
    "\n",
    "    \n",
    "    # Return a restructured version of the dataset (one object per digit in 'boxes').\n",
    "    #\n",
    "    #   Return a list of dicts :\n",
    "    #      'filename' : filename of the samples\n",
    "    #      'boxes' : list of dicts (one by digit) :\n",
    "    #          'label' : 1 to 9 corresponding digits. 10 for digit '0' in image.\n",
    "    #          'left', 'top' : position of bounding box\n",
    "    #          'width', 'height' : dimension of bounding box\n",
    "    #\n",
    "    # Note: We may turn this to a generator, if memory issues arise.\n",
    "    def getAllNumbersRestructured(self): # getAllDigitStructure_ByDigit\n",
    "        numbersData = self.getAllNumbersStructure()\n",
    "        \n",
    "        result = []\n",
    "        for numData in numbersData:\n",
    "            metadatas = []\n",
    "            for i in range(len(numData['height'])):\n",
    "                metadata = {}\n",
    "                metadata['height'] = numData['height'][i]\n",
    "                metadata['label']  = numData['label'][i]\n",
    "                metadata['left']   = numData['left'][i]\n",
    "                metadata['top']    = numData['top'][i]\n",
    "                metadata['width']  = numData['width'][i]\n",
    "                metadatas.append(metadata)\n",
    "                \n",
    "            result.append({ 'boxes':metadatas, 'name':numData[\"name\"] })\n",
    "        print(\"Dataset size:\", len(result))    \n",
    "        print(\"Object structure: \", result[0])\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train/digitStruct.mat file structure contain 33402 entries\n"
     ]
    }
   ],
   "source": [
    "file_ = os.path.join(train_folder, 'digitStruct.mat')\n",
    "dsf = DigitStructsWrapper(file_)\n",
    "train_data = dsf.getAllNumbersRestructured()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_ = os.path.join(test_folder, 'digitStruct.mat')\n",
    "dsf = DigitStructsWrapper(file_)\n",
    "test_data = dsf.getAllNumbersRestructured()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_ = os.path.join(extra_folder, 'digitStruct.mat')\n",
    "dsf = DigitStructsWrapper(file_)\n",
    "extra_data = dsf.getAllNumbersRestructured()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stat(data):\n",
    "    label_count = {}\n",
    "    for i in data:\n",
    "        label_count[len(i[\"boxes\"])] = label_count.get(len(i[\"boxes\"]), 0)  + 1\n",
    "    return label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_stat = stat(train_data)\n",
    "test_stat = stat(test_data)\n",
    "extra_stat = stat(extra_data)\n",
    "print(train_stat)\n",
    "print(test_stat)\n",
    "print(extra_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(1)\n",
    "plt.subplots_adjust(hspace=1)\n",
    "plt.figure(figsize=(12,3.5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.bar(range(len(train_stat)), train_stat.values(), align='center')\n",
    "plt.xticks(range(len(train_stat)),train_stat.keys())\n",
    "plt.title('Train')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Occurencies')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.bar(range(len(test_stat)), test_stat.values(), align='center')\n",
    "plt.xticks(range(len(test_stat)),test_stat.keys())\n",
    "plt.title('Test')\n",
    "plt.xlabel('Labels')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.bar(range(len(extra_stat)), extra_stat.values(), align='center')\n",
    "plt.xticks(range(len(extra_stat)),extra_stat.keys())\n",
    "plt.title('Extra')\n",
    "plt.xlabel('Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the data with digits labels more than 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = filter(lambda a: len(a[\"boxes\"]) < 5, train_data)\n",
    "test_data = filter(lambda a: len(a[\"boxes\"]) < 5, test_data)\n",
    "extra_data = filter(lambda a: len(a[\"boxes\"]) < 5, extra_data)\n",
    "train_stat = stat(train_data)\n",
    "test_stat = stat(test_data)\n",
    "extra_stat = stat(extra_data)\n",
    "print(stat(train_data))\n",
    "print(stat(test_data))\n",
    "print(stat(extra_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(1)\n",
    "plt.subplots_adjust(hspace=1)\n",
    "plt.figure(figsize=(12,3.5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.bar(range(len(train_stat)), train_stat.values(), align='center')\n",
    "plt.xticks(range(len(train_stat)),train_stat.keys())\n",
    "plt.title('Train')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Occurencies')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.bar(range(len(test_stat)), test_stat.values(), align='center')\n",
    "plt.xticks(range(len(test_stat)),test_stat.keys())\n",
    "plt.title('Test')\n",
    "plt.xlabel('Labels')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.bar(range(len(extra_stat)), extra_stat.values(), align='center')\n",
    "plt.xticks(range(len(extra_stat)),extra_stat.keys())\n",
    "plt.title('Extra')\n",
    "plt.xlabel('Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Reformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def print_data_stats(data, folder):\n",
    "    data_imgSize = np.ndarray([len(data),2])\n",
    "\n",
    "    for i in np.arange(len(data)):\n",
    "        filename = data[i]['name']\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        data_imgSize[i, :] = Image.open(filepath).size[:]\n",
    "\n",
    "    max_w, max_h = np.amax(data_imgSize[:,0]), np.amax(data_imgSize[:,1])\n",
    "    min_w, min_h = np.amin(data_imgSize[:,0]), np.amin(data_imgSize[:,1])\n",
    "    mean_w, mean_h = np.mean(data_imgSize[:,0]), np.mean(data_imgSize[:,1])\n",
    "    print(folder, \"max width and height:\", max_w, max_h) \n",
    "    print(folder, \"min width and height:\", min_w, min_h)\n",
    "    print(folder, \"mean width and height:\", mean_w, mean_h, \"\\n\")\n",
    "    \n",
    "    max_w_i, max_h_i = np.where(data_imgSize[:,0] == max_w), np.where(data_imgSize[:,1] == max_h)\n",
    "    print(folder, \"max width indicies:\", max_w_i) \n",
    "    print(folder, \"max height indicies:\", max_h_i, \"\\n\")\n",
    "    \n",
    "    \n",
    "    min_w_i, min_h_i = np.where(data_imgSize[:,0] == min_w), np.where(data_imgSize[:,1] == min_h)\n",
    "    print(folder, \"min width indicies:\", min_w_i) \n",
    "    print(folder, \"min height indicies:\", min_h_i, \"\\n***\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_data_stats(train_data, train_folder)\n",
    "print_data_stats(test_data, test_folder)\n",
    "print_data_stats(extra_data, extra_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = 32\n",
    "\n",
    "def prepare_images(samples, folder):\n",
    "    print(\"Started preparing images for convnet...\")\n",
    "    \n",
    "    prepared_images = np.ndarray([len(samples),img_size,img_size,1], dtype='float32')\n",
    "    actual_numbers = np.ones([len(samples),5], dtype=int) * 10\n",
    "    files = []\n",
    "    for i in range(len(samples)):\n",
    "        filename = samples[i]['name']\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        image = Image.open(filepath)\n",
    "        boxes = samples[i]['boxes']\n",
    "        number_length = len(boxes)\n",
    "        files.append(filename)\n",
    "        \n",
    "        # at 0 index we store length of a label. 3 -> 1; 123-> 3, 12543 -> 5\n",
    "        actual_numbers[i,0] = number_length\n",
    "        \n",
    "        top = np.ndarray([number_length], dtype='float32')\n",
    "        left = np.ndarray([number_length], dtype='float32')\n",
    "        height = np.ndarray([number_length], dtype='float32')\n",
    "        width = np.ndarray([number_length], dtype='float32')\n",
    "        \n",
    "        for j in range(number_length):\n",
    "            # here we use j+1 since first entry used by label length\n",
    "            actual_numbers[i,j+1] = boxes[j]['label']\n",
    "            if boxes[j]['label'] == 10: # Replacing 10 with 0\n",
    "                actual_numbers[i,j+1] = 0\n",
    "                \n",
    "            top[j] = boxes[j]['top']\n",
    "            left[j] = boxes[j]['left']\n",
    "            height[j] = boxes[j]['height']\n",
    "            width[j] = boxes[j]['width']\n",
    "        \n",
    "        img_min_top = np.amin(top)\n",
    "        img_min_left = np.amin(left)\n",
    "        img_height = np.amax(top) + height[np.argmax(top)] - img_min_top\n",
    "        img_width = np.amax(left) + width[np.argmax(left)] - img_min_left\n",
    "\n",
    "        img_left = np.floor(img_min_left - 0.1 * img_width)\n",
    "        img_top = np.floor(img_min_top - 0.1 * img_height)\n",
    "        img_right = np.amin([np.ceil(img_left + 1.2 * img_width), image.size[0]])\n",
    "        img_bottom = np.amin([np.ceil(img_top + 1.2 * img_height), image.size[1]])\n",
    "            \n",
    "        image = image.crop((img_left, img_top, img_right, img_bottom)).resize([img_size, img_size], Image.ANTIALIAS) # Resize image to 32x32\n",
    "        image = np.dot(np.array(image, dtype='float32'), [[0.2989],[0.5870],[0.1140]]) # Convert image to the grayscale\n",
    "\n",
    "        mean = np.mean(image, dtype='float32')\n",
    "        std = np.std(image, dtype='float32', ddof=1)\n",
    "        if std < 0.0001: \n",
    "            std = 1.0\n",
    "        image = (image - mean) / std\n",
    "        prepared_images[i,:,:] = image[:,:,:]\n",
    "        \n",
    "    print(\"Completed. Images cropped, resized and grayscaled\")\n",
    "    \n",
    "    return prepared_images, actual_numbers, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, train_labels, _ = prepare_images(train_data, train_folder)\n",
    "print(train_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data, test_labels, test_filenames = prepare_images(test_data, test_folder)\n",
    "print(test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extra_data, extra_labels, _ = prepare_images(extra_data, extra_folder)\n",
    "print(extra_data.shape, extra_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Here we add new data to our training set from extra set.\n",
    "# Then we remove this part from memory to free it\n",
    "train_data_temp = np.concatenate((train_data, extra_data[:40000, :, :, :]))\n",
    "extra_data_temp = np.delete(extra_data, np.arange(40000), axis=0)\n",
    "\n",
    "train_labels_temp = np.concatenate((train_labels, extra_labels[:40000]))\n",
    "extra_labels_temp = np.delete(extra_labels, np.arange(40000), axis=0)\n",
    "\n",
    "# And then we shuffle all the data we have\n",
    "train_data_temp, train_labels_temp = shuffle(train_data_temp, train_labels_temp)\n",
    "extra_data_temp, extra_labels_temp = shuffle(extra_data_temp, extra_labels_temp)\n",
    "test_data_temp, test_labels_temp, test_filenames_temp = shuffle(test_data, test_labels, test_filenames)\n",
    "\n",
    "print(\"Train shapes:\", train_data_temp.shape, train_labels_temp.shape)\n",
    "print(\"Extra shapes:\", extra_data_temp.shape, extra_labels_temp.shape)\n",
    "print(\"Test shapes:\", test_data_temp.shape, test_labels_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_file = 'SVHN2.pickle'\n",
    "\n",
    "try:\n",
    "    f = open(pickle_file, 'wb')\n",
    "    save = {\n",
    "        'train_data': train_data_temp,\n",
    "        'train_labels': train_labels_temp,\n",
    "        'test_data': test_data_temp,\n",
    "        'test_labels': test_labels_temp,\n",
    "        'test_filenames': test_filenames_temp,\n",
    "        'valid_data': extra_data_temp, # The rest of extra data will be used \n",
    "        'valid_labels': extra_labels_temp # as validation set during model training\n",
    "        }\n",
    "    pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', pickle_file, ':', e)\n",
    "    raise\n",
    "    \n",
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_num_length = Counter(train_labels_temp[:,0])\n",
    "test_num_length = Counter(test_labels_temp[:,0])\n",
    "extra_num_length = Counter(extra_labels_temp[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(2)\n",
    "plt.subplots_adjust(hspace=1)\n",
    "plt.figure(figsize=(12,3.5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.bar(train_num_length.keys(), train_num_length.values(), align='center')\n",
    "plt.xticks(train_num_length.keys())\n",
    "plt.title('Train')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Occurencies')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.bar(test_num_length.keys(), test_num_length.values(), align='center')\n",
    "plt.xticks(test_num_length.keys())\n",
    "plt.title('Test')\n",
    "plt.xlabel('Labels')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.bar(extra_num_length.keys(), extra_num_length.values(), align='center')\n",
    "plt.xticks(test_num_length.keys())\n",
    "plt.title('Validation')\n",
    "plt.xlabel('Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = 'SVHN2.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_labels = save['train_labels']\n",
    "    test_labels = save['test_labels']\n",
    "    valid_labels = save['valid_labels']\n",
    "    del save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Remove classes of empty labels\n",
    "train_digits = Counter(train_labels.flatten()[np.where(train_labels.flatten() != 10)])\n",
    "test_digits = Counter(test_labels.flatten()[np.where(test_labels.flatten() != 10)])\n",
    "valid_digits = Counter(valid_labels.flatten()[np.where(valid_labels.flatten() != 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(3)\n",
    "plt.subplots_adjust(hspace=1)\n",
    "plt.figure(figsize=(12,3.5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.bar(train_digits.keys(), train_digits.values(), align='center')\n",
    "plt.xticks(train_digits.keys())\n",
    "plt.title('Train')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Occurencies')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.bar(test_digits.keys(), test_digits.values(), align='center')\n",
    "plt.xticks(test_digits.keys())\n",
    "plt.title('Test')\n",
    "plt.xlabel('Labels')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.bar(valid_digits.keys(), valid_digits.values(), align='center')\n",
    "plt.xticks(valid_digits.keys())\n",
    "plt.title('Validation')\n",
    "plt.xlabel('Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
